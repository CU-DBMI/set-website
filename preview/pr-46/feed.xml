<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/set-website/preview/pr-46/feed.xml" rel="self" type="application/atom+xml" /><link href="/set-website/preview/pr-46/" rel="alternate" type="text/html" /><updated>2025-05-23T15:15:29+00:00</updated><id>/set-website/preview/pr-46/feed.xml</id><title type="html">Software Engineering Team</title><subtitle>The software engineering team of the Department of Biomedical Informatics at the University of Colorado Anschutz</subtitle><entry><title type="html">Introducing uv: A Fast, Portable Python Environment Manager</title><link href="/set-website/preview/pr-46/2025/05/22/introducing-uv.html" rel="alternate" type="text/html" title="Introducing uv: A Fast, Portable Python Environment Manager" /><published>2025-05-22T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2025/05/22/introducing-uv</id><content type="html" xml:base="/set-website/preview/pr-46/2025/05/22/introducing-uv.html"><![CDATA[<h1 id="introducing-uv-a-fast-portable-python-environment-manager">Introducing uv: A Fast, Portable Python Environment Manager</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<!-- excerpt start -->
<p><strong>Managing Python environments has evolved rapidly over the last decade, but complexity and portability remain challenges.</strong><br />
<strong><code class="language-plaintext highlighter-rouge">uv</code> from Astral aims to simplify environment management with exceptional speed, cross-platform portability, and complete feature parity with existing tools.</strong><br />
In this article, we&#8217;ll explore the history of Python environment management, consider conda in context with Python ecosystems, and provide an overview of using <code class="language-plaintext highlighter-rouge">uv</code>.
<!-- excerpt end --></p>

<h2 id="what-is-uv-and-why-does-it-matter">What is <code class="language-plaintext highlighter-rouge">uv</code> and why does it matter?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/uv_and_python.png" style="
        width: 25%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p><code class="language-plaintext highlighter-rouge">uv</code> is a Python environment management and packaging tool which helps you write and maintain Python software.
In context with other similar tools <code class="language-plaintext highlighter-rouge">uv</code> is magnitudes faster at completing the same work.
This is due largely to <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)">Rust</a> bindings which help the Python-focused procedures complete more quickly and a custom dependency resolver (which often consumes large amounts of time).
In the following paragraphs we&#8217;ll cover some background on this area to help provide context about <code class="language-plaintext highlighter-rouge">uv</code> and the domain it assists with.</p>

<h2 id="what-are-python-packages-and-environment-management">What are Python packages and environment management?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/python_environment_managers.png" style="
        width: 60%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Python packages are the primary way you can install and import pre-existing code into your projects (without needing to copy the code into your own project directly).
Python environments include all the necessary details (including external package dependencies) to help ensure your projects works through reproducible execution.
Python environment management tools are used to help add, remove, or update external package dependencies.
They also help you build packages of your own for deployment to others.</p>

<p>Without environment management tools and their related code you will be unable to accurately reproduce your Python environment.
This can lead to challenges when it comes to reproducibility (you may see different outcomes or exceptions from system to system).
It also can be costly in terms of time (dependency management alone can cause hours of debugging time).
Using environment managers with Python is nearly required at this point in time.</p>

<h2 id="a-brief-history-of-python-environment-management">A brief history of Python environment management</h2>

<!--
Source for diagram
%%{init: { 'logLevel': 'debug', 'theme': 'base', 'timeline': {'disableMulticolor': true}}}%%
timeline
    2000 : distutils & setup.py
    2004 : setuptools
    2007 : virtualenv <br>(external)
    2008 : pip
    2010 : requirements.txt <br> (widespread adoption)
    2012 : conda
         : venv (stdlib)
    2017 : pyproject.toml (PEP 518)
         : pipenv
         : hatch
    2018 : poetry
    2023 : uv
-->

<figure class="figure">
  <a class="figure-image" aria-label="Python packaging and environment management has evolved since the year 2000. It includes many different styles and ecosystems.">
    <img src="/set-website/preview/pr-46/images/python_env_mgmt_timline.png" style="
        width: 100%;
        max-height: unset;
      " alt="Python packaging and environment management has evolved since the year 2000. It includes many different styles and ecosystems." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Python packaging and environment management has evolved since the year 2000. It includes many different styles and ecosystems.

    </figcaption>
  
</figure>

<p>Python environment management has drastically changed since the year 2000.
We provide the below timeline synopsis of some of the bigger changes to this domain for Python.
Keep in mind that many of these tools are still supported today but some are deprecated and in the process of being removed (such as <code class="language-plaintext highlighter-rouge">distutils</code>, which was removed from Python 3.12 and future versions).</p>

<ol>
  <li><strong>2000: <code class="language-plaintext highlighter-rouge">distutils</code> &amp; <code class="language-plaintext highlighter-rouge">setup.py</code></strong>
    <ul>
      <li>The original Python standard library tools for packaging and distributing Python projects. <a href="https://docs.python.org/3.11/library/distutils.html"><code class="language-plaintext highlighter-rouge">distutils</code></a> allowed developers to define how their projects should be built and installed using a <a href="https://packaging.python.org/en/latest/guides/distributing-packages-using-setuptools/#setup-py"><code class="language-plaintext highlighter-rouge">setup.py</code></a> script.</li>
    </ul>
  </li>
  <li><strong>2004: <code class="language-plaintext highlighter-rouge">setuptools</code></strong>
    <ul>
      <li><a href="https://setuptools.pypa.io/en/latest/userguide/"><code class="language-plaintext highlighter-rouge">setuptools</code></a> is an enhanced library building on <code class="language-plaintext highlighter-rouge">distutils</code> that introduced additional features like dependency management, easy installation, and entry points, becoming the de facto standard for Python packaging.</li>
    </ul>
  </li>
  <li><strong>2007: <code class="language-plaintext highlighter-rouge">virtualenv</code> (external)</strong>
    <ul>
      <li><a href="https://github.com/pypa/virtualenv"><code class="language-plaintext highlighter-rouge">virtualenv</code></a> is a third-party tool to create isolated Python environments, preventing conflicts between project dependencies by isolating them per project.</li>
    </ul>
  </li>
  <li><strong>2008: <code class="language-plaintext highlighter-rouge">pip</code></strong>
    <ul>
      <li><a href="https://github.com/pypa/pip"><code class="language-plaintext highlighter-rouge">pip</code></a> is a package installer for Python that greatly simplified the process of installing and managing Python packages from the Python Package Index (PyPI).</li>
    </ul>
  </li>
  <li><strong>2010: <code class="language-plaintext highlighter-rouge">requirements.txt</code> (widespread adoption)</strong>
    <ul>
      <li>The <a href="https://pip.pypa.io/en/stable/reference/requirements-file-format/"><code class="language-plaintext highlighter-rouge">requirements.txt</code></a> file is a plain text file format listing project dependencies, which became a standard way to specify and share the exact package versions needed for a Python project.</li>
    </ul>
  </li>
  <li><strong>2012: <code class="language-plaintext highlighter-rouge">conda</code></strong>
    <ul>
      <li><a href="https://docs.conda.io/projects/conda/en/stable/"><code class="language-plaintext highlighter-rouge">conda</code></a> is a cross-platform package and environment manager popular especially in the scientific Python community, able to manage non-Python dependencies as well.</li>
    </ul>

    <p><strong>2012: <code class="language-plaintext highlighter-rouge">venv</code> (stdlib)</strong></p>
    <ul>
      <li>The inclusion of <a href="https://docs.python.org/3/library/venv.html"><code class="language-plaintext highlighter-rouge">venv</code></a> in Python’s standard library to create lightweight virtual environments without requiring external tools.</li>
    </ul>
  </li>
  <li><strong>2017: <code class="language-plaintext highlighter-rouge">pyproject.toml</code> (PEP 518)</strong>
    <ul>
      <li>A new configuration file standard called <a href="https://peps.python.org/pep-0518/"><code class="language-plaintext highlighter-rouge">pyproject.toml</code> (PEP 518)</a> aimed at improving and standardizing Python project build metadata, allowing tools to declare build dependencies.</li>
    </ul>

    <p><strong>2017: <code class="language-plaintext highlighter-rouge">pipenv</code></strong></p>
    <ul>
      <li><a href="https://github.com/pypa/pipenv"><code class="language-plaintext highlighter-rouge">pipenv</code></a> is a tool combining package management and virtual environment management in one, focusing on ease of use and reproducible environments.</li>
    </ul>

    <p><strong>2017: <code class="language-plaintext highlighter-rouge">hatch</code></strong></p>
    <ul>
      <li><a href="https://github.com/pypa/hatch"><code class="language-plaintext highlighter-rouge">hatch</code></a> is a modern project manager and build tool focusing on simplicity, speed, and support for multiple Python versions and environments.</li>
    </ul>
  </li>
  <li><strong>2018: <code class="language-plaintext highlighter-rouge">poetry</code></strong>
    <ul>
      <li><a href="https://github.com/python-poetry/poetry"><code class="language-plaintext highlighter-rouge">poetry</code></a> is a comprehensive packaging and dependency management tool that uses <code class="language-plaintext highlighter-rouge">pyproject.toml</code>, aiming to simplify dependency resolution and publishing.</li>
    </ul>
  </li>
  <li><strong>2023: <code class="language-plaintext highlighter-rouge">uv</code></strong>
    <ul>
      <li><a href="https://github.com/astral-sh/uv"><code class="language-plaintext highlighter-rouge">uv</code></a> is a newer tool in the ecosystem (likely referring to a fast build or packaging tool, or a modern environment manager) reflecting ongoing innovation in Python packaging and environment management.</li>
    </ul>
  </li>
</ol>

<h2 id="where-are-packages-hosted">Where are packages hosted?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/pip_conda_pypi_forge.png" style="
        width: 60%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Python’s packaging ecosystem mainly revolves mostly around PyPI and Conda.
PyPI is the official repository for Python packages and is accessed through <code class="language-plaintext highlighter-rouge">pip</code>.
It handles pure Python packages well but struggles with packages that require non-Python dependencies or system libraries, which can make installation tricky across different platforms.</p>

<p>Conda is a package and environment manager that supports both Python and non-Python packages, making it popular in data science and scientific computing.
It simplifies managing complex dependencies but can be slower and sometimes inconsistent due to multiple package channels.
Choosing between PyPI and Conda often depends on whether you need pure Python packages or a more complete environment with system-level libraries.</p>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/conda_yield_pypi.png" style="
        width: 60%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Using PyPI and Conda together can be challenging because they manage packages and dependencies differently, which can lead to conflicts and unpredictable behavior.
Mixing installations from pip (PyPI) and Conda within the same environment may cause version mismatches, broken dependencies, or duplicated packages.
Additionally, Conda’s environment resolver and PyPI’s package manager don’t always communicate well, making it hard to maintain reproducible and stable environments when crossing between the two.
This complexity often forces developers to carefully manage and isolate environments or choose one system over the other to avoid issues.</p>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/pypi_to_forge.png" style="
        width: 60%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>A common approach in Python packaging is to first develop and release a package to PyPI, where it can be easily shared and installed using pip. 
Once the package is stable and widely used, it may be packaged for Conda—often via the community-maintained conda-forge channel—to support users who rely on Conda environments, especially in scientific computing. 
This pipeline allows developers to reach the broadest audience while maintaining compatibility with both ecosystems.</p>

<h2 id="how-are-python-packages-distributed">How are Python packages distributed?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/python_distribution_formats.png" style="
        width: 60%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>In Python packaging, <a href="https://packaging.python.org/en/latest/specifications/section-distribution-formats/">package distributions</a> are the artifacts that users download and install to use a Python project—most commonly as <code class="language-plaintext highlighter-rouge">.whl</code> (wheel) or <code class="language-plaintext highlighter-rouge">.tar.gz</code> (source distribution) files.
A wheel is a pre-built, binary package format (<code class="language-plaintext highlighter-rouge">.whl</code>) designed for fast installation without needing to compile code (note: a <code class="language-plaintext highlighter-rouge">.whl</code> is really a <code class="language-plaintext highlighter-rouge">.zip</code> so you can unzip it to take a look at the contents).
It’s the preferred format for most users and is what tools like pip look for first on PyPI.
In contrast, a source distribution (<code class="language-plaintext highlighter-rouge">.tar.gz</code>, often called an <code class="language-plaintext highlighter-rouge">sdist</code>) contains the raw source code and build instructions; installing from it may require compiling extensions or resolving more complex dependencies. Source distributions are essential for reproducibility, auditing, and as a fallback when no wheel is available for the user’s platform.</p>

<p>Conda packages, on the other hand, belong to a separate ecosystem built around the Conda package manager. A <a href="https://docs.conda.io/projects/conda-build/en/stable/resources/package-spec.html">Conda package</a> is a <code class="language-plaintext highlighter-rouge">.tar.bz2</code> or <code class="language-plaintext highlighter-rouge">.conda</code> archive that includes not just Python code, but also compiled binaries and system-level dependencies.
This makes Conda particularly useful for scientific computing, where packages often require compiled C/C++/Fortran libraries.
Unlike wheels, Conda packages are not tied to Python’s internal packaging standards - they’re built using Conda-specific metadata and managed by Conda environments.
While PyPI and pip dominate general-purpose Python packaging, the Conda ecosystem provides a more holistic, environment-based approach—at the cost of being somewhat siloed and less compatible with pure Python tools.</p>

<p>These files are typically uploaded using specific application programming interfaces (API&#8217;s) to PyPI, conda-forge, or other similar locations.</p>

<h2 id="uv-overview"><code class="language-plaintext highlighter-rouge">uv</code> overview</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/uv_magnifying_glass.png" style="
        width: 25%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Below we&#8217;ll provide a quick overview of using <code class="language-plaintext highlighter-rouge">uv</code> to accomplish various environment management and packaging tasks.</p>

<h3 id="installing">Installing</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LsSf</span> https://astral.sh/uv/install.sh | sh
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">uv</code> can be installed using a curl reference to a script for your local system.
Afterwards, <code class="language-plaintext highlighter-rouge">uv</code> becomes a CLI command you may use through your terminal session.
See the <a href="https://docs.astral.sh/uv/getting-started/installation/">installation documentation</a> for more information.</p>

<h3 id="intitializing-a-project">Intitializing a project</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># create a dir for the project and cd into it</span>
<span class="nb">mkdir </span>project_name <span class="o">&amp;&amp;</span> <span class="nb">cd </span>project_name
<span class="c"># initialize a uv project within the dir</span>
uv init <span class="nt">--package</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">uv</code> provides a nice initializer which can give you boilerplate files to work from.
We suggest using the <code class="language-plaintext highlighter-rouge">--package</code> structure which helps you create a Pythonic package and uses best practices.
Afterwards, the structure will look like the following:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tree ./
<span class="c"># tree output</span>
./
├── pyproject.toml
├── README.md
└── src
    └── project_name
        └── __init__.py

3 directories, 3 files
</code></pre></div></div>

<p>Let&#8217;s break down this file structure so we know what we&#8217;re working with:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pyproject.toml</code>: This file includes project metadata, configuration data, and (eventually) package dependency specifications.</li>
  <li><code class="language-plaintext highlighter-rouge">README.md</code>: This file is often used to help introduce projects and talk about the &#8220;what&#8221;, &#8220;why&#8221;, and &#8220;how&#8221; at a high level. It helps users get acquainted with what the project focuses on.</li>
  <li><code class="language-plaintext highlighter-rouge">src</code>: This directory is becoming standard practice for all source code within Python projects. It helps distinguish from documentation and &#8220;non-production&#8221; code.</li>
  <li><code class="language-plaintext highlighter-rouge">src/project_name</code>: This directory is typically used to house a Python &#8220;package&#8221; (or a collection of Python modules, a.k.a <code class="language-plaintext highlighter-rouge">.py</code> files).</li>
  <li><code class="language-plaintext highlighter-rouge">src/project_name/__init__.py</code>: This optional file is used to help initialize a Python project when it&#8217;s imported. It typically will include imports to specific public-facing Python objects you wish to share through the work. It also may configure the project.</li>
</ul>

<h3 id="adding-dependencies-with-uv">Adding dependencies with <code class="language-plaintext highlighter-rouge">uv</code></h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># add a dependency to the project</span>
uv add cowsay

<span class="c"># add a dependency to a "dev" dependency group for the project</span>
uv add pytest <span class="nt">--group</span> dev
</code></pre></div></div>

<p>We can add external dependencies to the project using the <code class="language-plaintext highlighter-rouge">uv add</code> command.
<code class="language-plaintext highlighter-rouge">uv</code> enables you to leverage dependency groups which are a way to distinguish between &#8220;production&#8221; dependencies and &#8220;development&#8221; dependencies.
For example, we might want to include <code class="language-plaintext highlighter-rouge">pytest</code> for software testing during development of the project so we could add it to the <code class="language-plaintext highlighter-rouge">dev</code> group (we likely won&#8217;t need <code class="language-plaintext highlighter-rouge">pytest</code> for the production code).
This helps keep the production dependencies light by only including the necessary packages if someone uses non-development work from the project.
Using <code class="language-plaintext highlighter-rouge">uv add</code> (or similarly, <code class="language-plaintext highlighter-rouge">uv sync</code>, which updates the environment) also automatically creates a <code class="language-plaintext highlighter-rouge">uv.lock</code> lockfile, which is important for consistent environment mangement.</p>

<h4 id="lockfiles-and-reproducibility">Lockfiles and reproducibility</h4>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/lockfile_for_reproducibility.png" style="
        width: 40%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Many modern Python environment managers automatically make use of lockfiles.
Lockfiles capture the exact dependency graph and package versions, ensuring that environments can be recreated byte-for-byte.
Be sure to check out our <a href="https://cu-dbmi.github.io/set-website/2024/02/20/Navigating-Dependency-Chaos-with-Lockfiles.html">in-depth blog post on lockfiles</a> for more information.
<code class="language-plaintext highlighter-rouge">uv</code> generates a <a href="https://docs.astral.sh/uv/concepts/projects/layout/#the-lockfile"><code class="language-plaintext highlighter-rouge">uv.lock</code> file</a> automatically, giving you:</p>

<ul>
  <li><strong>Deterministic installs</strong>: No surprises when sharing environments.</li>
  <li><strong>Auditability</strong>: Pinpoint which package versions are in use.</li>
  <li><strong>Collaboration</strong>: Team members and CI pipelines use the same environment.</li>
</ul>

<p><a href="https://peps.python.org/pep-0751/">PEP 751</a> introduces some standardization for Python lockfiles (<code class="language-plaintext highlighter-rouge">pylock.toml</code>) but many tools have not yet adopted this standard.
<code class="language-plaintext highlighter-rouge">uv</code>&#8217;s lockfile data cannot yet be fully expressed in <code class="language-plaintext highlighter-rouge">pylock.toml</code> files and as a result it still depends on <code class="language-plaintext highlighter-rouge">uv.lock</code> files.
It&#8217;s like that the Python standard for lockfiles will evolve over time and could eventually converge (meaning you&#8217;d be able to use multiple tools with the same lockfile).</p>

<h3 id="processing-code-through-uv-environments">Processing code through <code class="language-plaintext highlighter-rouge">uv</code> environments</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># run the boilerplate code through the uv environment</span>
<span class="c"># note: the `python -c` command flag executes inline code.</span>
uv run python <span class="nt">-c</span> <span class="s2">"import project_name; project_name.main()"</span>

<span class="c"># run pytest through the uv environment</span>
uv run pytest
</code></pre></div></div>

<p>When we want to process code through the <code class="language-plaintext highlighter-rouge">uv</code> environment we can use the <code class="language-plaintext highlighter-rouge">uv run</code> command.
If you&#8217;re used to using <code class="language-plaintext highlighter-rouge">conda</code> environments this is akin to <code class="language-plaintext highlighter-rouge">conda run -n env_name python</code>.
Note: <code class="language-plaintext highlighter-rouge">uv</code> does not enable you to activate or &#8220;enter into&#8221; an implicit shell for the environement like <code class="language-plaintext highlighter-rouge">conda activate</code>.
Instead, <code class="language-plaintext highlighter-rouge">uv</code> uses declarative syntax to ensure the command-line interface to the environment is explicit.</p>

<p>When working with other projects you might also need to run an <code class="language-plaintext highlighter-rouge">install</code> command in order to have access to the environment.
<code class="language-plaintext highlighter-rouge">uv</code> skips this step and automatically will install the environment on issuing a <code class="language-plaintext highlighter-rouge">uv run</code> (there is no <code class="language-plaintext highlighter-rouge">uv install</code> command).</p>

<p>When we use <code class="language-plaintext highlighter-rouge">uv run</code> several things happen:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">uv</code> will attempt to fetch a system or remote version of Python as stipulated in the <code class="language-plaintext highlighter-rouge">pyproject.toml</code> file (or make a guess at a version of Python to use).</li>
  <li><code class="language-plaintext highlighter-rouge">uv</code> will install or update an ephemeral virtual environment under a <code class="language-plaintext highlighter-rouge">~/.venv</code> directory (and use this environment to execute the process).</li>
</ul>

<h3 id="building-python-packages-for-distribution">Building Python packages for distribution</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># build a package for distribution</span>
uv build
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">uv</code> provides a build system which enables you to build packages for distribution through the command <code class="language-plaintext highlighter-rouge">uv build</code>.
By default it creates Pythonic <code class="language-plaintext highlighter-rouge">.whl</code> and <code class="language-plaintext highlighter-rouge">.tar.gz</code> formats that are common to PyPI.
Note that you still have to upload these through other means in order for them to be hosted on common platforms like PyPI.
We recommend using the <a href="https://docs.pypi.org/trusted-publishers/">Trusted Publisher</a> method for publishing your packages once readied, which takes advantage of GitHub Actions or similar continuous integration / continuous deployment (CI/CD) tooling.</p>

<div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[build-system]</span>
<span class="py">build-backend</span> <span class="p">=</span> <span class="s">"setuptools.build_meta"</span>
<span class="py">requires</span> <span class="p">=</span> <span class="p">[</span> <span class="py">"setuptools&gt;</span><span class="p">=</span><span class="mi">64</span><span class="s">", "</span><span class="py">setuptools-scm&gt;</span><span class="p">=</span><span class="mi">8</span><span class="s">" ]</span><span class="err">
</span></code></pre></div></div>

<p>Note that you can change your build backends within the <code class="language-plaintext highlighter-rouge">pyproject.toml</code> configuration (instead of using <code class="language-plaintext highlighter-rouge">uv-build</code> by default).
For example, if you wanted to use <code class="language-plaintext highlighter-rouge">setuptools</code> you could stipulate something like the following in your <code class="language-plaintext highlighter-rouge">pyproject.toml</code> file instead.
This can assist with areas where you may like to use dynamic versioning for your work through projects like <a href="https://setuptools-scm.readthedocs.io/en/latest/usage/"><code class="language-plaintext highlighter-rouge">setuptools-scm</code></a>.</p>

<h2 id="migrating-existing-environments-to-uv">Migrating existing environments to <code class="language-plaintext highlighter-rouge">uv</code></h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/migrate-to-uv.png" style="
        width: 60%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Reading this are you thinking you might want to move your project environment management to <code class="language-plaintext highlighter-rouge">uv</code> but sweating the idea that it will be complicated?
For users looking to migrate existing environments to <code class="language-plaintext highlighter-rouge">uv</code>, tools like <a href="https://github.com/mkniewallner/migrate-to-uv"><code class="language-plaintext highlighter-rouge">migrate-to-uv</code></a> provide a transition path by converting existing <code class="language-plaintext highlighter-rouge">requirements.txt</code> or, for example, Poetry-based <code class="language-plaintext highlighter-rouge">pyproject.toml</code> files.
This can provide a streamlined and low-cost way to transition projects over to <code class="language-plaintext highlighter-rouge">uv</code>.</p>

<h2 id="conclusion">Conclusion</h2>

<blockquote>
  <p>“The best tool is the one you don’t have to think about using.” - common adage</p>
</blockquote>

<p><code class="language-plaintext highlighter-rouge">uv</code> from Astral offers research software engineers a fast, portable, and standards‑compliant environment manager that meets or exceeds the capabilities of existing tools.
By leveraging native Python packaging, robust lockfiles, and seamless Jupyter support, uv simplifies reproducible workflows and accelerates development.</p>]]></content><author><name>dave-bunten</name></author><category term="environment-management" /><category term="uv" /><category term="python" /><category term="reproducibility" /><category term="packaging" /><summary type="html"><![CDATA[Introducing uv: A Fast, Portable Python Environment Manager]]></summary></entry><entry><title type="html">Understanding Object Storage: A Guide for Research Software Development</title><link href="/set-website/preview/pr-46/2025/05/13/Understanding-Object-Storage.html" rel="alternate" type="text/html" title="Understanding Object Storage: A Guide for Research Software Development" /><published>2025-05-13T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2025/05/13/Understanding-Object-Storage</id><content type="html" xml:base="/set-website/preview/pr-46/2025/05/13/Understanding-Object-Storage.html"><![CDATA[<h1 id="understanding-object-storage-a-guide-for-research-software-development">Understanding Object Storage: A Guide for Research Software Development</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Object storage enables flexible, scalable, and metadata-rich access to research data in modern computing ecosystems.">
    <img src="/set-website/preview/pr-46/images/files-and-bucket.png" style="
        width: 40%;
        max-height: unset;
      " alt="Object storage enables flexible, scalable, and metadata-rich access to research data in modern computing ecosystems." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Object storage enables flexible, scalable, and metadata-rich access to research data in modern computing ecosystems.

    </figcaption>
  
</figure>

<!-- excerpt start -->
<p><strong>Managing large-scale scientific data is a defining challenge of modern research.</strong>
With datasets regularly exceeding gigabytes—or even terabytes—in size, researchers require scalable, cost-effective, and reliable storage infrastructure.</p>

<p><strong>Object storage offers a flexible alternative to traditional filesystems.</strong>
It supports high-throughput access, structured metadata, and distributed scaling, making it a foundational tool in research computing, reproducible science, and FAIR data practices.</p>

<p>In this article, we’ll trace the evolution of object storage (also sometimes referred to as &#8220;S3&#8221;, &#8220;storage buckets&#8221;, or &#8220;object stores&#8221;), explain its design principles, survey current platforms, and walk through a hands-on example using the open-source <a href="https://min.io/">MinIO</a> tool.
<!-- excerpt end --></p>

<h2 id="a-brief-history-of-object-storage">A brief history of object storage</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Object storage has roots in scientific research and helped build a foundation for later systems like AWS S3. Image credit: Meyer, Franz Sales, 1849 https: commons.wikimedia.org wiki File:Handbook of ornament; a grammar of art, industrial and architectural designing in all its branches, for practical as well as theoretical use 1900 14597942407 .jpg cropped">
    <img src="/set-website/preview/pr-46/images/historical-buckets.png" style="
        width: 40%;
        max-height: unset;
      " alt="Object storage has roots in scientific research and helped build a foundation for later systems like AWS S3. Image credit: Meyer, Franz Sales, 1849 https: commons.wikimedia.org wiki File:Handbook of ornament; a grammar of art, industrial and architectural designing in all its branches, for practical as well as theoretical use 1900 14597942407 .jpg cropped" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Object storage has roots in scientific research and helped build a foundation for later systems like AWS S3. (Image credit: <a href="https://commons.wikimedia.org/wiki/File:Handbook_of_ornament;_a_grammar_of_art,_industrial_and_architectural_designing_in_all_its_branches,_for_practical_as_well_as_theoretical_use_(1900)_(14597942407).jpg">Meyer, Franz Sales, 1849</a> (cropped))

    </figcaption>
  
</figure>

<p>Traditional storage systems relied on block storage (used by hard drives) and file storage (used by operating systems).
While effective for early computing, these models struggled to scale with the demands of scientific data and cloud-native applications.</p>

<p>Object storage originated in the research community to address these challenges.
In the late 1990s, the NASD project at Carnegie Mellon and HP Labs introduced the idea of storing data as self-contained objects with rich metadata—decoupling data access from file hierarchies (<a href="https://dl.acm.org/doi/10.1145/384265.291029">Gibson et al., 1998</a>).</p>

<p>In the early 2000s, the open-source Ceph project (from UCSC) introduced the now-famous CRUSH algorithm to distribute data without centralized metadata bottlenecks (<a href="https://dl.acm.org/doi/10.5555/1298455.1298485">Weil et al., 2006</a>).</p>

<p>Amazon S3 brought these ideas to a global audience in 2006, offering a scalable, HTTP-accessible object store with an API-driven model that became a standard for cloud and scientific applications (<a href="https://aws.amazon.com/blogs/aws/amazon_s3/">Amazon S3 launch blog post</a>).</p>

<p>Unlike file systems, object stores provide:</p>

<ul>
  <li>A flat namespace with key-based access</li>
  <li>Rich, customizable metadata</li>
  <li>Scalable, distributed architecture</li>
</ul>

<p>These qualities make object storage essential for managing large, unstructured, and reproducible scientific datasets.</p>

<h2 id="why-use-object-storage-for-research">Why use object storage for research?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Scientific research can benefit from the use of object storage for a wide variety of data.">
    <img src="/set-website/preview/pr-46/images/science-bucket.png" style="
        width: 40%;
        max-height: unset;
      " alt="Scientific research can benefit from the use of object storage for a wide variety of data." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Scientific research can benefit from the use of object storage for a wide variety of data.

    </figcaption>
  
</figure>

<p>Object storage is not just a buzzword.
It enables capabilities increasingly vital to modern research:</p>

<ul>
  <li><strong>Scalability</strong>: Stores billions of files with virtually no performance degradation.</li>
  <li><strong>Flexibility</strong>: Ideal for unstructured data (images, JSON, audio, NetCDF, Parquet, etc.).</li>
  <li><strong>Metadata-rich</strong>: Stores metadata alongside objects, useful for provenance, reproducibility, and FAIR data principles (<a href="https://doi.org/10.1038/sdata.2016.18">Wilkinson et al., 2016</a>).</li>
  <li><strong>Cloud-native</strong>: Compatible with public cloud platforms and on-premises deployments.</li>
  <li><strong>HTTP-accessible</strong>: Allows sharing, versioning, and integration with APIs and remote workflows.</li>
</ul>

<p>Traditionally seen as a passive place to &#8220;put files,&#8221; object storage is often now being used as a primary data substrate—functioning more like a database than just a dumping ground.
This shift aligns closely with principles from the Composable Data Management System Manifesto (<a href="https://dl.acm.org/doi/10.14778/3603581.3603604">Pedreira et. al, 2023</a>), which advocates for modular, interoperable, and storage-agnostic data infrastructure.</p>

<p>Generally, consider use cases like:</p>

<ul>
  <li>Long-term archiving of large-scale microscopy datasets.</li>
  <li>Sharing reproducible analysis results using structured metadata.</li>
  <li>Automating pipelines that read and write from shared storage</li>
</ul>

<p>In research, where <strong>data integrity, sharing, and sustainability</strong> are paramount, object storage provides a modern backbone.</p>

<h2 id="common-platforms-and-ecosystem">Common platforms and ecosystem</h2>

<p>Below are some popular object storage platforms used in research and industry:</p>

<table>
  <thead>
    <tr>
      <th>Platform</th>
      <th>Description</th>
      <th>Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**[Amazon S3](https://aws.amazon.com/s3/)**</td>
      <td>The original commercial object store.</td>
      <td>Commercial</td>
    </tr>
    <tr>
      <td>**[Google Cloud Storage](https://cloud.google.com/storage)**</td>
      <td>Integrated with Google Cloud ecosystem.</td>
      <td>Commercial</td>
    </tr>
    <tr>
      <td>**[Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs)**</td>
      <td>Microsoft’s cloud object store.</td>
      <td>Commercial</td>
    </tr>
    <tr>
      <td>**[MinIO](https://min.io/)**</td>
      <td>High-performance, S3-compatible OSS.</td>
      <td>Open Source</td>
    </tr>
    <tr>
      <td>**[Ceph](https://ceph.io/)**</td>
      <td>Distributed object (and block/file) system.</td>
      <td>Open Source</td>
    </tr>
    <tr>
      <td>**[Wasabi](https://wasabi.com/cloud-object-storage)**</td>
      <td>Cost-effective S3-compatible storage.</td>
      <td>Commercial</td>
    </tr>
    <tr>
      <td>**[OpenStack Swift](https://docs.openstack.org/swift/latest/)**</td>
      <td>Open-source cloud platform component.</td>
      <td>Open Source</td>
    </tr>
  </tbody>
</table>

<p>In academic environments, <strong>MinIO</strong> and <strong>Ceph</strong> are frequently used for institutional deployments that must remain on-premises or comply with specific data governance needs.</p>

<h2 id="how-object-storage-works">How object storage works</h2>

<figure class="figure">
  <a class="figure-image" aria-label="An object store maps keys to data and metadata using a flat namespace, ideal for scalable distributed systems.">
    <img src="/set-website/preview/pr-46/images/object-storage-concepts.png" style="
        width: 60%;
        max-height: unset;
      " alt="An object store maps keys to data and metadata using a flat namespace, ideal for scalable distributed systems." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      An object store maps keys to data and metadata using a flat namespace, ideal for scalable distributed systems.

    </figcaption>
  
</figure>

<p>Here are the core principles of object storage to help conceptualize common terms and how it works.</p>

<ul>
  <li><strong>Flat Namespace</strong>: No folder hierarchies; everything is accessed via a unique object key (similar to a URL path). Folders are typically simulated with &#8220;/&#8221; slashes to help unify how one may reference objects in correspondence with a filesystem.</li>
  <li><strong>Objects</strong>: Each unit of data includes the content, metadata, and a unique identifier (key).</li>
  <li><strong>Buckets</strong>: Logical containers for grouping objects (like folders, but flat). Generally a bucket is associated with one project.</li>
  <li><strong>APIs</strong>: Most object stores use HTTP REST APIs, often based on the <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html">Amazon S3 API</a>.</li>
  <li><strong>Versioning and Lifecycle</strong>: Objects can be versioned and automatically expired or archived.</li>
  <li><strong>Event Notification</strong>: Some systems emit events (e.g., via webhooks or queues) when new data is written—ideal for automation pipelines.</li>
</ul>

<h2 id="demo-using-minio-for-object-storage-data">Demo: Using MinIO for object storage data</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/object-storage-demo.png" style="
        width: 40%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Let’s walk through how to use <a href="https://min.io">MinIO</a> to create and interact with object storage on your local system.
MinIO is lightweight, open source, and provides an S3-compatible interface, making it nice for development and reproducible demos.</p>

<h3 id="step-1-install-minio">Step 1: Install MinIO</h3>

<p>You can install MinIO locally via Docker:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-p</span> 9000:9000 <span class="nt">-p</span> 9001:9001 <span class="se">\</span>
  <span class="nt">-e</span> <span class="s2">"MINIO_ROOT_USER=minioadmin"</span> <span class="se">\</span>
  <span class="nt">-e</span> <span class="s2">"MINIO_ROOT_PASSWORD=minioadmin"</span> <span class="se">\</span>
  quay.io/minio/minio server /data <span class="nt">--console-address</span> <span class="s2">":9001"</span>
</code></pre></div></div>

<p>Access the web UI at <a href="http://localhost:9001">http://localhost:9001</a> using the above credentials.</p>

<h3 id="step-2-upload-a-file">Step 2: Upload a file</h3>

<p>You can interact with MinIO using the official <a href="https://min.io/docs/minio/linux/reference/minio-mc.html"><code class="language-plaintext highlighter-rouge">mc</code></a> client:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># install client</span>
brew <span class="nb">install </span>minio/stable/mc  <span class="c"># or use curl/wget for Linux</span>

<span class="c"># configure client</span>
mc <span class="nb">alias set local </span>http://localhost:9000 minioadmin minioadmin

<span class="c"># create a bucket</span>
mc mb <span class="nb">local</span>/research-data

<span class="c"># create a file</span>
<span class="nb">echo</span> <span class="s2">"1,2,3"</span> <span class="o">&gt;</span> dataset.csv

<span class="c"># upload a file</span>
mc <span class="nb">cp </span>dataset.csv <span class="nb">local</span>/research-data
</code></pre></div></div>

<h3 id="step-3-access-via-python">Step 3: Access via Python</h3>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/object-storage-python.png" style="
        width: 40%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>You can also use the official MinIO Python client to interact with your object storage server:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>minio
</code></pre></div></div>

<p>Then, use the client to connect and list objects:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">minio</span> <span class="kn">import</span> <span class="n">Minio</span>

<span class="c1"># Initialize client
</span><span class="n">client</span> <span class="o">=</span> <span class="n">Minio</span><span class="p">(</span>
    <span class="s">"localhost:9000"</span><span class="p">,</span>
    <span class="n">access_key</span><span class="o">=</span><span class="s">"minioadmin"</span><span class="p">,</span>
    <span class="n">secret_key</span><span class="o">=</span><span class="s">"minioadmin"</span><span class="p">,</span>
    <span class="n">secure</span><span class="o">=</span><span class="bp">False</span>  <span class="c1"># Use True if running over HTTPS
</span><span class="p">)</span>

<span class="c1"># List objects in a bucket
</span><span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">client</span><span class="p">.</span><span class="n">list_objects</span><span class="p">(</span><span class="s">"research-data"</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">obj</span><span class="p">.</span><span class="n">object_name</span><span class="p">)</span>
</code></pre></div></div>

<p>This approach is lightweight, straightforward, and ideal for working directly with MinIO in local or institutional deployments.</p>

<h2 id="streaming-data-from-object-storage-with-minio-pandas-polars-or-duckdb">Streaming Data from Object Storage with MinIO, Pandas, Polars, or DuckDB</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/pandas-duckdb-and-polars.png" style="
        width: 40%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>In composable data workflows, streaming data directly from object storage is increasingly common.
Instead of downloading full files to local disk, tools like Pandas and DuckDB can read from object storage streams—reducing I/O overhead and enabling efficient in situ analytics.
Tools like <a href="https://github.com/fsspec/filesystem_spec">fsspec</a> can abstract access across many storage backends—including S3 and GCS—making it easier to build storage-agnostic workflows.</p>

<h3 id="example-streaming-a-csv-into-pandas">Example: Streaming a CSV into Pandas</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Stream data from the S3 API (MinIO) into a Pandas DataFrame
</span><span class="n">df_s3</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s">"s3://my-bucket/data.csv"</span><span class="p">,</span>
    <span class="n">storage_options</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"key"</span><span class="p">:</span> <span class="s">"minioadmin"</span><span class="p">,</span>
        <span class="s">"secret"</span><span class="p">:</span> <span class="s">"minioadmin"</span><span class="p">,</span>
        <span class="s">"client_kwargs"</span><span class="p">:</span> <span class="p">{</span><span class="s">"endpoint_url"</span><span class="p">:</span> <span class="s">"http://localhost:9000"</span><span class="p">},</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="example-streaming-a-csv-into-polars">Example: Streaming a CSV into Polars</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="n">pl</span>

<span class="c1"># Stream data from the S3 API (MinIO) into a Polars DataFrame
</span><span class="n">df_s3</span> <span class="o">=</span> <span class="n">pl</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s">"s3://my-bucket/data.csv"</span><span class="p">,</span>
    <span class="n">storage_options</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"key"</span><span class="p">:</span> <span class="s">"minioadmin"</span><span class="p">,</span>
        <span class="s">"secret"</span><span class="p">:</span> <span class="s">"minioadmin"</span><span class="p">,</span>
        <span class="s">"client_kwargs"</span><span class="p">:</span> <span class="p">{</span><span class="s">"endpoint_url"</span><span class="p">:</span> <span class="s">"http://localhost:9000"</span><span class="p">},</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="example-streaming-a-csv-into-duckdb">Example: Streaming a CSV into DuckDB</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">duckdb</span>

<span class="k">with</span> <span class="n">duckdb</span><span class="p">.</span><span class="n">connect</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb</span><span class="p">:</span>
    <span class="c1"># Stream data from the S3 API (MinIO)
</span>    <span class="c1"># from DuckDB into Pandas DataFrame
</span>    <span class="n">df</span> <span class="o">=</span> <span class="n">ddb</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="sa">f</span><span class="s">"""
        /* install httpfs for duckdb */
        INSTALL httpfs;
        LOAD httpfs;
        
        /* add a custom secret for access to endpoint */
        CREATE SECRET (
            TYPE s3,
            KEY_ID 'minioadmin',
            SECRET 'minioadmin',
            ENDPOINT 'localhost:9000'
        );
        
        /* perform selection on the file */
        SELECT * FROM read_csv('s3://my-bucket/data.csv');
        """</span>
    <span class="p">).</span><span class="n">df</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="s3-compatible-object-storage-case-study-dell-powerscale-isilon">S3-compatible object storage case study: Dell PowerScale (Isilon)</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/cloud-or-onprem.png" style="
        width: 40%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Some research institutions like the University of Colorado Anschutz have adopted <strong>Dell PowerScale (Isilon)</strong> for file and object storage (<a href="https://www.cuanschutz.edu/offices/office-of-information-technology/tools-services/detail-page/storage-servers-and-backups">CU Anschutz Storage Options</a>).
This adds some convenience due to its ability to serve both traditional file-based workloads (i.e. filemounts) and modern S3-API based pipelines like those described above.</p>

<p>Isilon allows researchers to treat data stored on the NAS as S3-compatible objects, enabling seamless integration with cloud-native tools and streaming workflows—even in strictly on-premises environments.</p>

<h3 id="-cost-savings-isilon-object-storage-vs-cloud-storage-awsgcp">💸 Cost savings: Isilon object storage vs. cloud storage (AWS/GCP)</h3>

<p>Cloud object storage platforms like <strong>AWS S3</strong> and <strong>Google Cloud Storage (GCS)</strong> offer great scalability, but they often come with <strong>ongoing costs that grow with usage</strong>, especially due to <strong>egress fees</strong> (i.e., data leaving the cloud) or <strong>operation</strong> charges (when you make changes to objects).</p>

<p>In contrast, <strong>on-premises object storage systems</strong>—like <strong>Dell Isilon</strong>—can provide substantial long-term savings for research institutions that already maintain storage infrastructure.
Similar to cloud-provider object storage systems, you can still use S3-like API&#8217;s through tools like MinIO with Isilon.</p>

<h3 id="-storage-cost-comparison-approximate-per-gb-per-month">💾 Storage cost comparison (approximate, per GB per month)</h3>

<p>Object storage providers generally charge a flat fee for the amount of data stored within their platform by month.
Cloud providers typically charge varying rates by &#8220;storage class&#8221; which stipulate how frequently you will access the data (lower cost storage classes often have higher egress or outgoing tranfer costs).
For the sake of an example below we use &#8220;standard&#8221; or default storage classes below.
See below for some examples.</p>

<table>
  <thead>
    <tr>
      <th>Storage Tier</th>
      <th>Storage Cost (USD/GB/mo)</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Dell Isilon**</td>
      <td>$0.016</td>
      <td>Based on [CU Anschutz Rates](https://www.cuanschutz.edu/offices/office-of-information-technology/get-help/billing-and-rates#ac-backup-and-storage-0)</td>
    </tr>
    <tr>
      <td>**AWS S3 Standard (AWS S3)**</td>
      <td>$0.023</td>
      <td>[S3 Standard - Pricing Link](https://aws.amazon.com/s3/pricing/)</td>
    </tr>
    <tr>
      <td>**Google Cloud Storage (GCS)**</td>
      <td>$0.020</td>
      <td>[Standard storage - Pricing Link](https://cloud.google.com/storage/pricing)</td>
    </tr>
  </tbody>
</table>

<h3 id="-data-transfer-cost-egress">📤 Data transfer cost (Egress)</h3>

<p>Object storage providers often charge for &#8220;egress&#8221;, or data transfers to a location outside their platforms.
These charges may seem small at first but can add up over time.
It&#8217;s also important to note &#8220;ingress&#8221;, or data transferred into an object storage provider&#8217;s bucket, may also have distinct cost implications (these are often less than egress).
Note: Isilon at CU Anschutz is currently limited to virtual private network (VPN) or campus-based networks for egress and ingress.</p>

<table>
  <thead>
    <tr>
      <th>Provider</th>
      <th>Egress (Download) Cost Per GB</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Dell Isilon**</td>
      <td>$0.00</td>
      <td>No per-byte charge for transfers for [CU Anschutz Rates](https://www.cuanschutz.edu/offices/office-of-information-technology/get-help/billing-and-rates#ac-backup-and-storage-0)</td>
    </tr>
    <tr>
      <td>**AWS S3**</td>
      <td>$0.09</td>
      <td>First 10 TB per month after 100GB free tier [Pricing Link](https://aws.amazon.com/s3/pricing/)</td>
    </tr>
    <tr>
      <td>**GCS**</td>
      <td>$0.12</td>
      <td>First TB per month [Pricing Link](https://cloud.google.com/storage/pricing)</td>
    </tr>
  </tbody>
</table>

<h3 id="an-example-scenario">An example scenario</h3>

<p>Some of the above numbers are difficult to contextualize without an example scenario.
Consider an example scenario where we have 500 GB stored for 6 months and where we download that 500 GB once per month.
Keep in mind these are estimations and don&#8217;t include additional other charges from cloud providers, tax, and other considerations.</p>

<table>
  <thead>
    <tr>
      <th>Provider</th>
      <th>Calculation</th>
      <th>Total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Dell Isilon**</td>
      <td><code class="language-plaintext highlighter-rouge">$0.016 * 500 GB * 6 Months (no additional cost for egress)</code></td>
      <td>$48.00</td>
    </tr>
    <tr>
      <td>**AWS S3**</td>
      <td><code class="language-plaintext highlighter-rouge">($0.023 * 500 GB * 6 Months) + ($0.09 * 400 GB * 6 Months)</code></td>
      <td>$285.00</td>
    </tr>
    <tr>
      <td>**GCS**</td>
      <td><code class="language-plaintext highlighter-rouge">($0.020 * 500 GB * 6 Months) + ($0.12 * 500 GB * 6 Months)</code></td>
      <td>$420.00</td>
    </tr>
  </tbody>
</table>

<h2 id="conclusion">Conclusion</h2>

<p>Object storage is a foundational technology for modern research computing. It allows research teams to scale data access, enable metadata-rich reproducibility, and bridge the gap between local experimentation and cloud workflows.</p>

<p>By learning how to use tools like MinIO and understanding the object storage model, research software developers can design more robust, future-proof, and <a href="https://en.wikipedia.org/wiki/FAIR_data">FAIR</a>-aligned systems for handling scientific data.</p>

<blockquote>
  <p><em>“Data is a precious thing and will last longer than the systems themselves.” - Tim Berners-Lee</em></p>
</blockquote>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li>Wilkinson, M. D., et al. (2016). <a href="https://doi.org/10.1038/sdata.2016.18">The FAIR Guiding Principles for scientific data management and stewardship</a>.</li>
  <li>MinIO Documentation: <a href="https://min.io/docs">https://min.io/docs</a></li>
  <li>AWS S3 API Reference: <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html">https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html</a></li>
  <li>GO FAIR Initiative: <a href="https://www.go-fair.org/">https://www.go-fair.org/</a></li>
</ul>]]></content><author><name>dave-bunten</name></author><category term="data-management" /><category term="object-storage" /><category term="reproducibility" /><category term="scientific-software" /><category term="s3" /><category term="data-streaming" /><summary type="html"><![CDATA[Understanding Object Storage: A Guide for Research Software Development]]></summary></entry><entry><title type="html">Testing Scientific Software: A Practical Guide for Developers</title><link href="/set-website/preview/pr-46/2024/09/25/Testing-Scientific-Software.html" rel="alternate" type="text/html" title="Testing Scientific Software: A Practical Guide for Developers" /><published>2024-09-25T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2024/09/25/Testing-Scientific-Software</id><content type="html" xml:base="/set-website/preview/pr-46/2024/09/25/Testing-Scientific-Software.html"><![CDATA[<h1 id="testing-scientific-software-a-practical-guide-for-developers">Testing Scientific Software: A Practical Guide for Developers</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Software testing helps us find bugs in our code which otherwise may go unseen.">
    <img src="/set-website/preview/pr-46/images/magnifying-glass-and-bugs.png" style="
        width: 40%;
        max-height: unset;
      " alt="Software testing helps us find bugs in our code which otherwise may go unseen." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Software testing helps us find bugs in our code which otherwise may go unseen.

    </figcaption>
  
</figure>

<!-- excerpt start -->
<p><strong>Scientific software plays a crucial role in research.</strong>
When your software is used to analyze data, simulate models, or derive scientific conclusions, ensuring its correctness becomes critical.
<strong>A small bug can have a significant impact on your results</strong>, potentially invalidating months of work, or worse, causing the retraction of published research (for example: <a href="https://www.science.org/doi/10.1126/science.314.5807.1856">see here</a>).
Fortunately, software testing can help minimize such risks, giving you more confidence in your code and a greater chance to catch issues early.</p>

<p>In this guide, we’ll walk through key types of software tests, practical advice for using popular testing tools like <code class="language-plaintext highlighter-rouge">pytest</code> and <code class="language-plaintext highlighter-rouge">doctest</code>, and how you can incorporate these into your scientific development workflow.
<!-- excerpt end --></p>

<h2 id="why-testing-matters-in-science">Why testing matters in science</h2>

<p>Imagine you’ve written a simulation that generates data based on a complex scientific model.
It works well under some conditions, but during peer review, a colleague finds a subtle bug.
This bug doesn&#8217;t affect small data sets but produces significant errors on larger simulations.
The consequences?
You have to revise your paper, and time is lost fixing code.
There&#8217;s also the possibility of bugs taking a long time to find (if ever) potentially leading to erroneous research.</p>

<p><strong>Consider: how can an audience know a software creates a reproducible outcome without  tests they can run and verify themselves?</strong>
Testing your software upfront ensures that potential errors are caught early and your scientific conclusions remain valid and robust.
This article covers how to write code which automates the process of testing your software.</p>

<p>You may already have tests in place which haven&#8217;t yet been automated.
If this is the case, consider integrating these with automated tools like those mentioned below to help create reproducible research software!</p>

<h2 id="production-code-vs-test-code">Production code vs test code</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Software testing often involves two distinct sections of production or application code alongside testing code.">
    <img src="/set-website/preview/pr-46/images/production-and-test-code.png" style="
        width: 50%;
        max-height: unset;
      " alt="Software testing often involves two distinct sections of production or application code alongside testing code." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Software testing often involves two distinct sections of production or application code alongside testing code.

    </figcaption>
  
</figure>

<p>When working with software testing principles it can be helpful to distinguish <strong>&#8220;production&#8221; or &#8220;application&#8221; code</strong> (code which provides some utility besides testing itself) from <strong>&#8220;test&#8221; code</strong> (code which will be used to test the production or application code).
These are often (but not always) stored in separate directories or components within the project.</p>

<h2 id="types-of-tests-for-scientific-software">Types of tests for scientific software</h2>

<p>In software development, tests are typically categorized into several types.
<strong>Each plays a unique role in ensuring your code functions as intended.</strong></p>

<figure class="figure">
  <a class="figure-image" aria-label="Unit tests focus on testing an isolated set of functionality within your code.">
    <img src="/set-website/preview/pr-46/images/unit-test-code.png" style="
        width: 50%;
        max-height: unset;
      " alt="Unit tests focus on testing an isolated set of functionality within your code." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Unit tests focus on testing an isolated set of functionality within your code.

    </figcaption>
  
</figure>

<ul>
  <li><strong>Unit tests</strong>: These validate small, isolated parts of your code, like functions or methods.
They are one of the most basic forms of testing but extremely valuable, ensuring the correctness of atomic units in your codebase.</li>
</ul>

<figure class="figure">
  <a class="figure-image" aria-label="Integration tests help ensure multiple software components act as expected together.">
    <img src="/set-website/preview/pr-46/images/integration-test-code.png" style="
        width: 50%;
        max-height: unset;
      " alt="Integration tests help ensure multiple software components act as expected together." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Integration tests help ensure multiple software components act as expected together.

    </figcaption>
  
</figure>

<ul>
  <li><strong>Integration tests</strong>: Once your units of code are tested individually, <strong>integration tests ensure software components work together</strong>.
This is especially important in scientific software where different models, algorithms, and data structures interact.</li>
</ul>

<figure class="figure">
  <a class="figure-image" aria-label="System or end-to-end tests might include those which check how external software interacts to form a cohesive output with your production code.">
    <img src="/set-website/preview/pr-46/images/system-test-code.png" style="
        width: 50%;
        max-height: unset;
      " alt="System or end-to-end tests might include those which check how external software interacts to form a cohesive output with your production code." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      System or end-to-end tests might include those which check how external software interacts to form a cohesive output with your production code.

    </figcaption>
  
</figure>

<ul>
  <li><strong>System / End-to-End tests</strong>: These check the software from a user’s perspective.
For scientific software, this often means running entire workflows or simulations to make sure that everything from data input to output runs smoothly.</li>
</ul>

<p>There are also many other different types of tests and testing philosophies which can be found here: <a href="https://en.wikipedia.org/wiki/Software_testing#Categorization">https://en.wikipedia.org/wiki/Software_testing#Categorization</a>.</p>

<h2 id="testing-in-python">Testing in Python</h2>

<p>Testing in Python is often performed using the built-in <a href="https://docs.python.org/3/library/unittest.html"><code class="language-plaintext highlighter-rouge">unittest</code></a> module or <a href="https://github.com/pytest-dev/pytest"><code class="language-plaintext highlighter-rouge">pytest</code></a> package.
There is also an additional built-in module, <a href="https://docs.python.org/3/library/doctest.html"><code class="language-plaintext highlighter-rouge">doctest</code></a>, which allows you to test whether statements run as expected within <a href="https://peps.python.org/pep-0257/#what-is-a-docstring">docstrings</a>.</p>

<p><a href="https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement"><code class="language-plaintext highlighter-rouge">assert</code> statements</a> are a common part of writing tests in Python.
We can use <code class="language-plaintext highlighter-rouge">assert</code> to determine the truthiness of certain output (see below for an example).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># we can use the assert statements to determine
# the truthiness (or lack thereof) of values.
</span><span class="k">assert</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">1</span>
<span class="c1"># returns True
</span><span class="k">assert</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span>
<span class="c1"># returns False
</span></code></pre></div></div>

<p>The following examples will be added to a demonstrational repository which can be found here: <a href="https://github.com/CU-DBMI/demo-python-software-testing">https://github.com/CU-DBMI/demo-python-software-testing</a></p>

<h2 id="introduction-to-pytest">Introduction to <code class="language-plaintext highlighter-rouge">pytest</code></h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/pytest.png" style="
        width: 30%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p><code class="language-plaintext highlighter-rouge">pytest</code> is one of the most popular testing frameworks in Python.
An advantage to using <code class="language-plaintext highlighter-rouge">pytest</code> is that it is widely used, includes many different <a href="https://docs.pytest.org/en/stable/reference/plugin_list.html">plugins</a> to extend functionality, and is relatively uncomplicated.</p>

<h3 id="getting-started-with-pytest">Getting started with <code class="language-plaintext highlighter-rouge">pytest</code></h3>

<p>Consider the following project tree structure representing directories and files which is common to <code class="language-plaintext highlighter-rouge">pytest</code> projects.
Note the <code class="language-plaintext highlighter-rouge">tests</code> directory, which includes code dedicated to testing the <code class="language-plaintext highlighter-rouge">package_name</code> package module.
<code class="language-plaintext highlighter-rouge">pytest</code> seeks to run test code with the prefix of <code class="language-plaintext highlighter-rouge">test_</code> under the <code class="language-plaintext highlighter-rouge">tests</code> directory.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>example_project
├── pyproject.toml
├── src
│   └── package_name
│       └── package_module.py
└── tests
    └── test_package_module.py
</code></pre></div></div>

<p>Just in case, make sure you install <code class="language-plaintext highlighter-rouge">pytest</code> into the project&#8217;s environment management:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use pip to install pytest into an existing environment</span>
pip <span class="nb">install </span>pytest

<span class="c"># or, add pytest to a poetry environment</span>
poetry add pytest
</code></pre></div></div>

<p>Assume we have a simple function within <code class="language-plaintext highlighter-rouge">package_module.py</code> which helps us understand whether a given integer is an even number.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">is_even</span><span class="p">(</span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="s">"""
    Determines if a number is even.

    An even number is divisible by 2 without a remainder.

    Args:
        number (int):
          The number to check.

    Returns:
        bool:
          True if the number is even, False if it is odd.
    """</span>
    <span class="k">return</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
</code></pre></div></div>

<p>Next, we could create a simple unit test within <code class="language-plaintext highlighter-rouge">test_package_module.py</code> for the <code class="language-plaintext highlighter-rouge">is_even()</code> function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_is_even</span><span class="p">():</span>
    <span class="c1"># assert that 2 is detected as an even number
</span>    <span class="k">assert</span> <span class="n">is_even</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<p>Once we have the test written, we can use the <code class="language-plaintext highlighter-rouge">pytest</code> command through our project environment</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># run the `pytest` command through your terminal</span>
pytest

<span class="c"># or, run `pytest` through a poetry environment</span>
poetry run pytest
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">pytest</code> will automatically find all files starting with test_ and run any functions inside them that start with test_.
It also produces concise output, helping you pinpoint errors quickly.
See below for an example of what the output might look like (we can see that the single test passed).</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>============== test session starts ===============
platform darwin -- Python 3.11.9, pytest-8.3.3,
pluggy-1.5.0
rootdir: /example_project
configfile: pyproject.toml
collected 1 item

tests/test_package_module.py .             [100%]

=============== 1 passed in 0.00s ================
</code></pre></div></div>

<h3 id="additional-pytest-features">Additional <code class="language-plaintext highlighter-rouge">pytest</code> features</h3>

<ul>
  <li><strong>Using temporary directories</strong>: <code class="language-plaintext highlighter-rouge">pytest</code> allows for the creation of <a href="https://docs.pytest.org/en/stable/how-to/tmp_path.html">temporary directories</a> where test data can be stored for each test run in isolation. This pattern can be helpful for times where you may need to generate and store test data for use among multiple tests.</li>
  <li><strong>Fixtures</strong>: Use <a href="https://docs.pytest.org/en/stable/explanation/fixtures.html"><code class="language-plaintext highlighter-rouge">pytest</code> fixtures</a> to set up any necessary preconditions for your tests (like loading test datasets).</li>
  <li><strong>Parameterization</strong>: If you need to test multiple inputs on the same function, <code class="language-plaintext highlighter-rouge">pytest</code> allows you to <a href="https://docs.pytest.org/en/stable/how-to/parametrize.html">parameterize</a> your tests, running the same test function with different values.</li>
</ul>

<h2 id="using-doctest-for-documentation-and-testing">Using <code class="language-plaintext highlighter-rouge">doctest</code> for documentation and testing</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/doctest.png" style="
        width: 30%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p><code class="language-plaintext highlighter-rouge">doctest</code> is another tool which can be used for testing.
It serves a dual purpose: it embeds tests directly in your documentation by using interactive examples in docstrings.
This can be a lightweight way to share testable functionality within the documentation for your code.
Be cautious however; <code class="language-plaintext highlighter-rouge">doctests</code> are not generally suitable for large or complex testing.</p>

<h3 id="writing-doctests">Writing doctests</h3>

<p>A <a href="https://docs.python.org/3/library/doctest.html"><code class="language-plaintext highlighter-rouge">doctest</code></a> is simply an example of using a function, placed in docstrings.
The general pattern follows Python interactive terminal input (denoted by <code class="language-plaintext highlighter-rouge">&gt;&gt;&gt;</code>) followed by the expected standard output (which sometimes may be truncated when dealing with large numbers or strings).</p>

<p>The <code class="language-plaintext highlighter-rouge">Examples</code> section of the docstring below demonstrates what a doctest for our earlier function might look like.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">is_even</span><span class="p">(</span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="s">"""
    Determines if a number is even.

    An even number is divisible by 2 without a remainder.

    Args:
        number (int):
            The number to check.

    Returns:
        bool:
            True if the number is even, False if it is odd.

    Examples:
        &gt;&gt;&gt; is_even(2)
        True
        &gt;&gt;&gt; is_even(3)
        False
    """</span>
    <span class="k">return</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
</code></pre></div></div>

<p>You can run always run doctests by adding the following to the same module which includes that code.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="c1"># run doctests within module
</span>    <span class="n">doctest</span><span class="p">.</span><span class="n">testmod</span><span class="p">()</span>
</code></pre></div></div>

<p>You also can run doctests through <code class="language-plaintext highlighter-rouge">pytest</code> by using the <code class="language-plaintext highlighter-rouge">--doctest-modules</code> command flag.
This can be helpful for areas where we don&#8217;t want to use the <a href="https://docs.python.org/3/library/__main__.html"><code class="language-plaintext highlighter-rouge">if __name__ == "__main__":</code> pattern</a>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># run the `pytest` command through your terminal</span>
pytest <span class="nt">--doctest-modules</span>

<span class="c"># or, run `pytest` through a poetry environment</span>
poetry run pytest <span class="nt">--doctest-modules</span>
</code></pre></div></div>

<p>The output might look like this:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>============== test session starts ===============
platform darwin -- Python 3.11.9, pytest-8.3.3,
pluggy-1.5.0
rootdir: /example_project
configfile: pyproject.toml
collected 2 items

src/package_name/module.py .               [ 50%]
tests/test_package_module.py .             [100%]

=============== 2 passed in 0.01s ================
</code></pre></div></div>

<p>This ensures that the examples in your documentation are always accurate and tested as part of your development cycle.</p>

<h2 id="using-hypothesis-for-testing">Using Hypothesis for testing</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/hypothesis.png" style="
        width: 30%;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p>Using <a href="https://github.com/HypothesisWorks/hypothesis">Hypothesis</a> for testing is a powerful approach for validating the correctness of scientific software.
By employing the Hypothesis library, you can perform property-based testing that generates test cases based on the characteristics of your input data.
This method allows you to test your functions against a broad range of inputs, ensuring that edge cases and unexpected scenarios are adequately handled.</p>

<h3 id="what-is-property-based-testing">What is property-based testing?</h3>

<p><a href="https://hypothesis.works/articles/what-is-property-based-testing/">Property-based testing</a> focuses on verifying that certain properties hold true for a wide range of input values, rather than checking specific outputs for predetermined inputs.
This contrasts with traditional example-based testing, where you specify the exact inputs and outputs (which can take time to imagine or construct individually).</p>

<h3 id="getting-started-with-hypothesis">Getting started with hypothesis</h3>

<p>To begin using Hypothesis in your project, you first need to install the library:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use pip to install hypothesis into an existing environment</span>
pip <span class="nb">install </span>hypothesis

<span class="c"># or, add hypothesis to a poetry environment</span>
poetry add hypothesis
</code></pre></div></div>

<p>Once installed, you can write tests that utilize its capabilities. 
With Hypothesis, you can write a test that asserts properties about even numbers. For instance, all even numbers should return True when passed to the is_even function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">hypothesis</span> <span class="kn">import</span> <span class="n">given</span>
<span class="kn">from</span> <span class="nn">hypothesis.strategies</span> <span class="kn">import</span> <span class="n">integers</span>

<span class="o">@</span><span class="n">given</span><span class="p">(</span><span class="n">integers</span><span class="p">())</span>
<span class="k">def</span> <span class="nf">test_is_even</span><span class="p">(</span><span class="n">number</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="using-the-hypothesis-ghostwriter">Using the Hypothesis ghostwriter</h3>

<p>Hypothesis also includes <a href="https://hypothesis.readthedocs.io/en/latest/ghostwriter.html">a &#8220;ghostwriter&#8221; CLI</a> which can infer how to write Hypothesis tests given an object from Python code.
This can help automate the process of writing your test code or provide inspiration for how to construct your Hypothesis tests.
<em>Caveat emptor</em>: please be sure to review any code generated by the Hypothesis ghostwriter (it may not capture useful tests or edge cases).</p>

<p>Given the example code from the above, we could ask the Hypothesis ghostwriter to construct a test for the <code class="language-plaintext highlighter-rouge">is_even()</code> function as follows:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># run the command from your activated Python environment</span>
hypothesis write package_name.module.is_even

<span class="c"># or, run through a poetry environment</span>
poetry run hypothesis write package_name.module.is_even
</code></pre></div></div>

<p>The output looks similar but not quite the same as the Hypothesis test we shared above.
Note that the test name implies and itself employs a technique called <a href="https://en.wikipedia.org/wiki/Fuzzing">fuzzing, or fuzz testing</a>, which is used to help determine where software might break.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This test code was written by the `hypothesis.extra.ghostwriter` module
# and is provided under the Creative Commons Zero public domain dedication.
</span>
<span class="kn">import</span> <span class="nn">package_name.module</span>
<span class="kn">from</span> <span class="nn">hypothesis</span> <span class="kn">import</span> <span class="n">given</span><span class="p">,</span> <span class="n">strategies</span> <span class="k">as</span> <span class="n">st</span>


<span class="o">@</span><span class="n">given</span><span class="p">(</span><span class="n">number</span><span class="o">=</span><span class="n">st</span><span class="p">.</span><span class="n">integers</span><span class="p">())</span>
<span class="k">def</span> <span class="nf">test_fuzz_is_even</span><span class="p">(</span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">package_name</span><span class="p">.</span><span class="n">module</span><span class="p">.</span><span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="o">=</span><span class="n">number</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="benefits-of-using-hypothesis">Benefits of using Hypothesis</h2>

<p>Below are just a few of the benefits you&#8217;ll find with using Hypothesis:</p>

<ul>
  <li><strong><em>Discovering Edge Cases</em></strong>: Hypothesis automatically generates diverse input scenarios, including edge cases that might be overlooked in example-based tests.</li>
  <li><strong><em>Reduced Boilerplate Code</em></strong>: You can focus on the properties of your functions rather than writing extensive examples for every possible case.</li>
  <li><strong><em>Increased Confidence</em></strong>: By validating the behavior of your code against a broader set of inputs, you can be more confident that your scientific software will behave correctly in practice.</li>
</ul>

<h2 id="best-practices-for-scientific-software-testing">Best practices for scientific software testing</h2>

<p>Now that you understand some testing tools, here are some best practices for testing scientific software:</p>

<ul>
  <li>
    <p><strong>Write tests early</strong>: Incorporate testing from the start. 
This is crucial, especially when your software are prone to evolving.</p>
  </li>
  <li>
    <p><strong>Test small and test often</strong>: Focus on unit tests that cover individual functions and methods.
Catching small errors early prevents larger problems down the line.</p>
  </li>
  <li>
    <p><strong>Use realistic test data</strong>: When testing your functions, prioritize test data that reflects the real-world conditions where your software will be applied. Secondarily, use &#8220;mock&#8221; or synthetically created data when the real data are too large or complex to test quickly. For more on this topic, see <a href="https://abseil.io/resources/swe-book/html/ch13.html#prefer_realism_over_isolation">&#8220;Prefer Realism Over Isolation&#8221; from the Test Doubles chapter in the book Software Engineering at Google</a>.</p>
  </li>
  <li>
    <p><strong>Automate your tests</strong>: Use tools like <code class="language-plaintext highlighter-rouge">pytest</code> and Continuous Integration (CI) services (e.g., GitHub Actions, GitLab CI) to run your tests automatically on every commit.
This ensures that every update is tested, and bugs are identified early.</p>
  </li>
  <li>
    <p><strong>Combine different tests approaches to help diversify your test coverage</strong>: Both are essential in scientific software.
While unit tests help you pinpoint specific issues, integration tests validate that modules work correctly when combined.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Testing is a vital part of developing scientific software. By using tools like <code class="language-plaintext highlighter-rouge">pytest</code>, <code class="language-plaintext highlighter-rouge">doctest</code>, and Hypothesis, you can automate the testing process and ensure your codebase remains robust.
Investing time in writing good tests upfront will save you countless hours in debugging and re-running experiments.</p>

<p>Remember, the correctness of your code is directly tied to the validity of your scientific results.
By adopting a solid testing strategy, you&#8217;re taking a significant step toward ensuring reproducible, reliable, and impactful scientific research.</p>

<p>Now, you’re ready to ensure your scientific code is as solid as your research!</p>

<p>If interested, be sure to reference the related demonstrational repository with code from this blog post which can be found here: <a href="https://github.com/CU-DBMI/demo-python-software-testing">https://github.com/CU-DBMI/demo-python-software-testing</a></p>

<h2 id="additional-material">Additional material</h2>

<ul>
  <li>Eisty, N. U., &amp; Carver, J. C. (2022). Testing Research Software: A Survey. Empirical Software Engineering, 27(6), 138. <a href="https://doi.org/10.1007/s10664-022-10184-9">https://doi.org/10.1007/s10664-022-10184-9</a></li>
  <li>Kanewala, U., &amp; Bieman, J. M. (2018). Testing Scientific Software: A Systematic Literature Review (arXiv:1804.01954). arXiv. <a href="http://arxiv.org/abs/1804.01954">http://arxiv.org/abs/1804.01954</a></li>
  <li>Bender, A. (2020) Testing Overview. Winters, T., Manshreck, T., &amp; Wright, H. Software engineering at Google: Lessons learned from programming over time. <a href="https://abseil.io/resources/swe-book/html/ch11.html">https://abseil.io/resources/swe-book/html/ch11.html</a></li>
  <li><a href="https://cu-dbmi.github.io/set-website/2024/07/28/Uncovering-Code-Coverage.html">CU-DBMI SET Blog Post: Uncovering Code Coverage: Ensuring Software Reliability with Comprehensive Testing</a></li>
</ul>]]></content><author><name>dave-bunten</name></author><category term="software-testing" /><category term="scientific-software" /><category term="python" /><category term="reproducibility" /><summary type="html"><![CDATA[Testing Scientific Software: A Practical Guide for Developers]]></summary></entry><entry><title type="html">Uncovering Code Coverage: Ensuring Software Reliability with Comprehensive Testing</title><link href="/set-website/preview/pr-46/2024/07/28/Uncovering-Code-Coverage.html" rel="alternate" type="text/html" title="Uncovering Code Coverage: Ensuring Software Reliability with Comprehensive Testing" /><published>2024-07-28T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2024/07/28/Uncovering-Code-Coverage</id><content type="html" xml:base="/set-website/preview/pr-46/2024/07/28/Uncovering-Code-Coverage.html"><![CDATA[<h1 id="uncovering-code-coverage-ensuring-software-reliability-with-comprehensive-testing">Uncovering Code Coverage: Ensuring Software Reliability with Comprehensive Testing</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Code coverage gives our code protection from the unknown.">
    <img src="/set-website/preview/pr-46/images/file-holding-umbrella-for-coverage.png" style="
        width: 200px;
        max-height: unset;
      " alt="Code coverage gives our code protection from the unknown." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Code coverage gives our code protection from the unknown.

    </figcaption>
  
</figure>

<!-- excerpt start -->

<p>Test coverage is a crucial aspect of software development that helps ensure your code is reliable and bug-free.
By measuring how much of your code is covered by tests, you can identify untested areas and improve overall quality.
In this post, we&#8217;ll dive into what test coverage is, why it matters, and explore some tools for measuring it.
Let&#8217;s get started!</p>

<!-- excerpt end -->

<h2 id="what-is-code-coverage">What is Code Coverage?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Code which is tested is considered covered .">
    <img src="/set-website/preview/pr-46/images/simple-example-of-coverage-for-functions.png" style="
        width: 600px;
        max-height: unset;
      " alt="Code which is tested is considered covered ." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Code which is tested is considered &#8216;covered&#8217;.

    </figcaption>
  
</figure>

<blockquote>
  <p>&#8220;With tests, we can change the behavior of our code quickly and verifiably. Without them, we really don&#8217;t know if our code is getting better or worse.&#8221; (<a href="https://www.goodreads.com/quotes/718460-code-without-tests-is-bad-code-it-doesn-t-matter-how">Michael Feathers, Working Effectively with Legacy Code</a>)</p>
</blockquote>

<p>Code coverage, also known as test coverage, refers to the percentage of your code that is executed when your tests run (<a href="https://en.wikipedia.org/wiki/Code_coverage">Wikipedia: Code coverage</a>).
Software developers use code coverage as a way to understand areas which may need tests.
By understanding these metrics, you can get a clearer picture of your code&#8217;s reliability.</p>

<h2 id="types-of-coverage">Types of Coverage</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># example line
</span><span class="k">print</span><span class="p">(</span><span class="s">"A line which could be tested for coverage."</span><span class="p">)</span>

<span class="c1"># example statement (potentially multi-line)
</span><span class="n">statement</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">1</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># example function
</span><span class="k">def</span> <span class="nf">example</span><span class="p">():</span>
    <span class="k">return</span> <span class="s">"An example function."</span>

<span class="c1"># example branching
</span><span class="k">if</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">statement</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">True</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">False</span>
</code></pre></div></div>

<p>Line coverage, statement coverage, function coverage, and branch coverage common metrics used to measure how thoroughly code is tested, but they each focus on different aspects.</p>

<ul>
  <li><strong>Line coverage</strong> tracks the execution of individual lines of code, indicating whether each line has been run during testing.</li>
  <li><strong>Statement coverage</strong> is similar but considers whether each statement (a single unit of execution) within the code has been executed, regardless of the number of lines.</li>
  <li><strong>Function coverage</strong> checks whether each function or method in the code has been called during the tests, ensuring that all parts of the code&#8217;s interface are exercised.</li>
  <li><strong>Branch coverage</strong>, helps verify whether every possible path through control structures (like if-else blocks, which are often treated as a single compound statement) has been followed, ensuring that all potential outcomes and decision points are tested.</li>
</ul>

<h2 id="benefits-of-test-coverage">Benefits of Test Coverage</h2>

<blockquote>
  <p>&#8220;If you are testing thoughtfully and well, I would expect a coverage percentage in the upper 80s or 90s. I would be suspicious of anything like 100% - it would smell of someone writing tests to make the coverage numbers happy, but not thinking about what they are doing.&#8221; (<a href="https://martinfowler.com/bliki/TestCoverage.html">Martin Fowler, Test Coverage</a>)</p>
</blockquote>

<p>High test coverage ensures your code is reliable and less prone to bugs. 
It helps you identify untested parts of your codebase, facilitating better maintenance and encouraging a culture of quality.
However, it&#8217;s important to balance this with the understanding that striving for 100% coverage can sometimes lead to anti-patterns.
Such anti-patterns include writing superficial tests that don&#8217;t effectively validate functionality, or spending excessive time on achieving full coverage at the expense of more critical development tasks.</p>

<p>There are often times where you need to make changes to your code which can cause unforeseen issues to arise (for example, when there&#8217;s coupling to other functionality).
With good test coverage, you can more confidently refactor code during these occasions, knowing that any issues will be quickly caught by your tests.
Because of this, implementing code coverage at the beginning of the development process promotes writing cleaner and more reliable code over time.
If you’re working with code that currently has no coverage, there’s no time like the present to start!</p>

<h2 id="measuring-test-coverage">Measuring Test Coverage</h2>

<h3 id="tools">Tools</h3>

<p>Different languages have different tools for measuring code coverage.
These tools help you visualize and understand your test coverage, making it easier to spot gaps and improve your tests.
While the implementations may differ in their processing and report formatting, they all follow similar principles.
Many of these tools are available without additional cost of freely as open-source packages.
Below are just a few languages and common test coverage tools you can use with them.</p>

<ul>
  <li><strong>Python</strong>, <a href="https://github.com/nedbat/coveragepy"><code class="language-plaintext highlighter-rouge">coverage.py</code></a> is a popular open-source solution which can be paired with <a href="https://github.com/pytest-dev/pytest-cov"><code class="language-plaintext highlighter-rouge">pytest-cov</code></a>. <a href="https://github.com/plasma-umass/slipcover"><code class="language-plaintext highlighter-rouge">slipcover</code></a> is a similar coverage tool which can be used with Python.</li>
  <li><strong>R</strong> developers often use <a href="https://github.com/r-lib/covr"><code class="language-plaintext highlighter-rouge">covr</code></a>.</li>
  <li><strong>C++</strong> developers can rely on <a href="https://gcc.gnu.org/onlinedocs/gcc/gcov/introduction-to-gcov.html"><code class="language-plaintext highlighter-rouge">gcov</code></a> or <a href="https://github.com/linux-test-project/lcov"><code class="language-plaintext highlighter-rouge">LCOV</code></a>.</li>
  <li><strong>MATLAB</strong> has built-in test coverage features through <a href="https://www.mathworks.com/help/matlab/matlab_prog/types-of-code-coverage-for-matlab-source-code.html"><code class="language-plaintext highlighter-rouge">CodeCoveragePlugin</code></a>.</li>
</ul>

<h3 id="platforms">Platforms</h3>

<p>In addition to the tools mentioned above there are also various test or code coverage platforms (often <a href="https://en.wikipedia.org/wiki/Software_as_a_service">software as a service (SaaS)</a> companies).
These platforms allow you to integrate the data with your GitHub workflows and often include additional insights like historical data tracking, etc.
Platforms may be an option to consider when thinking about scale and the type of information you&#8217;re interested in viewing.
See below for some examples of these:</p>

<ul>
  <li><a href="https://about.codecov.io/">Codecov</a>, known for its ease of setup and comprehensive support for various languages, is a popular code coverage reporting tool that integrates with many CI/CD services and version control systems.</li>
  <li><a href="https://www.codacy.com/coverage">Codacy</a> is a code quality platform that includes code coverage as one of its features.</li>
  <li><a href="https://codeclimate.com/">Code Climate</a> is another code quality platform which includes code coverage as one of its features.</li>
</ul>

<h2 id="using-coveragepy-for-measuring-test-coverage-in-python">Using <code class="language-plaintext highlighter-rouge">coverage.py</code> for Measuring Test Coverage in Python</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Source: Coverage.py website https: coverage.readthedocs.io en 7.6.0">
    <img src="/set-website/preview/pr-46/images/coverage.py-logo.png" style="
        width: 200px;
        max-height: unset;
      " alt="Source: Coverage.py website https: coverage.readthedocs.io en 7.6.0" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      (Source: <a href="https://coverage.readthedocs.io/en/7.6.0/">Coverage.py website</a>)

    </figcaption>
  
</figure>

<p><code class="language-plaintext highlighter-rouge">coverage.py</code> is a powerful tool for measuring code coverage in Python. 
It&#8217;s easy to set up: just install it via <a href="https://pip.pypa.io/en/stable/">pip</a> (or your development environment), run your tests with coverage, and generate reports in various formats.
By default, <code class="language-plaintext highlighter-rouge">coverage.py</code> measures <strong>statement coverage</strong> but it can be configured to measure others (<a href="https://coverage.readthedocs.io/en/7.6.0/index.html#capabilities">see here for more</a>).
Interpreting these reports helps you understand which parts of your code need more testing love.</p>

<h3 id="a-quick-example-of-coveragepy">A quick example of <code class="language-plaintext highlighter-rouge">coverage.py</code></h3>

<p>The following content may help demonstrate how <code class="language-plaintext highlighter-rouge">coverage.py</code> and test coverage works.
This example assumes one has installed both <code class="language-plaintext highlighter-rouge">coverage.py</code> and <a href="https://docs.pytest.org/en/stable/"><code class="language-plaintext highlighter-rouge">pytest</code></a> (a common Python testing framework) using pip (for instance, by using the command <code class="language-plaintext highlighter-rouge">pip install coverage pytest</code>).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># module.py
</span>
<span class="k">def</span> <span class="nf">covered_test</span><span class="p">():</span>
    <span class="k">return</span> <span class="s">"This test has coverage."</span>

<span class="k">def</span> <span class="nf">uncovered_test</span><span class="p">():</span>
    <span class="k">return</span> <span class="s">"This test doesn't have coverage."</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">module.py</code> has two functions, one which will be covered by a test and the other which will not.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test_module.py
</span>
<span class="kn">from</span> <span class="nn">module</span> <span class="kn">import</span> <span class="n">covered_test</span>

<span class="k">def</span> <span class="nf">test_add</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">covered_test</span><span class="p">()</span> <span class="o">==</span> <span class="s">"This test has coverage."</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">test_module.py</code> has one test for <code class="language-plaintext highlighter-rouge">module.covered_test</code>.
<code class="language-plaintext highlighter-rouge">module.uncovered_test</code> remains without a test and won&#8217;t be considered as covered by <code class="language-plaintext highlighter-rouge">coverage.py</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># first we process test coverage</span>
<span class="nv">$ </span>coverage run <span class="nt">-m</span> pytest
<span class="c"># then we show the reported output of</span>
<span class="c"># processed test coverage</span>
<span class="nv">$ </span>coverage report
Name             Stmts   Miss  Cover
<span class="nt">------------------------------------</span>
module.py            4      1    75%
test_module.py       3      0   100%
<span class="nt">------------------------------------</span>
TOTAL                7      1    86%
</code></pre></div></div>

<p>We use the above <code class="language-plaintext highlighter-rouge">coverage.py</code> commands to first process test coverage and then to show a report about test coverage afterwards.
Notice that <code class="language-plaintext highlighter-rouge">module.py</code> shows it does not have full coverage, indicating a possible area where we can improve testing.</p>

<h2 id="integrating-code-coverage-tools-with-cicd-pipelines">Integrating Code Coverage Tools with CI/CD Pipelines</h2>

<p>Continuous integration and deployment (CI/CD) are essential for modern development workflows.
By integrating code coverage tools with CI/CD pipelines, you can automate the process of checking test coverage.
Setting up <code class="language-plaintext highlighter-rouge">coverage.py</code> with GitHub Actions workflows, for example, maintains high standards and can catch issues early.
Strategies like setting coverage thresholds and failing builds on coverage drops help maintain high standards.
Comparing current coverage with previous coverage can be done using techniques like hash checks for binary files or storing and comparing coverage reports.
This ensures you know exactly what&#8217;s changed and can act accordingly.</p>

<h3 id="pre-commit-hooks-to-generate-coveragepy-reports">Pre-commit Hooks to Generate <code class="language-plaintext highlighter-rouge">coverage.py</code> Reports</h3>

<figure class="figure">
  <a class="figure-image" aria-label="Pre-commit may be used to help automatically generate coverage reports alongside your source control practices.">
    <img src="/set-website/preview/pr-46/images/coverage-pre-commit-workflow.png" style="
        width: auto;
        max-height: unset;
      " alt="Pre-commit may be used to help automatically generate coverage reports alongside your source control practices." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Pre-commit may be used to help automatically generate coverage reports alongside your source control practices.

    </figcaption>
  
</figure>

<p><a href="https://pre-commit.com/">Pre-commit</a> hooks are scripts that run before a commit is finalized.
You can set up a pre-commit hook to run tests and generate coverage reports using <code class="language-plaintext highlighter-rouge">coverage.py</code> (see the example below).
This ensures consistency by comparing reports before and after changes.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># example .pre-commit-config.yml</span>
<span class="c1"># See https://pre-commit.com for more information</span>
<span class="na">repos</span><span class="pi">:</span>
    <span class="c1"># process coverage within local environment</span>
  <span class="pi">-</span> <span class="na">repo</span><span class="pi">:</span> <span class="s">local</span>
    <span class="na">hooks</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">code-cov-gen</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">Generate code coverage</span>
        <span class="na">language</span><span class="pi">:</span> <span class="s">system</span>
        <span class="na">entry</span><span class="pi">:</span> <span class="s">coverage run -m pytest</span>
        <span class="na">pass_filenames</span><span class="pi">:</span> <span class="no">false</span>
        <span class="na">always_run</span><span class="pi">:</span> <span class="no">true</span>
    <span class="c1"># generate xml coverage report and export to a badge</span>
    <span class="c1"># for display within a readme or other documentation.</span>
  <span class="pi">-</span> <span class="na">repo</span><span class="pi">:</span> <span class="s">https://github.com/Weird-Sheep-Labs/coverage-pre-commit</span>
    <span class="na">rev</span><span class="pi">:</span> <span class="s">0.1.1</span>
    <span class="na">hooks</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">coverage-xml</span>
      <span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">coverage-badge</span>
</code></pre></div></div>

<p>If there&#8217;s a significant drop in coverage, the changes are immediately visible, potentially before the commit even happens.
This workflow can also help generate metadata for association with a repository, for example, through <a href="https://github.com/dbrgn/coverage-badge">coverage-badge</a> or <a href="https://github.com/smarie/python-genbadge">genbage</a>.</p>

<h3 id="pull-request-comment-with-coveragepy-reports">Pull Request Comment with <code class="language-plaintext highlighter-rouge">coverage.py</code> Reports</h3>

<figure class="figure">
  <a class="figure-image" aria-label="GitHub Actions workflows can help add coverage reporting capabilities to your pull requests.">
    <img src="/set-website/preview/pr-46/images/coverage-pr-comment-workflow.png" style="
        width: auto;
        max-height: unset;
      " alt="GitHub Actions workflows can help add coverage reporting capabilities to your pull requests." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      GitHub Actions workflows can help add coverage reporting capabilities to your pull requests.

    </figcaption>
  
</figure>

<p>Another workflow which might be helpful is posting coverage reports when a pull request (PR) is opened (for example, using GitHub Action <a href="https://github.com/orgoro/coverage">orgoro/coverage</a>).
This process involves generating a coverage report during the CI/CD pipeline and integrating it with the PR.</p>

<figure class="figure">
  <a class="figure-image" aria-label="Example pull request comment with code coverage details source: https: github.com orgoro coverage .">
    <img src="/set-website/preview/pr-46/images/coverage-workflow-pr-comment.png" style="
        width: auto;
        max-height: unset;
      " alt="Example pull request comment with code coverage details source: https: github.com orgoro coverage ." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Example pull request comment with code coverage details (source: https://github.com/orgoro/coverage).

    </figcaption>
  
</figure>

<p>By doing so, developers can immediately see which parts of the code are covered by tests and which are not, enabling them to identify potential gaps in testing.
This transparency helps maintain high code quality, ensures that new changes are well-tested, and encourages best practices in test-driven development.</p>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>Code coverage is a vital part of software development that helps maintain code quality and reliability. By integrating coverage tools and practices into your workflow, you can ensure your code is thoroughly tested and ready for any changes. Start using Code coverage tools in your projects today and experience the benefits firsthand!</p>

<h2 id="additional-resources">Additional Resources</h2>

<p>For further reading and resources, check out the the following resources on this topic:</p>

<ul>
  <li><a href="https://linearb.io/blog/code-coverage-types">LinearB Blog: Code Coverage Types: Which Is the Best?</a></li>
  <li><a href="https://learn.scientific-python.org/development/guides/coverage">Scientific Python Development Guide: Code Coverage</a></li>
  <li><a href="https://research.google/pubs/code-coverage-at-google">Google Research: Code coverage at Google</a></li>
  <li><a href="https://ieeexplore.ieee.org/abstract/document/7272926">IEEE: How Effective Are Code Coverage Criteria?</a></li>
</ul>]]></content><author><name>dave-bunten</name></author><category term="code-coverage" /><category term="test-coverage" /><category term="software-quality" /><category term="testing" /><category term="software-sustainability" /><summary type="html"><![CDATA[Uncovering Code Coverage: Ensuring Software Reliability with Comprehensive Testing]]></summary></entry><entry><title type="html">Leveraging Kùzu and Cypher for Advanced Data Analysis</title><link href="/set-website/preview/pr-46/2024/05/24/Leveraging-K%C3%B9zu-and-Cypher-for-Advanced-Data-Analysis.html" rel="alternate" type="text/html" title="Leveraging Kùzu and Cypher for Advanced Data Analysis" /><published>2024-05-24T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2024/05/24/Leveraging-K%C3%B9zu-and-Cypher-for-Advanced-Data-Analysis</id><content type="html" xml:base="/set-website/preview/pr-46/2024/05/24/Leveraging-K%C3%B9zu-and-Cypher-for-Advanced-Data-Analysis.html"><![CDATA[<h1 id="leveraging-kùzu-and-cypher-for-advanced-data-analysis">Leveraging Kùzu and Cypher for Advanced Data Analysis</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Image sourced from https: github.com kuzudb kuzu.">
    <img src="/set-website/preview/pr-46/images/kuzu_logo.png" style="
        width: 500px;
        max-height: unset;
      " alt="Image sourced from https: github.com kuzudb kuzu." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      (Image sourced from https://github.com/kuzudb/kuzu.)

    </figcaption>
  
</figure>

<!-- excerpt start -->

<p>Graph databases can offer a more natural and intuitive way to model and explore relationships within data.
In this post, we&#8217;ll dive into the world of graph databases, focusing on Kùzu, an embedded graph database and query engine for a number of languages, and Cypher, a powerful query language designed for graph data.
We&#8217;ll explore how these tools can transform your data management and analysis workflows, provide insights into their capabilities, and discuss when it might be more appropriate to use server-based solutions.
Whether you&#8217;re a research software developer looking to integrate advanced graph processing into your applications or simply curious about the benefits of graph databases, this guide will equip you with the knowledge to harness the full potential of graph data.</p>

<!-- excerpt end -->

<h2 id="tabular-data">Tabular Data</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Tabular data is made up up rows or records and columns.">
    <img src="/set-website/preview/pr-46/images/tabular_data_image.png" style="
        width: auto;
        max-height: unset;
      " alt="Tabular data is made up up rows or records and columns." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Tabular data is made up up rows (or records) and columns.

    </figcaption>
  
</figure>

<p>Data are often stored in a table, or <a href="https://en.wikipedia.org/wiki/Table_(database)">tabular format</a>, where information is organized into rows and columns.
Each row represents a single record and each column represents attributes of that record.
Tables are particularly effective for storing and querying large volumes of data with a fixed set of columns and data types.
Despite its versatility, tabular data can become cumbersome when dealing with complex relationships and interconnected data, where a graph-based approach might be more suitable.</p>

<h2 id="graph-data">Graph Data</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Graph data is made up of nodes and edges.">
    <img src="/set-website/preview/pr-46/images/graph_data_intro.png" style="
        width: auto;
        max-height: unset;
      " alt="Graph data is made up of nodes and edges." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Graph data is made up of nodes and edges.

    </figcaption>
  
</figure>

<p><a href="https://en.wikipedia.org/wiki/Graph_(abstract_data_type)">Graph data</a> represents information in the form of nodes (also called vertices) and edges (connections between nodes).
This structure is useful for modeling complex relationships and interconnected data, such as social networks, biological networks, and transportation systems.
Unlike tabular data, which is often &#8220;flattened&#8221; (treating multidimensional data as singular columns) and often rigid (requiring all new data to conform to a specific schema), graph data allows for more flexible and dynamic representations.</p>

<figure class="figure">
  <a class="figure-image" aria-label="Nodes and edges may have properties in a graph.">
    <img src="/set-website/preview/pr-46/images/graph_data_intro_properties.png" style="
        width: auto;
        max-height: unset;
      " alt="Nodes and edges may have properties in a graph." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Nodes and edges may have properties in a graph.

    </figcaption>
  
</figure>

<p>Nodes and edges act like different kinds of tabular records within the context of graphs.
Nodes and edges can also have properties (attributes) which further provide description to a graph.
Properties are akin to columns of a particular record in tabular formats which help describe a certain record (or node).
Graph data models are particularly useful for exploring connections, performing path analysis, and uncovering patterns that may require more transformation in tabular formats.</p>

<h2 id="graph-databases">Graph Databases</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Graph databases store graph data.">
    <img src="/set-website/preview/pr-46/images/graph_database.png" style="
        width: auto;
        max-height: unset;
      " alt="Graph databases store graph data." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Graph databases store graph data.

    </figcaption>
  
</figure>

<p><a href="https://en.wikipedia.org/wiki/Graph_database">Graph databases</a> are specialized databases designed to store, query, and manage graph data efficiently.
They use graph structures for semantic queries, with nodes, edges, and properties being stored directly in the database.
Unlike traditional relational databases that use tables, graph databases leverage the natural relationships in the data, allowing for faster retrieval and sometimes more intuitive querying of interconnected information.
This makes them ideal for applications involving complex relationships, such as social networks, supply chain management, and knowledge graphs.
Graph databases support various query languages and algorithms optimized for traversing and analyzing graph structures.</p>

<h2 id="graph-database-querying">Graph Database Querying</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Graph data are typically queried using specialized languages such as Cypher.">
    <img src="/set-website/preview/pr-46/images/graph_database_querying.png" style="
        width: auto;
        max-height: unset;
      " alt="Graph data are typically queried using specialized languages such as Cypher." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Graph data are typically queried using specialized languages such as Cypher.

    </figcaption>
  
</figure>

<p>Graph database querying involves using specialized query languages to retrieve and manipulate graph data.
Unlike SQL, which often is used for tabular databases, graph databases use languages like <a href="https://en.wikipedia.org/wiki/Cypher_(query_language)">Cypher</a>, <a href="https://en.wikipedia.org/wiki/Gremlin_(query_language)">Gremlin</a>, and <a href="https://en.wikipedia.org/wiki/SPARQL">SPARQL</a>, which are designed to handle graph-specific operations.
These languages allow users to perform complex queries that traverse the graph, find paths between nodes, filter based on properties, and analyze relationships.
Querying in graph databases can be highly efficient due to their ability to leverage the inherent structure of the graph, enabling fast execution of complex queries that would be cumbersome and slow in a relational database.</p>

<h2 id="cypher-query-language">Cypher Query Language</h2>

<div class="language-cypher highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">MATCH</span><span class="w"> </span><span class="ss">(</span><span class="py">p:</span><span class="n">Person</span> <span class="ss">{</span><span class="py">name:</span> <span class="s1">'Alice'</span><span class="ss">})</span><span class="o">-</span><span class="ss">[</span><span class="nc">:FRIEND</span><span class="ss">]</span><span class="o">-&gt;</span><span class="ss">(</span><span class="n">friend</span><span class="ss">)</span>
<span class="k">RETURN</span> <span class="n">friend.name</span><span class="ss">,</span> <span class="n">friend.age</span>
</code></pre></div></div>

<p class="center"><em>This query finds nodes labeled &#8220;Person&#8221; with the name &#8220;Alice&#8221; and returns the names and ages of nodes connected to Alice by a &#8220;FRIEND&#8221; relationship.</em></p>

<p>Cypher is a powerful, declarative graph query language designed specifically for querying and updating graph databases.
Originally developed for <a href="https://en.wikipedia.org/wiki/Neo4j">Neo4j</a> (one of the most popular graph databases), it is known for its expressive and intuitive syntax that makes it easy to work with graph data.
Cypher allows users to perform complex queries using simple and readable patterns that resemble ASCII art, making it accessible to both developers and data scientists.
It supports a wide range of operations, including pattern matching, filtering, aggregation, and graph traversal, enabling efficient exploration and manipulation of graph structures.
For example, a basic Cypher query to find all nodes connected by a &#8220;FRIEND&#8221; relationship might look like this: <code class="language-plaintext highlighter-rouge">MATCH (a)-[:FRIEND]-&gt;(b) RETURN a, b</code>, which finds and returns pairs of nodes a and b where a is connected to b by a &#8220;FRIEND&#8221; relationship.</p>

<h2 id="kùzu">Kùzu</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Kùzu provides a database format and query engine accessible through Python and other languages by using Cypher queries.">
    <img src="/set-website/preview/pr-46/images/kuzu_intro.png" style="
        width: auto;
        max-height: unset;
      " alt="Kùzu provides a database format and query engine accessible through Python and other languages by using Cypher queries." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Kùzu provides a database format and query engine accessible through Python and other languages by using Cypher queries.

    </figcaption>
  
</figure>

<p><a href="https://github.com/kuzudb/kuzu">Kùzu</a> is an embedded graph database and query engine designed to integrate seamlessly with Python, Rust, Node, C/C++, or Java software.
Kùzu is optimized for high performance and can handle complex graph queries with ease.
Querying graphs in Kùzu is performed using the Cypher syntax, providing transferrability of queries in multiple programming languages.
Kùzu also provides direct integration with export formats that allow for efficient data analysis or processing such as Pandas and Arrow.
Kùzu is particularly suitable for software developers who need to integrate graph database capabilities into their projects without the overhead of managing a separate database server.</p>

<h2 id="tabular-and-graph-data-interoperation">Tabular and Graph Data Interoperation</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Kùzu uses tabular data as both input and output for data operations.">
    <img src="/set-website/preview/pr-46/images/kuzu_table_ingest.png" style="
        width: auto;
        max-height: unset;
      " alt="Kùzu uses tabular data as both input and output for data operations." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Kùzu uses tabular data as both input and output for data operations.

    </figcaption>
  
</figure>

<p>Tabular data and graph data can sometimes be used in tandem in order to achieve software goals (one isn&#8217;t necessaryily better than the other or supposed to be used in isolation).
For example, Kùzu offers both data import and export to tabular formats to help with conversion and storage outside of a graph database.
This is especially helpful when working with tabular data as an input, when trying to iterate over large datasets in smaller chunks, or building integration paths to other pieces of software which aren&#8217;t Kùzu or graph data compatible.</p>

<h2 id="kùzu-tabular-data-imports">Kùzu Tabular Data Imports</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># portions of this content referenced
# with modifications from:
# https://docs.kuzudb.com/import/parquet/
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">kuzu</span>

<span class="c1"># create parquet-based data for import into kuzu
</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">"name"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Adam"</span><span class="p">,</span> <span class="s">"Adam"</span><span class="p">,</span> <span class="s">"Karissa"</span><span class="p">,</span> <span class="s">"Zhang"</span><span class="p">],</span>
     <span class="s">"age"</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">25</span><span class="p">]}</span>
<span class="p">).</span><span class="n">to_parquet</span><span class="p">(</span><span class="s">"user.parquet"</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"from"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Adam"</span><span class="p">,</span> <span class="s">"Adam"</span><span class="p">,</span> <span class="s">"Karissa"</span><span class="p">,</span> <span class="s">"Zhang"</span><span class="p">],</span>
        <span class="s">"to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Karissa"</span><span class="p">,</span> <span class="s">"Zhang"</span><span class="p">,</span> <span class="s">"Zhang"</span><span class="p">,</span> <span class="s">"Noura"</span><span class="p">],</span>
        <span class="s">"since"</span><span class="p">:</span> <span class="p">[</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="mi">2021</span><span class="p">,</span> <span class="mi">2022</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">).</span><span class="n">to_parquet</span><span class="p">(</span><span class="s">"follows.parquet"</span><span class="p">)</span>

<span class="c1"># form a kuzu database connection
</span><span class="n">db</span> <span class="o">=</span> <span class="n">kuzu</span><span class="p">.</span><span class="n">Database</span><span class="p">(</span><span class="s">"./test"</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">kuzu</span><span class="p">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>

<span class="c1"># use wildcard-based copy in case of multiple files
# copy node data
</span><span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">'COPY User FROM "user*.parquet";'</span><span class="p">)</span>
<span class="c1"># copy edge data
</span><span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">'COPY Follows FROM "follows*.Parquet";'</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span>
    <span class="s">"""MATCH (a:User)-[f:Follows]-&gt;(b:User)
    RETURN a.name, b.name, f.since;"""</span>
<span class="p">).</span><span class="n">get_as_df</span><span class="p">()</span>
</code></pre></div></div>

<p>One way to create graphs within Kùzu is to import data from tabular datasets.
Kùzu provides functionality to convert tabular data from CSV, <a href="https://en.wikipedia.org/wiki/Apache_Parquet">Parquet</a>, or <a href="https://numpy.org/">NumPy</a> files into a graph.
This process enables seamless integration of tabular data sources into the graph database, providing the benefits of graph-based querying and analysis while leveraging the familiar structure and benefits of tabular data.</p>

<h2 id="kùzu-data-results-and-exports">Kùzu Data Results and Exports</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># portions of this content referenced 
# with modifications from:
# https://kuzudb.com/api-docs/python/kuzu.html
</span><span class="kn">import</span> <span class="nn">kuzu</span>

<span class="c1"># form a kuzu database connection
</span><span class="n">db</span> <span class="o">=</span> <span class="n">kuzu</span><span class="p">.</span><span class="n">Database</span><span class="p">(</span><span class="s">"./test"</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">kuzu</span><span class="p">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>

<span class="n">query</span> <span class="o">=</span> <span class="s">"MATCH (u:User) RETURN u.name, u.age;"</span>

<span class="c1"># run query and return Pandas DataFrame
</span><span class="n">pd_df</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="n">get_as_df</span><span class="p">()</span>

<span class="c1"># run query and return Polars DataFrame
</span><span class="n">pl_df</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="n">get_as_pl</span><span class="p">()</span>

<span class="c1"># run query and return PyArrow Table
</span><span class="n">arrow_tbl</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="n">get_as_arrow</span><span class="p">()</span>

<span class="c1"># run query and return PyTorch Geometric Data
</span><span class="n">pyg_d</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="n">get_as_torch_geometric</span><span class="p">()</span>

<span class="c1"># run query within COPY to export directly to file
</span><span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">"COPY (MATCH (u:User) return u.*) TO 'user.parquet';"</span><span class="p">)</span>
</code></pre></div></div>

<p>Kùzu also is flexible when it comes to receiving data from Cypher queries.
After performing a query you have the option to use a number of methods to automatically convert into various in-memory data formats, for example, <a href="https://kuzudb.com/api-docs/python/kuzu.html#QueryResult.get_as_df">Pandas DataFrames</a>, <a href="https://kuzudb.com/api-docs/python/kuzu.html#QueryResult.get_as_pl">Polars DataFrames</a>,<a href="https://kuzudb.com/api-docs/python/kuzu.html#QueryResult.get_as_torch_geometric"> PyTorch Geometric (PyG) Data</a>, or <a href="https://kuzudb.com/api-docs/python/kuzu.html#QueryResult.get_as_arrow">PyArrow Tables</a>.
There are also options to export data directly to CSV or Parquet files for times where file-based data is preferred.</p>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>

<p>Kùzu, with its seamless integration into Python environments and efficient handling of graph data, presents a compelling solution for developers seeking embedded graph database capabilities.
Its ability to transform and query tabular data into rich graph structures opens up new possibilities for data analysis and application development.
However, it&#8217;s important to consider the scale and specific needs of your project when choosing between Kùzu and more robust server-based solutions like Neo4j.
By leveraging the right tool for the right job, whether it&#8217;s Kùzu for lightweight embedded applications or a server-based database for enterprise-scale operations, developers can unlock the full potential of graph data. Embracing these technologies allows for deeper insights, more complex data relationships, and ultimately, more powerful and efficient applications.</p>]]></content><author><name>dave-bunten</name></author><category term="research-data-engineering" /><category term="graph-data" /><category term="databases" /><category term="cypher" /><category term="data-interoperability" /><summary type="html"><![CDATA[Leveraging Kùzu and Cypher for Advanced Data Analysis]]></summary></entry><entry><title type="html">Parquet: Crafting Data Bridges for Efficient Computation</title><link href="/set-website/preview/pr-46/2024/03/25/Parquet-Crafting-Data-Bridges-for-Efficient-Computation.html" rel="alternate" type="text/html" title="Parquet: Crafting Data Bridges for Efficient Computation" /><published>2024-03-25T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2024/03/25/Parquet-Crafting-Data-Bridges-for-Efficient-Computation</id><content type="html" xml:base="/set-website/preview/pr-46/2024/03/25/Parquet-Crafting-Data-Bridges-for-Efficient-Computation.html"><![CDATA[<h1 id="parquet-crafting-data-bridges-for-efficient-computation">Parquet: Crafting Data Bridges for Efficient Computation</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/Apache_Parquet_logo.svg" style="
        width: 500px;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p class="center"><em>(Image: <a href="https://commons.wikimedia.org/wiki/File:Apache_Parquet_logo.svg">Vulphere, Wikimedia Commons</a>)</em></p>

<!-- excerpt start -->
<p><a href="https://en.wikipedia.org/wiki/Apache_Parquet">Apache Parquet</a> is a columnar and strongly-typed tabular data storage format built for scalable processing which is widely compatible with many data models, programming languages, and software systems.
Parquet files (typically denoted with a <code class="language-plaintext highlighter-rouge">.parquet</code> filename extension) are typically compressed within the format itself and are often used in embedded or cloud-based high-performance scenarios.
It has grown in popularity since it was introduced in 2013 and is used as a core data storage technology in many organizations.
This article will introduce the Parquet format from a research data engineering perspective.
<!-- excerpt end --></p>

<h2 id="understanding-the-parquet-file-format">Understanding the Parquet file format</h2>

<figure class="figure">
  <a class="figure-image" aria-label="figure link">
    <img src="/set-website/preview/pr-46/images/parquet_flooring.jpg" style="
        width: 500px;
        max-height: unset;
      " alt="figure image" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
</figure>

<p class="center"><em>(Image: <a href="https://commons.wikimedia.org/wiki/File:Fischgr%C3%A4t_route_4_fischbacher_living.jpg">Robert Fischbacher163, Wikimedia Commons</a>)</em></p>

<p>Parquet began around 2013 as work by Twitter and Cloudera collaborators to help solve large data challenges (for example, in <a href="https://en.wikipedia.org/wiki/Apache_Hadoop">Apache Hadoop</a> systems).
It was partially inspired by a Google Research publication: <a href="https://research.google/pubs/dremel-interactive-analysis-of-web-scale-datasets-2/"><em>&#8220;Dremel: Interactive Analysis of Web-Scale Datasets&#8221;</em></a>.
Parquet joined the <a href="https://en.wikipedia.org/wiki/The_Apache_Software_Foundation">Apache Software Foundation</a> in 2015 as a Top-Level Project (TLP) (<a href="https://news.apache.org/foundation/entry/the_apache_software_foundation_announces75">link</a>)
The format is similar and has related goals to that of the <a href="https://en.wikipedia.org/wiki/Apache_ORC">ORC</a>, <a href="https://en.wikipedia.org/wiki/Apache_Avro">Avro</a>, and <a href="https://arrow.apache.org/docs/python/feather.html">Feather</a> file formats.</p>

<p>One definition for the word &#8220;parquet&#8221; is: <em>&#8220;A wooden floor made of parquetry.&#8221;</em> (<a href="https://en.wiktionary.org/wiki/parquet">Wiktionary: Parquet</a>).
Parquetry are often used to form decorative geometric patterns in flooring.
It seems fitting to name the format this way due to how columns and values are structured (see more below), akin to constructing a beautiful &#8216;floor&#8217; for your data efforts.</p>

<p>We cover a few pragmatic aspects of the Parquet file format below.</p>

<h3 id="--columnar-data-storage"><i class="fas fa-table-columns"></i>  Columnar data storage</h3>

<!-- retain original HTML as code-based content 
<table>
<tr>
<th>Data Type</th>
<th>Data</th>
<th>How data is organized on file</th>
</tr>
<tr>
<td>CSV</td>
<td>
<table>
<tr>
<td>1</td>
<td>Grapes</td>
</tr>
<tr>
<td>2</td>
<td>Oranges</td>
</tr>
</table>
<td>
<table>
<tr>
<td>1</td><td>Grapes</td><td>2</td><td>Oranges</td>
</tr>
</table>
</td>
</tr>
<tr>
<td>Parquet</td>
<td>
<table>
<tr>
<td>1</td>
<td>Grapes</td>
</tr>
<tr>
<td>2</td>
<td>Oranges</td>
</tr>
</table>
<td>

<table>
<tr>
<td>1</td><td>2</td><td>Grapes</td><td>Oranges</td>
</tr>
</table>

<center>(simplification, see abstractions below)</center>

</td>
</tr>
</table>
-->

<figure class="figure">
  <a class="figure-image" aria-label="Parquet organizes column values together. CSV intermixes values from multiple columns">
    <img src="/set-website/preview/pr-46/images/csv_vs_parquet_data_on_file.png" style="
        width: auto;
        max-height: unset;
      " alt="Parquet organizes column values together. CSV intermixes values from multiple columns" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Parquet organizes column values together. CSV intermixes values from multiple columns

    </figcaption>
  
</figure>

<p>Parquet files store data in a <strong>&#8220;columnar&#8221;</strong> way which is distinct from other formats.
We can understand this columnar format by using <a href="https://en.wikipedia.org/wiki/Plaintext">plaintext</a> <a href="https://en.wikipedia.org/wiki/Comma-separated_values">comma-separated value (CSV)</a> format as a reference point.
CSV files store data in a row-orientated way by using new lines to represent rows of values.
Reading all values of a single column in CSV often involves seeking through multiple other portions of the data by default.</p>

<p>Parquet files are binary in nature, optimizing storage by arranging values from individual columns in close proximity to each other.
This enables the data to be stored and retrieved more efficiently than possible with CSV files.
For example, Parquet files allow you to query individual columns without needing to traverse non-necessary column value data.</p>

<h3 id="-parquet-format-abstractions"><i class="fas fa-sitemap"></i> Parquet format abstractions</h3>

<h4 id="row-groups-column-chunks-and-pages">Row groups, column chunks, and pages</h4>
<!-- set a max width for mermaid diagram below so it doesn't render so large -->
<style>
.mermaid {
  display: block;
  margin: 0 auto;
  max-height: 400px;
}
</style>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IFRCXG5zdWJncmFwaCBwYXJxdWV0X2ZpbGVbXCJQYXJxdWV0IEZpbGVcIl1cbmRpcmVjdGlvbiBUQlxuc3ViZ3JhcGggcm93Z3JvdXBfMSBbXCJSb3cgZ3JvdXAgMVwiXVxuZGlyZWN0aW9uIFRCXG5zdWJncmFwaCBjb2x1bW5fMV9hW1wiQ29sdW1uIEFcIl1cbmRpcmVjdGlvbiBUQlxucGFnZV8xX2FfMFtcIlBhZ2UgMFwiXVxucGFnZV8xX2FfMVtcIlBhZ2UgMVwiXVxuZW5kXG5zdWJncmFwaCBjb2x1bW5fMV9iW1wiQ29sdW1uIEJcIl1cbmRpcmVjdGlvbiBUQlxucGFnZV8xX2JfMFtcIlBhZ2UgMFwiXVxucGFnZV8xX2JfMVtcIlBhZ2UgMVwiXVxuZW5kXG5lbmRcbiUlLVxuc3ViZ3JhcGggcm93Z3JvdXBfMiBbXCJSb3cgZ3JvdXAgMlwiXVxuZGlyZWN0aW9uIFRCXG5zdWJncmFwaCBjb2x1bW5fMl9hW1wiQ29sdW1uIEFcIl1cbmRpcmVjdGlvbiBUQlxucGFnZV8yX2FfMFtcIlBhZ2UgMFwiXVxucGFnZV8yX2FfMVtcIlBhZ2UgMVwiXVxuZW5kXG5zdWJncmFwaCBjb2x1bW5fMl9iW1wiQ29sdW1uIEJcIl1cbmRpcmVjdGlvbiBUQlxucGFnZV8yX2JfMFtcIlBhZ2UgMFwiXVxucGFnZV8yX2JfMVtcIlBhZ2UgMVwiXVxuZW5kXG4lJS1cbmVuZFxuZW5kIiwibWVybWFpZCI6bnVsbH0" /></p>

<p class="center"><em>Parquet organizes data using row groups, columns, and pages.</em></p>

<p>Parquet files organize column data inside of <strong>row groups</strong>.
Each row group includes chunks of columns in the form of <strong>pages</strong>.
Row groups and column pages are configurable and may change depending on the configuration of your Parquet client.
<strong>Note:</strong> you don&#8217;t need to be an expert on these details to leverage and benefit from Parquet as these are often configured for default general purposes.</p>

<h4 id="page-encodings">Page encodings</h4>

<p>Pages within column chunks may have a number of different <strong>encodings</strong>.
<a href="https://github.com/apache/parquet-format/blob/master/Encodings.md">Parquet encodings</a> are often selected based on the type of data included within columns and the operational or performance needs associated with a project.
By default, <a href="https://github.com/apache/parquet-format/blob/master/Encodings.md#plain-plain--0">Plain (<code class="language-plaintext highlighter-rouge">PLAIN</code>) encoding</a> is used which means all values are stored back to back.
Another encoding type, <a href="https://github.com/apache/parquet-format/blob/master/Encodings.md#run-length-encoding--bit-packing-hybrid-rle--3">Run Length Encoding (<code class="language-plaintext highlighter-rouge">RLE</code>)</a>, is often used to efficiently store columns with many consecutively repeated values.
Column encodings are sometimes set for each individual column, usually in an automatic way based on the data involved.</p>

<h3 id="-compression"><i class="fas fa-box-archive"></i> Compression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

<span class="c1"># create a pyarrow table
</span><span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"A"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="s">"B"</span><span class="p">:</span> <span class="p">[</span><span class="s">"foo"</span><span class="p">,</span> <span class="s">"bar"</span><span class="p">,</span> <span class="s">"baz"</span><span class="p">,</span> <span class="s">"qux"</span><span class="p">,</span> <span class="s">"quux"</span><span class="p">],</span>
        <span class="s">"C"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Write Parquet file with Snappy compression
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"example.snappy.parquet"</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">"SNAPPY"</span><span class="p">)</span>

<span class="c1"># Write Parquet file with Zstd compression
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"example.zstd.parquet"</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">"ZSTD"</span><span class="p">)</span>
</code></pre></div></div>

<p class="center"><em>Parquet files can be compressed as they&#8217;re written using parameters.</em></p>

<p>Parquet files may leverage compression to help reduce file size and increase data read performance.
Compression is applied at the page level, combining benefits from various encodings.
Data stored through Parquet is usually compressed when it is written, denoting the compression type through the filename (for example: <code class="language-plaintext highlighter-rouge">filename.snappy.parquet</code>).
<a href="https://en.wikipedia.org/wiki/Snappy_(compression)">Snappy</a> is often used as a common compression algorithm for Parquet data.
<a href="https://en.wikipedia.org/wiki/Brotli">Brotli</a>, <a href="https://en.wikipedia.org/wiki/Gzip">Gzip</a>, <a href="https://en.wikipedia.org/wiki/Zstd">ZSTD</a>, <a href="https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)">LZ4</a> are also sometimes used.
It&#8217;s worth exploring what compression works best for the data and systems you use (for example, <a href="https://www.uber.com/blog/cost-efficiency-big-data">ZSTD compression may hold benefits</a>).</p>

<h3 id="-strongly-typed-data"><i class="fas fa-icons"></i> &#8220;Strongly-typed&#8221; data</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

<span class="c1"># create a pyarrow table
</span><span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"A"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s">"B"</span><span class="p">:</span> <span class="p">[</span><span class="s">"foo"</span><span class="p">,</span> <span class="s">"bar"</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="s">"C"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># write the pyarrow table to a parquet file
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"example.parquet"</span><span class="p">)</span>

<span class="c1"># raises exception:
# ArrowTypeError: Expected bytes, got a 'int' object (for column B)
# Note: while this is an Arrow in-memory data exception, it also
# prevents us from attempting to perform incompatible operations
# within the Parquet file.
</span></code></pre></div></div>

<p class="center"><em>Data value must be all of the same type within a Parquet column.</em></p>

<p>Data within Parquet is <a href="https://en.wikipedia.org/wiki/Strong_and_weak_typing">&#8220;strongly-typed&#8221;</a>; specific data types (such as integer, string, etc.) are associated with each column, and thus value.
Attempting to store a data value type which does not match the column data type will usually result in an error.
This can lead to performance and compression benefits due to how quickly Parquet readers can determine the data type.
Strongly-typed data also embeds a kind of validation directly inside your work (data errors <a href="https://en.wikipedia.org/wiki/Shift-left_testing">&#8220;shift left&#8221;</a> and are often discovered earlier).
<a href="https://cu-dbmi.github.io/set-website/2023/10/04/Data-Quality-Validation.html">See here</a> for more on data quality validation topics we&#8217;ve written about.</p>

<h3 id="-complex-data-handling"><i class="fas fa-diagram-successor"></i> Complex data handling</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

<span class="c1"># create a pyarrow table with complex data types
</span><span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"A"</span><span class="p">:</span> <span class="p">[{</span><span class="s">"key1"</span><span class="p">:</span> <span class="s">"val1"</span><span class="p">},</span> <span class="p">{</span><span class="s">"key2"</span><span class="p">:</span> <span class="s">"val2"</span><span class="p">}],</span>
        <span class="s">"B"</span><span class="p">:</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
        <span class="s">"C"</span><span class="p">:</span> <span class="p">[</span>
            <span class="nb">bytearray</span><span class="p">(</span><span class="s">"😊"</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">)),</span>
            <span class="nb">bytearray</span><span class="p">(</span><span class="s">"🌻"</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">)),</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># write the pyarrow table to a parquet file
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"example.parquet"</span><span class="p">)</span>

<span class="c1"># read the schema of the parquet file
</span><span class="k">print</span><span class="p">(</span><span class="n">parquet</span><span class="p">.</span><span class="n">read_schema</span><span class="p">(</span><span class="n">where</span><span class="o">=</span><span class="s">"example.parquet"</span><span class="p">))</span>

<span class="c1"># prints:
# A: struct&lt;key1: string, key2: string&gt;
#   child 0, key1: string
#   child 1, key2: string
# B: list&lt;element: int64&gt;
#   child 0, element: int64
# C: binary
</span></code></pre></div></div>

<p class="center"><em>Parquet file columns may contain complex data types such as nested types (lists, dictionaries) and byte arrays.</em></p>

<p>Parquet files may store many data types that are complicated or impossible to store in other formats.
For example, images may be stored using the <a href="https://parquet.apache.org/docs/file-format/types/">byte array</a> storage type.
Nested data may be stored using <a href="https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#nested-types"><code class="language-plaintext highlighter-rouge">LIST</code> or <code class="language-plaintext highlighter-rouge">MAP</code> logical types</a>.
Dates or times may be stored using <a href="https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#temporal-types">various temporal data types.</a>
Oftentimes, complex data conversion within Parquet files is already implemented (for example, in <a href="https://arrow.apache.org/docs/developers/python.html">PyArrow</a>).</p>

<h3 id="-metadata"><i class="fas fa-tags"></i> Metadata</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

<span class="c1"># create a pyarrow table
</span><span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"A"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s">"B"</span><span class="p">:</span> <span class="p">[</span><span class="s">"foo"</span><span class="p">,</span> <span class="s">"bar"</span><span class="p">,</span> <span class="s">"baz"</span><span class="p">],</span>
        <span class="s">"C"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># add custom metadata to table
</span><span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="p">.</span><span class="n">replace_schema_metadata</span><span class="p">(</span><span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s">"data-producer"</span><span class="p">:</span> <span class="s">"CU DBMI SET Blog"</span><span class="p">})</span>

<span class="c1"># write the pyarrow table to a parquet file
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"example.snappy.parquet"</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">"SNAPPY"</span><span class="p">)</span>

<span class="c1"># read the schema
</span><span class="k">print</span><span class="p">(</span><span class="n">parquet</span><span class="p">.</span><span class="n">read_schema</span><span class="p">(</span><span class="n">where</span><span class="o">=</span><span class="s">"example.snappy.parquet"</span><span class="p">))</span>

<span class="c1"># prints
# A: int64
# B: string
# C: double
# -- schema metadata --
# data-producer: 'CU DBMI SET Blog'
</span></code></pre></div></div>

<p class="center"><em>Metadata are treated as a distinct and customizable components of Parquet files.</em></p>

<p>The Parquet format treats data about the data (metadata) separately from that of column value data.
<a href="https://parquet.apache.org/docs/file-format/metadata/">Parquet metadata</a> includes column names, data types, compression, various statistics about the file, and custom fields (in key-value form).
This metadata may be read without reading column value data which can assist with data exploration tasks (especially if the data are large).</p>

<h3 id="-multi-file-datasets"><i class="fas fa-folder-tree"></i> Multi-file &#8220;datasets&#8221;</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

<span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">(</span><span class="s">"./dataset"</span><span class="p">).</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># create pyarrow tables
</span><span class="n">table_1</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">({</span><span class="s">"A"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">table_2</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">({</span><span class="s">"A"</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]})</span>

<span class="c1"># write the pyarrow table to parquet files
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table_1</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"./dataset/example_1.parquet"</span><span class="p">)</span>
<span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table_2</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"./dataset/example_2.parquet"</span><span class="p">)</span>

<span class="c1"># read the parquet dataset
</span><span class="k">print</span><span class="p">(</span><span class="n">parquet</span><span class="p">.</span><span class="n">ParquetDataset</span><span class="p">(</span><span class="s">"./dataset"</span><span class="p">).</span><span class="n">read</span><span class="p">())</span>

<span class="c1"># prints (note that, for ex., [1] is a row group of column A)
# pyarrow.Table
# A: int64
# ----
# A: [[1],[2,3]]
</span></code></pre></div></div>

<p class="center"><em>Parquet datasets may be composed of one or many individual Parquet files.</em></p>

<p>Parquet files may be used individually or treated as a &#8220;dataset&#8221; through file groups which include the same schema (column names and types).
This means you can store &#8220;chunks&#8221; of Parquet-based data in one or many files and provides opportunities for intermixing or extending data.
When reading Parquet data this way libraries usually use the directory as a way to parse all files as a single dataset.
Multi-file datasets mean you gain the ability to store arbitrarily large amounts of data by sidestepping, for example, <a href="https://en.wikipedia.org/wiki/Inode">inode</a> limitations.</p>

<h3 id="-apache-arrow-memory-format-integration"><i class="fas fa-forward"></i> Apache Arrow memory format integration</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

<span class="c1"># create a pyarrow table
</span><span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Table</span><span class="p">.</span><span class="n">from_pydict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"A"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s">"B"</span><span class="p">:</span> <span class="p">[</span><span class="s">"foo"</span><span class="p">,</span> <span class="s">"bar"</span><span class="p">,</span> <span class="s">"baz"</span><span class="p">],</span>
        <span class="s">"C"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># write the pyarrow table to a parquet file
</span><span class="n">parquet</span><span class="p">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s">"example.parquet"</span><span class="p">)</span>

<span class="c1"># show schema of table and parquet file
</span><span class="k">print</span><span class="p">(</span><span class="n">table</span><span class="p">.</span><span class="n">schema</span><span class="p">.</span><span class="n">types</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">parquet</span><span class="p">.</span><span class="n">read_schema</span><span class="p">(</span><span class="s">"example.parquet"</span><span class="p">).</span><span class="n">types</span><span class="p">)</span>

<span class="c1"># prints
# [DataType(int64), DataType(string), DataType(double)]
# [DataType(int64), DataType(string), DataType(double)]
</span></code></pre></div></div>

<p class="center"><em>Parquet file and Arrow data types are well-aligned.</em></p>

<p>The Parquet format has robust support and integration with the <a href="https://arrow.apache.org/docs/index.html">Apache Arrow</a> memory format.
This enables consistency across Parquet integration and how the data are read using various programming languages (the Arrow memory format is relatively uniform across these).</p>

<h2 id="performance-with-parquet">Performance with Parquet</h2>

<p>Parquet files often outperforms traditional formats due to how it is designed.
Other data file formats may vary in performance contingent on specific configurations and system integration.
We urge you to perform your own testing to find out what works best for your circumstances.
See below for a list of references which compare Parquet to other formats.</p>

<ul>
  <li>CSV vs Parquet - <a href="https://posit.co/blog/speed-up-data-analytics-with-parquet-files/">Speed up data analytics and wrangling with Parquet files (Posit)</a></li>
  <li>CSV vs Parquet - <a href="https://dzone.com/articles/how-to-be-a-hero-with-powerful-parquet-google-and">Apache Parquet vs. CSV Files (DZone)</a></li>
  <li>Feather vs Parquet - <a href="https://ursalabs.org/blog/2020-feather-v2/">Feather V2 with Compression Support in Apache Arrow 0.17.0 (Ursa Labs)</a></li>
  <li>ORC vs Parquet - <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/cpe.5523">The impact of columnar file formats on SQL-on-hadoop engine performance: A study on ORC and Parquet (Concurrency and Computation: Practice and Experience)</a></li>
</ul>

<h2 id="how-can-you-use-parquet">How can you use Parquet?</h2>

<p>The Parquet format is common in many data management platforms and libraries.
Below are a list of just a few popular places where you can use Parquet.</p>

<ul>
  <li><strong>Python</strong>
    <ul>
      <li>Pandas (<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html"><code class="language-plaintext highlighter-rouge">pd.DataFrame.to_parquet()</code></a>, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_parquet.html"><code class="language-plaintext highlighter-rouge">pd.read_parquet()</code></a>)</li>
      <li>Apache Spark (<a href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html">Spark SQL Guide: Parquet Files</a>)</li>
      <li>PyTorch (<a href="https://pytorch.org/data/main/generated/torchdata.datapipes.iter.ParquetDataFrameLoader.html"><code class="language-plaintext highlighter-rouge">ParquetDataFrameLoader</code></a>)</li>
      <li>PyArrow (<a href="https://arrow.apache.org/docs/python/parquet.html">PyArrow: Reading and Writing the Apache Parquet Format</a>)</li>
    </ul>
  </li>
  <li><strong>R</strong>
    <ul>
      <li>dplyr (<a href="https://arrow.apache.org/docs/2.0/r/articles/dataset.html">Arrow: Working with Arrow Datasets and dplyr</a>)</li>
      <li>Arrow (<a href="https://arrow.apache.org/docs/r/reference/write_parquet.html"><code class="language-plaintext highlighter-rouge">write_parquet()</code></a>, <a href="https://arrow.apache.org/docs/r/reference/read_parquet.html"><code class="language-plaintext highlighter-rouge">read_parquet()</code></a>)</li>
      <li>DuckDB (<a href="https://duckdb.org/docs/api/r.html">DuckDB R API</a>, <a href="https://duckdb.org/docs/data/parquet/overview">DuckDB: Reading and Writing Parquet Files</a>)</li>
    </ul>
  </li>
</ul>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>

<p>This article covered the Parquet file format including notable features and usage.
Thank you for joining us on this exploration of Parquet.
We appreciate your support, hope the content here helps with your data decisions, and look forward to continuing the exploration of data formats in future posts.</p>]]></content><author><name>dave-bunten</name></author><category term="research-data-engineering" /><category term="file-formats" /><category term="large-data" /><category term="data-performance" /><category term="parquet" /><summary type="html"><![CDATA[Parquet: Crafting Data Bridges for Efficient Computation]]></summary></entry><entry><title type="html">Navigating Dependency Chaos with Lockfiles</title><link href="/set-website/preview/pr-46/2024/02/20/Navigating-Dependency-Chaos-with-Lockfiles.html" rel="alternate" type="text/html" title="Navigating Dependency Chaos with Lockfiles" /><published>2024-02-20T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2024/02/20/Navigating-Dependency-Chaos-with-Lockfiles</id><content type="html" xml:base="/set-website/preview/pr-46/2024/02/20/Navigating-Dependency-Chaos-with-Lockfiles.html"><![CDATA[<h1 id="navigating-dependency-chaos-with-lockfiles">Navigating Dependency Chaos with Lockfiles</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<!-- excerpt start -->
<p>Writing software often entails using code from other people to solve common challenges and take advantage of existing work.
External software used by a specific project can be called a &#8220;dependency&#8221; (the software &#8220;depends&#8221; on that external work to accomplish tasks).
Collections of software are oftentimes made available as &#8220;packages&#8221; through various platforms.
<a href="https://en.wikipedia.org/wiki/Package_manager">Package management</a> for dependencies, the task of managing collections of dependencies for a specific project, is a specialized area of software development that can involve the use of unique tools and files.
This article will cover package dependency management through special files generally referred to as &#8220;lockfiles&#8221;.
<!-- excerpt end --></p>

<h2 id="why-use-dependencies">Why use dependencies?</h2>

<figure class="figure">
  <a class="figure-image" aria-label="Reinvent the Wheel comic by Randall Munroe, XKCD.">
    <img src="https://imgs.xkcd.com/comics/reinvent_the_wheel.png" style="
        width: auto;
        max-height: unset;
      " alt="Reinvent the Wheel comic by Randall Munroe, XKCD." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      &#8216;Reinvent the Wheel&#8217; comic by Randall Munroe, XKCD.

    </figcaption>
  
</figure>

<p>There are various advantages to using packaged dependencies in your projects.
Using existing work this way practices a collective <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">&#8220;don&#8217;t repeat yourself [or ourselves]&#8221; (DRY)</a> among the global community of software developers to avoid <a href="https://en.wikipedia.org/wiki/Reinventing_the_wheel">reinventing the wheel</a>.
Using dependencies allows us to make explicit decisions about the specific focus, or context, which the project will prioritize.
While it&#8217;s oftentimes easy to include and use dependencies in a project they come with risks that are important to consider.</p>

<p>See below for a rough list of reasons why one might opt to use specific dependencies in a project:</p>

<ol>
  <li>Solutions which entail a lot of <a href="https://en.wikipedia.org/wiki/Edge_case">edge cases</a> (particularly error prone).</li>
  <li>Solutions which need constant maintenance, i.e. a &#8220;frequently moving targets&#8221;.</li>
  <li>Solutions which require special domain knowledge or training to correctly implement.</li>
</ol>

<p>A common dependency which demonstrates these aspects are those which assist with datetimes, timezones, and time deltas.</p>

<h2 id="the-dependency-wilderness">The dependency wilderness</h2>

<!-- set a max width for mermaid diagram below so it doesn't render so large -->
<style>
.mermaid {
  display: block;
  margin: 0 auto;
  max-height: 400px;
}
</style>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZ2FudHRcbnlvdXIgcHJvamVjdCA6YSwgMjAyNC0wNy0wMSwgM3dcbnBhbmRhcyA6YWN0aXZlICxiLCAyMDI0LTA3LTA3LCAxd1xubnVtcHkgOmFjdGl2ZSwgYywgMjAyNC0wNy0wOSwgMTBkXG5zY2lweSA6YWN0aXZlLCBkLCAyMDI0LTA3LTA0LCA2ZCIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Dependencies are often on their own unpredictable schedule outside of your project&#8217;s control.</em></p>

<p>Using existing software package dependencies helps conserve resources but comes with unique challenges related to unpredictability (such as when those dependencies are updated).
This unpredictability can sometimes result in what&#8217;s colloquially called <a href="https://en.wikipedia.org/wiki/Dependency_hell">&#8220;dependency hell&#8221; or &#8220;dependency chaos&#8221;</a>, where for example multiple external dependencies conflict with one another and are unable to be automatically resolved (among other issues).
These challenges can be especially frustrating due to when they occur (often outside of our personal schedule awareness) and how long they can take to debug (finding fixes sometimes entails costly <a href="https://en.wikipedia.org/wiki/Trial_and_error">trial-and-error</a>).
It can feel like walking through a forest at night without a flashlight, constantly tripping over roots or running into stumps and branches!</p>

<h2 id="illuminating-the-dependency-thicket">Illuminating the dependency thicket</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbmludmVudGlvbltcIk92ZXJ3aGVsbWluZ1xcbmludmVudGlvblwiXVxuZGVwZW5kZW5jeWNoYW9zW1wiSW5maW5pdGVcXG5kZXBlbmRlbmN5XFxuY2hhb3NcIl1cbiUlLVxuaW52ZW50aW9uIDwtLi4uLi4uLT4gfCBzb2Z0d2FyZSBkZXBlbmRlbmN5IFxcbiBjaG9pY2VzIHxkZXBlbmRlbmN5Y2hhb3NcbiUlLSIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Software dependency choices may be understood through careful consideration between the cost of internal overwhelming invention vs external dependency chaos.</em></p>

<p>Dependency chaos can sometimes lead to <a href="https://en.wikipedia.org/wiki/Not_invented_here">&#8220;not invented here syndrome&#8221;</a> where there&#8217;s less trust in external-facing work outside of an individual or group of people.
When or if this happens it can be important to understand dependencies as a <strong>scale of choices between overwhelming invention and infinite dependency chaos</strong>.
For example, to accomplish a small project it may not be wise to create a brand new programming language (towards the extreme of overwhelming invention).
On the other hand, if we depended upon all existing work within a certain context the solution may not be specialized, efficient, or resourceful enough to meet the goals within a reasonable amount of time.</p>

<script type="module">
  import mermaid from 'https://unpkg.com/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>

<pre class="mermaid">
mindmap
  root((Project))
    Data storage
      File 1
      Database 2
    Data x processing
      Package X
      Package Y
    Integration
      Solution A
      Platform B
</pre>

<p class="center"><em>Dependency awareness and opportunity can be grouped into concerns and documented as part of a literature review (seen here as a <a href="https://en.wikipedia.org/wiki/Mind_map">mind map</a>).</em></p>

<p>It can be helpful to reconsider existing knowledge on a topic area through formal or informal <a href="https://en.wikipedia.org/wiki/Literature_review">literature review</a> (understanding that code within software is a type of literature) when thinking about the scale of decisions mentioned above.
Outlining existing work through a literature review can help with <a href="https://en.wikipedia.org/wiki/Revision_(writing)#Reflection_in_the_revision_process">second-order thinking revision</a> where we might benefit from reflecting on dependency decision-making again after an initial (first-order) creative process.
Each potential dependency discovered through this process can be organized using <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns (SoC)</a> under specific <em>concern</em> labels, or a general set of information which affects related code.
Include dependencies within your project which will helpfully limit the code produced (or SoC <em>sections</em>) thereby reducing the overall amount of <em>concerns</em> the project must maintain.</p>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbnRleHRCW1wiQ29udGV4dCBBXCJdXG5kaXJlY3Rpb24gVEJcbnByb2Nlc3NlZDFbXCJkYXRhXCJdXG53aWRnZXRcbm1ldGFkYXRhMVtcIm1ldGFkYXRhXCJdXG5lbmRcbiUlLVxuc3ViZ3JhcGggY29udGV4dEFbXCJDb250ZXh0IEJcIl1cbmRpcmVjdGlvbiBUQlxucHJvY2Vzc2VkMltcImRhdGFcIl1cbmdpem1vXG5tZXRhZGF0YTJbXCJtZXRhZGF0YVwiXVxuZW5kXG4lJS1cbnByb2Nlc3NlZDEgPC0uLT4gfCBsb29vc2VseSBjb3VwbGVkXFxuc2hhcmVkIGNvbnRleHQgfCBwcm9jZXNzZWQyXG53aWRnZXQgfn5-IHwgZGlzdGluY3Qgc29sdXRpb25zXFxud2l0aCBkaWZmZXJlbnQgbmFtZXMgfCBnaXptb1xubWV0YWRhdGExIH5-fiB8IGRpc3RpbmN0IHNvbHV0aW9uc1xcbndpdGggdGhlIHNhbWUgbmFtZXMgfCBtZXRhZGF0YTIiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p class="center"><em>Bounded contexts along with shared or distinct components can be used to help limit the complexity of a project in helpful ways.</em></p>

<p>The concept of <a href="https://martinfowler.com/bliki/BoundedContext.html">bounded context</a> from <a href="https://en.wikipedia.org/wiki/Domain-driven_design">domain-driven design</a> can sometimes be used to help distinguish what is in or out of scope for a particular project as a way of reducing complexity.
Bounded context can be used as a way to draw abstract lines around a certain <a href="https://en.wikipedia.org/wiki/Span_of_control">span of control</a> in order to align available resources (like time and people) with the focus of the project.
It also can help promote <a href="https://en.wikipedia.org/wiki/Loose_coupling">loose coupling</a> of software components in order to enable flexible design over time.
Without these considerations and the use of dependencies we might face &#8220;endless&#8221; software <a href="https://en.wikipedia.org/wiki/Feature_creep">feature creep</a> by continually adding new bounded contexts that are outside of our span of control (or resources).</p>

<h2 id="version-constraints-as-dependency-specification-control">Version constraints as dependency specification control</h2>

<table>
<tr>
<th>Version constraint</th>
<th>Description of the version constraint</th>
</tr>
<tr>
<td>

`==2.1.0`

</td>
<td>Exactly and only version 2.1.0</td>
</tr>
<tr>
<td>

`&gt;=2.0.0`

</td>
<td>Greater than or equal to version 2.0.0</td>
</tr>
<tr>
<td>

`&gt;=2.0.0, &lt;3.0.0`

</td>
<td>Greater than or equal to version 2.0.0 and less than 3.0.0</td>
</tr>
<tr>
<td>

`&gt;=2.0.0, &lt;3.0.0, !=2.5.1`

</td>
<td>Greater than or equal to version 2.0.0, less than 3.0.0, and anything that's not exactly version 2.5.1</td>
</tr>
</table>

<p class="center"><em>Version constraint specifications provide code-based descriptions for dependency versions within your project (Pythonic version specification examples above).</em></p>

<p>Many aspects of dependency chaos arise from the fact that dependencies are updated at various times.
We often want to make certain we use the most up-to-date version of a dependency because those updates may come with performance, corrective, security, or other benefits.
To accomplish this we can use what are sometimes called dependency &#8220;version range constraints&#8221; or &#8220;compliant version specifications&#8221; to provide some flexibility in how packages are installed for our projects.
Version ranges are usually preferred to help keep software projects updated and also allow for flexible dependency resolutions (for example, when a single dependency is required by multiple other dependencies).
These are often specific to the package management system and programming language being used.
See the <a href="https://packaging.python.org/en/latest/specifications/version-specifiers/#id5">Python Packaging Authority&#8217;s Version Specifiers section</a> for an example of how these version constraints work.</p>

<p>Many version specification constraints build upon ideas from <a href="https://en.wikipedia.org/wiki/Software_versioning#Semantic_versioning">semantic versioning (SemVer)</a>.
Generally, SemVer uses a dotted three number syntax which includes a major, minor, and patch version separated by periods.
For example, a SemVer <code class="language-plaintext highlighter-rouge">1.2.3</code> represents major version 1, minor version 2, patch 3.
Developers may use of this type of specification to help differentiate the various releases of their software and help build user confidence about expected operations.
See the <a href="https://semver.org/">Semantic Versioning specification at https://semver.org/</a> for more information about how SemVer works.</p>

<h2 id="version-constraints-can-still-be-chaotic">Version constraints can still be chaotic</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtXG5hdXRvbnVtYmVyXG5EZXBlbmRlbmN5IEEgKERlcEEpIC0-PlJlbGVhc2UgUGxhdGZvcm06IHYxLjAuMCBSZWxlYXNlZCFcblJlbGVhc2UgUGxhdGZvcm0tPj5EZXZlbG9wZXIgQjogSW5zdGFsbCBEZXBBID49IDEuMC4wXG5EZXZlbG9wZXIgQi0-PlByb2plY3QgQzogQWRkIGNvbnN0cmFpbnQgRGVwQSA-PSAxLjAuMFxuRGVwZW5kZW5jeSBBIChEZXBBKSAtPj5SZWxlYXNlIFBsYXRmb3JtOiB2MS4xLjAgUmVsZWFzZWQhXG5Qcm9qZWN0IEMgLT4-IERldmVsb3BlciBEOiBJbnN0YWxsIGZyb20gcHJvamVjdFxuRGV2ZWxvcGVyIEQgLS0-PiBSZWxlYXNlIFBsYXRmb3JtOiBMb29rIGZvciB2ZXJzaW9uIHdoaWNoIG1hdGNoZXMgY29uc3RyYWludCAoPj0gMS4wLjApXG5SZWxlYXNlIFBsYXRmb3JtIC0-PiBEZXZlbG9wZXIgRDogSW5zdGFsbCBEZXBBIHYxLjEuMCAoPj0gMS4wLjApXG5EZXZlbG9wZXIgRC0-PiBQcm9qZWN0IEM6IEFkZCBuZXcgZmVhdHVyZVxucmVjdCByZ2IoMjU0LCAyMjYsIDIyNilcblByb2plY3QgQy0-PiBEZXZlbG9wZXIgRDogQXV0b21hdGVkIHRlc3RzIGZhaWwgZHVlIHRvIERlcEEgY2hhbmdlcyFcbmVuZCIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Unintentional failures can occur due to timeline variations between internal projects and external dependencies.</em></p>

<p>We sometimes require repeatable behavior to be productive with a project in addition to the flexibility of version range specifications.
For example, we may want for each developer and continuous integration step to have reproducible environments even if a dependency gets updated while internal development takes place.
Dependency version constraints oftentimes aren&#8217;t enough on their own to prevent reproducibility issues from occurring.
See the above diagram for a timeline depicting how <code class="language-plaintext highlighter-rouge">Developer B</code> and <code class="language-plaintext highlighter-rouge">Developer D</code> may have different experiences despite best efforts with version constraints (<code class="language-plaintext highlighter-rouge">Dependency A</code> may make a release that fits the version constraint but breaks <code class="language-plaintext highlighter-rouge">Project C</code> when <code class="language-plaintext highlighter-rouge">Developer D</code> tries to modify unrelated code).</p>

<h2 id="lockfiles-for-reproducible-version-constraint-behavior">Lockfiles for reproducible version constraint behavior</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtXG5hdXRvbnVtYmVyXG5EZXBlbmRlbmN5IEEgKERlcEEpIC0-PlJlbGVhc2UgUGxhdGZvcm06IHYxLjAuMCBSZWxlYXNlZCFcblJlbGVhc2UgUGxhdGZvcm0tPj5EZXZlbG9wZXIgQjogSW5zdGFsbCBEZXBBID49IDEuMC4wXG5EZXZlbG9wZXIgQi0-PlByb2plY3QgQzogQWRkIGNvbnN0cmFpbnQgRGVwQSA-PSAxLjAuMCAod2l0aCBsb2NrZmlsZSlcbkRlcGVuZGVuY3kgQSAoRGVwQSkgLT4-UmVsZWFzZSBQbGF0Zm9ybTogdjEuMS4wIFJlbGVhc2VkIVxuUHJvamVjdCBDIC0-PiBEZXZlbG9wZXIgRDogSW5zdGFsbCBmcm9tIHByb2plY3RcbkRldmVsb3BlciBEIC0tPj4gUmVsZWFzZSBQbGF0Zm9ybTogTG9vayBmb3IgdmVyc2lvbiB3aGljaCBtYXRjaGVzIGNvbnN0cmFpbnQgKD49IDEuMC4wKSBhbmQgbG9ja2ZpbGUgZGF0YSBhYm91dCB2ZXJzaW9uc1xuUmVsZWFzZSBQbGF0Zm9ybSAtPj4gRGV2ZWxvcGVyIEQ6IEluc3RhbGwgRGVwQSB2MS4wLjAgKG1hdGNoaW5nID49IDEuMC4wIGFuZCBsb2NrZmlsZSByZWZlcmVuY2UgdG8gdmVyc2lvbnMgYXZhaWxhYmxlIHRvIHByZXZpb3VzIGNoYW5nZXMpXG5EZXZlbG9wZXIgRC0-PiBQcm9qZWN0IEM6IEFkZCBuZXcgZmVhdHVyZVxucmVjdCByZ2IoMjA5LCAyNTAsIDIyOSlcblByb2plY3QgQy0-PiBEZXZlbG9wZXIgRDogQXV0b21hdGVkIHRlc3RzIGlzb2xhdGUgb2JzZXJ2YXRpb25zIHRvIG5ldyBmZWF0dXJlXG5lbmQiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p>Version constraint lockfiles provide one way to ensure reproducible behaviors within your projects.
Lockfiles are usually recommended to be included in source control, so one always has a complete snapshot (short of the literal full source code of the dependencies) of the project&#8217;s last known working configuration.</p>

<p>Lockfiles usually have the following characteristics (this varies by programming language and dependency type):</p>

<ul>
  <li>Lockfiles capture data about existing available and installable dependencies which match a provided version constraint specification as a single file which can be added to source control.</li>
  <li>Lockfiles are referenced when available to help create reproducible installations of dependencies.</li>
  <li>Lockfiles are often automatically created or changed by a package or environment management tool of some kind.</li>
  <li>Lockfiles focus on reproducibility of dependency installations and don&#8217;t enable dependency resolution on their own (this is instead a part of version range specification and package management tools).</li>
  <li>Lockfiles are used by developers, automated procedures (as with <a href="https://en.wikipedia.org/wiki/CI/CD">CI/CD</a> procedures), <a href="https://en.wikipedia.org/wiki/Deployment_environment#Production">production deployment environments</a>, and elsewhere to help ensure reproducibility.</li>
</ul>

<p>See the above modified timeline for <code class="language-plaintext highlighter-rouge">Developer B</code> and <code class="language-plaintext highlighter-rouge">Developer D</code> to better understand how their project will benefit from a shared lockfile and reproducible dependency installations.</p>

<h2 id="pythonic-example">Pythonic Example</h2>

<table>
<tr>
<th>Python Poetry command used</th>
<th>Description of what occurs</th>
</tr>
<tr>
<td>

`poetry add pandas`

</td>
<td>

- Adds a [__caret-based version constraint specification__](https://python-poetry.org/docs/dependency-specification/#caret-requirements) based on the latest release (for example `^2.2.1`) within a `pyproject.toml` file. This version constraint can be understood as `&gt;= 2.2.1, &lt; 2.3.0`.
- Create or update the `poetry.lock` lockfile with known compatible versions of Pandas based on the version constraint mentioned above.
- Installs the version of Pandas which matches the `pyproject.toml` and `poetry.lock` specifications.

</td>
</tr>
<tr>
<td>

`poetry install`

</td>
<td>

Installs the version of Pandas which matches the `pyproject.toml` and `poetry.lock` specifications (for example, within a new environment or for another developer).

</td>
</tr>
<tr>
<td>

`poetry update pandas`

</td>
<td>

- Poetry checks for available Pandas releases which are compatible with the version constraint (for ex. `^2.2.1`).
- If there are new versions available which match the constraint, Poetry will update the `poetry.lock` lockfile and install the matching version.

</td>
</tr>
<tr>
<td>

`poetry lock`

</td>
<td>

- Update all dependencies referenced in the `poetry.lock` lockfile with the latest compatible versions based on the version constraints specified within the `pyproject.toml`.
- Optionally, if the `--no-update` flag is also used, refresh the dependency versions referenced within the `poetry.lock` lockfile based on version constraints specified within the `pyproject.toml` without seeking updated dependency releases.

</td>
</tr>
</table>

<p class="center"><em>Use Poetry commands to implement dependency version constraints and lockfiles for reproducible Python project environments.</em></p>

<p><a href="https://python-poetry.org/">Poetry</a> is a Python packaging and dependency management tool which implements version constraints and lockfiles to help developers maintain their software projects.
Using commands like <code class="language-plaintext highlighter-rouge">poetry add ...</code> and <code class="language-plaintext highlighter-rouge">poetry lock</code> automatically creates <code class="language-plaintext highlighter-rouge">poetry.lock</code> lockfiles based on specifications which are added either automatically or manually to <code class="language-plaintext highlighter-rouge">pyproject.toml</code> files.
Similar to other tools, Poetry can operate with or without <code class="language-plaintext highlighter-rouge">poetry.lock</code> lockfiles (<a href="https://python-poetry.org/docs/basic-usage/#committing-your-poetrylock-file-to-version-control">see here for more information</a>).
Another alternative to Poetry which makes use of lockfiles is <a href="https://pdm-project.org/latest/usage/dependency/#specify-the-lockfile-to-use">PDM (<code class="language-plaintext highlighter-rouge">pdm.lock</code> files)</a>.</p>

<h2 id="avoiding-over-constrained-dependencies">Avoiding over-constrained dependencies</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnByb2plY3RbXCJQcm9qZWN0XCJdXG5kZXZlbG9wZXJbXCJEZXZlbG9wZXJcIl1cbmRlcGJvdFtcIkRlcGVuZGVuY3lcXG5DaGVja2luZyBUb29sXCJdXG5zZWN1cml0eXZ1bG5bXCJTZWN1cml0eVxcblZ1bG5lcmFiaWxpdHlcIl1cbnByW1wiUHVsbFxcblJlcXVlc3RcIl1cbiUlLVxuZGV2ZWxvcGVyIC0tPiB8IHJldmlld3NcXG5jaGFuZ2VzIHwgcHJcbnNlY3VyaXR5dnVsbiAtLT4gfCBhbm5vdW5jZWQgYW5kXFxuY29uc2lkZXJlZCBieSB8IGRlcGJvdFxuZGVwYm90IC0tPiB8IG9wZW5zIFBSIHdpdGhcXG5yZWxhdGVkIGZpeCB8IHByXG5wciAtLT4gcHJvamVjdCIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Automated dependency checking tools like Dependabot or Renovate can be used to reduce project risk through timely dependency update changes assisted by human reviewers.</em></p>

<p>Using dependency version constraints and lockfiles are helpful for reproducibility but imply a risk of over-constraint.
Two important over-constraint considerations are:</p>

<ul>
  <li><strong>Bug fixes:</strong> we may perpetuate an incorrect or failing solution within our project as the result of not installing later releases of a dependency.</li>
  <li><strong>Security fixes:</strong> we may unknowingly create security risks for others through the inclusion of known <a href="https://en.wikipedia.org/wiki/Vulnerability_(computing)">security vulnerable</a> dependency versions.</li>
</ul>

<p>Make sure to address these risks by routinely considering whether your dependencies need to be updated (manually) or through the use of automated tools like <a href="https://github.blog/2020-06-01-keep-all-your-packages-up-to-date-with-dependabot/">GitHub&#8217;s Dependabot</a> or <a href="https://github.com/renovatebot/renovate">Mend Renovate</a>.
Tools like Dependabot or Renovate enable scheduled checks and updates to be applied to your project which can lead to a balanced way of ensuring risk reduction and productive future-focused development.</p>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>

<p>This article covered why dependencies are used, what complications they come with, and some tools to use addressing those challenges.
Every project can vary quite a bit when it comes to dependency management decision making and maintenance.
We hope you find success with dependency management through these and look forward to providing more information on this topic in the future.</p>]]></content><author><name>dave-bunten</name></author><category term="software-education" /><category term="python" /><category term="lockfiles" /><category term="dependency-management" /><category term="environment-management" /><category term="software-ecosystems" /><category term="dependency-chaos" /><summary type="html"><![CDATA[Navigating Dependency Chaos with Lockfiles]]></summary></entry><entry><title type="html">Python Memory Management and Troubleshooting</title><link href="/set-website/preview/pr-46/2024/01/22/Python-Memory-Management-and-Troubleshooting.html" rel="alternate" type="text/html" title="Python Memory Management and Troubleshooting" /><published>2024-01-22T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2024/01/22/Python-Memory-Management-and-Troubleshooting</id><content type="html" xml:base="/set-website/preview/pr-46/2024/01/22/Python-Memory-Management-and-Troubleshooting.html"><![CDATA[<h1 id="python-memory-management-and-troubleshooting">Python Memory Management and Troubleshooting</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>These blog posts are intended to provide software tips, concepts, and tools geared towards helping you achieve your goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any questions or suggestions for blog posts, please don&#8217;t hesitate to reach out!</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<!-- excerpt start -->
<p>Have you ever run Python code only to find it taking <em>forever</em> to complete or sometime abruptly ending with an error like: <code class="language-plaintext highlighter-rouge">123456 Killed</code> or <code class="language-plaintext highlighter-rouge">killed (program exited with code: 137)</code>?
You may have experienced memory resource or management challenges associated with these scenarios.
This post will cover some computer memory definitions, how Python makes use of computer memory, and share some tools which may help with these types of challenges.
<!-- excerpt end --></p>

<h2 id="what-is-software">What is Software?</h2>

<!-- set a max width for mermaid diagram below so it doesn't render so large -->
<style>
.mermaid {
  display: block;
  margin: 0 auto;
  max-height: 400px;
}
</style>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyIChyZXNvdXJjZXMpXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIHN0b3JhZ2VbXCJEYXRhIFN0b3JhZ2VcIl1cbnN1YmdyYXBoIHNvZnR3YXJlW1wiQ29tcHV0ZXIgU29mdHdhcmVcIl1cbnByb2dyYW1bXCJQcm9ncmFtKHMpXFxuKHNlcXVlbmNlcyBvZiBpbnN0cnVjdGlvbnMpXCJdXG5kb2N1bWVudGF0aW9uW1wiRG9jdW1lbnRhdGlvblwiXVxub3RoZXJfZGF0YVtcIk90aGVyIHJlbGF0ZWQgZGF0YVwiXVxuZW5kXG5lbmRcbmVuZFxuJSUtXG5zdHlsZSBjb21wdXRlciBmaWxsOiNmZmYsc3Ryb2tlOiMzMzNcbnN0eWxlIHN0b3JhZ2UgZmlsbDojZmZmLHN0cm9rZTojMzMzXG5zdHlsZSBzb2Z0d2FyZSBmaWxsOiM4NkVGQUMsc3Ryb2tlOiMzMzMiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p class="center"><em>Computer software includes programs, documentation, and other data maintained on computer data storage.</em></p>

<p>Computer software is the collection of programs and data which are used to accomplish a specific tasks on a computer.
&#8220;A <strong>computer program</strong> is a sequence or set of instructions in a programming language for a computer to execute. It is one component of software, which also includes documentation and other intangible components.&#8221; (<a href="https://en.wikipedia.org/wiki/Computer_program">Wikipedia: Computer program</a>).
Computer programs in their human-readable form are stored as <strong>source code</strong>.
Source code is often maintained on <a href="https://en.wikipedia.org/wiki/Computer_data_storage">computer data storage</a>.</p>

<h2 id="what-is-memory">What is Memory?</h2>

<h3 id="computer-memory">Computer Memory</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyIChyZXNvdXJjZXMpXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIHN0b3JhZ2VbXCJEYXRhIFN0b3JhZ2VcIl1cbnN1YmdyYXBoIHNvZnR3YXJlW1wiQ29tcHV0ZXIgU29mdHdhcmVcIl1cbnByb2dyYW1bXCJmYTpmYS1maWxlIFByb2dyYW0ocylcXG4oc2VxdWVuY2VzIG9mIGluc3RydWN0aW9ucylcIl1cbmVuZFxuZW5kXG5zdWJncmFwaCBtZW1vcnlbXCJNZW1vcnlcIl1cbnByb2Nlc3NbXCJmYTpmYS1yZWZyZXNoIFByb2Nlc3NcXG4ob25lIG9yIG1hbnkpXCJdXG5lbmRcbmVuZFxuJSUtXG5wcm9ncmFtIC0tPiB8IGxvYWRlZCBpbnRvXFxubWVtb3J5IGFzIHwgcHJvY2Vzc1xuJSUtXG5zdHlsZSBjb21wdXRlciBmaWxsOiNmZmYsc3Ryb2tlOiMzMzNcbnN0eWxlIHN0b3JhZ2UgZmlsbDojZmZmLHN0cm9rZTojMzMzXG5zdHlsZSBtZW1vcnkgZmlsbDojODZFRkFDLHN0cm9rZTojMzMzXG5zdHlsZSBzb2Z0d2FyZSBmaWxsOiNmZmYsc3Ryb2tlOiMzMzMiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p class="center"><em>Computer memory is a type of computer resource available for use by processes on a computer.</em></p>

<p>Computer memory, also sometimes known as &#8220;RAM&#8221; or &#8220;random-access memory&#8221;, or &#8220;dynamic memory&#8221; is a type of resource used by computer software on a computer.
<em>&#8220;Computer memory stores information, such as data and programs for immediate use in the computer. &#8230; Main memory operates at a high speed compared to non-memory storage which is slower but less expensive and oftentimes higher in capacity. &#8220; (<a href="https://en.wikipedia.org/wiki/Computer_memory">Wikipedia: Computer memory</a>).</em>
When we execute a computer program it becomes a <a href="https://en.wikipedia.org/wiki/Process_(computing)">process</a> (or sometimes many processes).
Processes are loaded into computer memory to follow the instructions and other data provided from their related computer programs.</p>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>The word &#8220;speed&#8221; in the above context is sometimes used to describe  the delay before an operation on a computer completes (also known as <em>latency</em>).
See the following on [Computer] <a href="https://www.softwareyoga.com/latency-numbers-everyone-should-know/">Latency Numbers Everyone Should Know</a> to better understand relative computer operation speeds.</p>


  </div>
</div>

<table>
<tr>
<th style="background-color:#E9DCFB;">Process Memory Segment</th>
<th style="background-color:#eee;">Purpose</th>
</tr>
<tr>
<td style="background-color:#E9EAFB;">Stack</td>
<td>Contains information about sequences of program instructions as functions or subroutines.</td>
</tr>
<tr>
<td style="background-color:#E9EAFB;">Heap</td>
<td>Area where memory for variables may be dynamically used.</td>
</tr>
<tr>
<td style="background-color:#E9EAFB;">Initialized data</td>
<td>Includes global and static variables which are explicitly initialized.</td>
</tr>
<tr>
<td style="background-color:#E9EAFB;">Uninitialized data</td>
<td>Includes global and static variables which are <strong>not</strong> explicitly initialized.</td>
</tr>
<tr>
<td style="background-color:#E9EAFB;">Text</td>
<td>Comprises program instructions for the process.</td>
</tr>
</table>

<p class="center"><em>Process memory is divided into segments which have specific purposes (<a href="https://learning.oreilly.com/library/view/the-linux-programming/9781593272203/xhtml/ch06.xhtml#ch06lev1sec03">The Linux Programming Interface by Michael Kerrisk</a>).</em></p>

<p>Memory for a process is further divided into parts which are typically called <em>segments</em>.
Each process memory segment has a specific purpose and way of organizing things.
For the purposes of this content we&#8217;ll focus on two of these segments: the stack and the heap.
The <a href="https://en.wikipedia.org/wiki/Call_stack"><strong><em>stack</em></strong> (sometimes also known as the &#8220;call stack&#8221;)</a> includes information about sequences of program instructions packaged as units called <a href="https://en.wikipedia.org/wiki/Function_(computer_programming)">&#8220;functions&#8221; or &#8220;subroutines&#8221;</a>.
The stack also typically stores function local variables, arguments, and return value.
The <a href="https://en.wikipedia.org/wiki/Memory_management#HEAP"><strong><em>heap</em></strong></a> is an area where variables for a program may be dynamically stored.
The stack can be thought of as a <i class="icon fa-solid fa-map"></i> &#8220;roadmap&#8221; for what program will accomplish (including the location of things it will need to do that work).
The heap can be imagined of as a <i class="icon fa-solid fa-warehouse"></i> &#8220;warehouse&#8221; store (or remove) things used as part of the stack &#8220;roadmap&#8221;.
Please see <a href="https://learning.oreilly.com/library/view/the-linux-programming/9781593272203/xhtml/ch06.xhtml#ch06lev1sec03">The Linux Programming Interface by Michael Kerrisk, Chapter 6.3: Memory Layout of a Process</a> for more information about processes.</p>

<table>
<tr><th colspan="2">Memory Blocks</th></tr>
<tr>
<td>

<div>
<strong>A.)</strong> All memory blocks available.

<table>
<tr><td>Block</td><td>Block</td><td>Block</td></tr>
</table>
</div>

</td>
<td>

<div>
<strong>B.)</strong> Some memory blocks in use.


<table>
<tr><td style="background:#86EFAC;">Block</td><td style="background:#86EFAC;">Block</td><td>Block</td></tr>
</table>
</div>

</td>
</tr>
<tr>
<td colspan="2" style="text-align:center;font-weight:bold;">Practical analogy</td>
</tr>
<tr>
<td>

<div>
<strong>C.)</strong> You have limited boxes to hold things.

<table>
<tr><td>📦</td><td>📦</td><td>📦</td></tr>
</table>
</div>

</td>
<td>

<div>
<strong>D.)</strong> Two boxes are used, the other remains empty (ready for use).

<table>
<tr><td style="background:#86EFAC;">📦</td><td style="background:#86EFAC;">📦</td><td>📦</td></tr>
</table>
</div>

</td>
</tr>
</table>

<p class="center"><em>Memory blocks may be free or used at various times. They can be thought of like reusable buckets to hold things.</em></p>

<p>The heap is often further organized through the use of <strong><em>&#8220;blocks&#8221;</em></strong>.
Memory blocks are chunks of memory of a certain <a href="https://en.wikipedia.org/wiki/Byte">byte</a> or <a href="https://en.wikipedia.org/wiki/Bit">bit</a> size (usually all the same size) (<a href="https://en.wikipedia.org/wiki/Block_(data_storage)">Wikipedia: Block (data storage)</a>).
Memory blocks may be in use or free at different times.
If the heap is a process memory <i class="icon fa-solid fa-warehouse"></i> &#8220;warehouse&#8221; then blocks are like <i class="icon fa-solid fa-boxes-stacked"></i> &#8220;boxes&#8221; inside the warehouse.</p>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyIChyZXNvdXJjZXMpXCJdXG5zdWJncmFwaCBtZW1vcnlbXCJNZW1vcnlcIl1cbnN1YmdyYXBoIHByb2Nlc3MgW1wiUHJvY2Vzc1wiXVxuc3ViZ3JhcGggaGVhcCBbXCJoZWFwXCJdXG5kaXJlY3Rpb24gVEJcbnN1YmdyYXBoIHBvb2wgW1wicG9vbChzKVwiXVxuYmxvY2tzMVtcImJsb2NrKHMpXCJdXG5lbmRcbmVuZFxuZW5kXG5lbmRcbmVuZFxuJSUtXG5zdHlsZSBjb21wdXRlciBmaWxsOiNmZmYsc3Ryb2tlOiMzMzNcbnN0eWxlIHBvb2wgZmlsbDojQkZEQkZFLHN0cm9rZTojMzMzOyIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Process memory heaps help organize memory blocks on a computer for specific procedures. Heaps may have one or many memory pools.</em></p>

<p>Blocks may be organized in hierarchical layers to manage memory efficiently or towards a specific purpose.
Blocks may sometimes be organized into <a href="https://en.wikipedia.org/wiki/Memory_pool"><strong><em>pools</em></strong></a> within the process memory heap segment.
Pools are areas of the heap used to efficiently manage blocks together in specific ways.
Each heap may have one or many pools (each with sets of blocks).
If the heap is a process memory <i class="icon fa-solid fa-warehouse"></i> &#8220;warehouse&#8221;, and blocks are like <i class="icon fa-solid fa-boxes-stacked"></i> &#8220;boxes&#8221; inside the warehouse, pools are like <i class="icon fa-solid fa-boxes-packing"></i> &#8220;shelves&#8221; for organizing and moving those boxes within the warehouse.</p>

<h3 id="memory-allocator">Memory Allocator</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtXG4lJS1cbnNvZnR3YXJlIC0-PiBhbGxvY2F0b3I6XCJJIG5lZWQgc29tZSBtZW1vcnksIHBsZWFzZSFcIlxuYWxsb2NhdG9yIC0-PiBtZW1vcnk6QWxsb2NhdGUgcG9ydGlvbiBvZiAgbWVtb3J5IGZvciB1c2Vcbm1lbW9yeSAtPj4gYWxsb2NhdG9yOkFsbG9jYXRlZCBtZW1vcnkgZm9yIHVzZVxuYWxsb2NhdG9yIC0-PiBzb2Z0d2FyZTpcIkhlcmUncyBzb21lIG1lbW9yeSB0byB1c2UhXCJcbiUlLVxuc29mdHdhcmUgLT4-IGFsbG9jYXRvcjpcIkknbSBmaW5pc2hlZCB3aXRoIHRoYXQgbWVtb3J5IVwiXG5hbGxvY2F0b3IgLT4-IG1lbW9yeTpGcmVlIHRoZSBtZW1vcnkgZm9yIG90aGVyIHB1cnBvc2VzLiIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Memory allocators help software reserve and free computer memory resources.</em></p>

<p>Memory management is a concept which helps enable the shared use of computer memory to avoid challenges such as memory overuse (where all memory is in use and never shared to other software).
Computer memory management often occurs through the use of a <strong><em>memory allocator</em></strong> which controls how computer memory resources are used for software.
Computer software is written to interact with memory allocators to use computer memory.
Memory allocators may be used manually (with specific directions provided on when and how to use memory resources) or automatically (with an algorithmic approach of some kind).
The memory allocator usually performs the following actions with memory (in addition to others):</p>

<ul>
  <li><strong>&#8220;Allocation&#8221;</strong>: computer memory resource reservation (taking memory). This is sometimes also known as &#8220;<code class="language-plaintext highlighter-rouge">alloc</code>&#8221;, or &#8220;allocate memory&#8221;.</li>
  <li><strong>&#8220;Deallocation&#8221;</strong>: computer memory resource freeing (giving back memory for other uses). This is sometimes also known as &#8220;<code class="language-plaintext highlighter-rouge">free</code>&#8221;, or &#8220;freeing memory from allocation&#8221;.</li>
</ul>

<h3 id="garbage-collection">Garbage Collection</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoic2VxdWVuY2VEaWFncmFtXG4lJS1cbnBhcnRpY2lwYW50IHNvZnR3YXJlXG5wYXJ0aWNpcGFudCBtZW1vcnkgYWxsb2NhdG9yXG5wYXJ0aWNpcGFudCBnYXJiYWdlIGNvbGxlY3RvclxucGFydGljaXBhbnQgbWVtb3J5XG4lJS1cbnNvZnR3YXJlIC0-PiBtZW1vcnkgYWxsb2NhdG9yOlwiSSBuZWVkIHNvbWUgbWVtb3J5LCBwbGVhc2UhXCJcbm1lbW9yeSBhbGxvY2F0b3IgLT4-IG1lbW9yeTpBbGxvY2F0ZSBwb3J0aW9uIG9mICBtZW1vcnkgZm9yIHVzZVxubWVtb3J5IC0-PiBtZW1vcnkgYWxsb2NhdG9yOkFsbG9jYXRlZCBtZW1vcnkgZm9yIHVzZVxubWVtb3J5IGFsbG9jYXRvciAtPj4gc29mdHdhcmU6XCJIZXJlJ3Mgc29tZSBtZW1vcnkgdG8gdXNlIVwiXG4lJS1cbnNvZnR3YXJlIC0tPj4gZ2FyYmFnZSBjb2xsZWN0b3IgOihzb2Z0d2FyZSBmaW5pc2hlcyB3aXRoIG1lbW9yeSB1c2FnZSwgc29tZXRpbWVzIGltcGxpY2l0bHkpXG5nYXJiYWdlIGNvbGxlY3RvciAgLT4-IG1lbW9yeTpGcmVlIHRoZSBtZW1vcnkgZm9yIG90aGVyIHB1cnBvc2VzLiIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Garbage collectors help free computer memory which is no longer referenced by software.</em></p>

<p>&#8220;Garbage collection (GC)&#8221; is used to describe a type of automated memory management.
GC is typically used to help reduce human error, avoid unintentional system failures, and decrease development time (through less memory-specific code).
&#8220;The <em>garbage collector</em> attempts to reclaim memory which was allocated by the program, but is no longer referenced; such memory is called <em>garbage</em>.&#8221; (<a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">Wikipedia: Garbage collection (computer science)</a>).
A garbage collector often works in tandem with a memory allocator to help control computer memory resource usage in software development.</p>

<h2 id="how-does-python-interact-with-computer-memory">How Does Python Interact with Computer Memory?</h2>

<h3 id="python-overview">Python Overview</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIG1lbW9yeVtcIk1lbW9yeVwiXVxucHJvY2Vzc1tcIlB5dGhvbiBwcm9jZXNzXCJdXG5lbmRcbmNvZGVbXCJQeXRob24gY29kZVwiXVxuaW50ZXJwcmV0ZXJbXCJQeXRob24gaW50ZXJwcmV0ZXJcIl1cbmVuZFxuJSUtXG5jb2RlIC0tPiB8aW50ZXJwcmV0ZWQgYW5kXFxuZXhlY3V0ZWQgYnl8IGludGVycHJldGVyXG5pbnRlcnByZXRlciA8LS0-IHxleGVjdXRlcyBhbmQgbWFuYWdlc1xcbiBwcm9jZXNzIG1lbW9yeXwgcHJvY2Vzc1xuJSUtXG5zdHlsZSBjb21wdXRlciBmaWxsOiNmZmYsc3Ryb2tlOiMzMzNcbnN0eWxlIG1lbW9yeSBmaWxsOiM4NkVGQUMsc3Ryb2tlOiMzMzNcbnN0eWxlIGNvZGUgZmlsbDojNjdFOEY5LHN0cm9rZTojMzMzO1xuc3R5bGUgaW50ZXJwcmV0ZXIgZmlsbDojRkRCQTc0LHN0cm9rZTojMzMzOyIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>A Python interpreter executes Python code and manages memory for Python procedures.</em></p>

<p>Python is an interpreted &#8220;high-level&#8221; programming language (<a href="https://www.python.org/doc/essays/blurb/">Python: What is Python?</a>).
Interpreted languages are those which include an &#8220;interpreter&#8221; which helps execute code written in a particular way (<a href="https://en.wikipedia.org/wiki/Interpreter_(computing)">Wikipedia: Interpreter (computing)</a>).
High-level languages such as Python often remove the requirement for software developers to manually perform memory management (<a href="https://en.wikipedia.org/wiki/High-level_programming_language">Wikipedia: High-level programming language</a>).</p>

<p>Python code is executed by a commonly pre-packaged and downloaded binary call the Python <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)">interpreter</a>.
The Python interpreter reads Python code and performs memory management as the code is executed.
The <a href="https://github.com/python/cpython">CPython Python interpreter</a> is the most commonly used interpreter for Python, and what&#8217;s use as a reference for other content here.
There are also other interpreters such as <a href="https://www.pypy.org/features.html">PyPy</a>, <a href="https://github.com/jython/jython">Jython</a>, and <a href="https://ironpython.net/">IronPython</a> which all handle memory differently than the CPython interpreter.</p>

<h3 id="pythons-memory-manager">Python&#8217;s Memory Manager</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIG1lbW9yeVtcIk1lbW9yeVwiXVxuc3ViZ3JhcGggcHJvY2Vzc1tcIlB5dGhvbiBwcm9jZXNzXCJdXG5weWhlYXBbXCJoZWFwXCJdXG5lbmRcbmVuZFxuY29kZVtcIlB5dGhvbiBjb2RlXCJdXG5zdWJncmFwaCBpbnRlcnByZXRlcltcIlB5dGhvbiBpbnRlcnByZXRlclwiXVxubWFuYWdlcltcIlB5dGhvbiBtZW1vcnkgbWFuYWdlclwiXVxuZW5kXG5lbmRcbiUlLVxuY29kZSAtLT4gfGludGVycHJldGVkIGFuZFxcbmV4ZWN1dGVkIGJ5fCBpbnRlcnByZXRlclxubWFuYWdlciAtLT4gfGV4ZWN1dGVzIGFuZCBtYW5hZ2VzXFxuIHByb2Nlc3MgbWVtb3J5fCBweWhlYXBcbiUlLVxuc3R5bGUgY29tcHV0ZXIgZmlsbDojZmZmLHN0cm9rZTojMzMzXG5zdHlsZSBtZW1vcnkgZmlsbDojODZFRkFDLHN0cm9rZTojMzMzXG5zdHlsZSBjb2RlIGZpbGw6IzY3RThGOSxzdHJva2U6IzMzMztcbnN0eWxlIG1hbmFnZXIgZmlsbDojRkRCQTc0LHN0cm9rZTojMzMzOyIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>The Python memory manager helps manage memory in the heap for Python processes executed by the Python interpreter.</em></p>

<p>Memory is managed for Python software processes automatically (when unspecified) or manually (when specified) through the Python interpreter.
The <strong><em>Python memory manager</em></strong> is an abstraction which manages memory for Python software processes through the Python interpreter (<a href="https://docs.python.org/3/c-api/memory.html">Python: Memory Management</a>).
From a high-level perspective, we assume variables and other operations written in Python will automatically allocate and deallocate memory through the Python interpreter when executed.
Python&#8217;s memory manager performs work through various <strong>memory allocators</strong> and a <strong>garbage collector</strong> (or as configured with customizations) within a <strong>private Python memory heap</strong>.</p>

<h3 id="pythons-memory-allocators">Python&#8217;s Memory Allocators</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIG1lbW9yeVtcIk1lbW9yeVwiXVxuc3ViZ3JhcGggcHJvY2Vzc1tcIlB5dGhvbiBwcm9jZXNzXCJdXG5weWhlYXBbXCJoZWFwXCJdXG5lbmRcbmVuZFxuY29kZVtcIlB5dGhvbiBjb2RlXCJdXG5tYWxsb2NbXCJDIG1lbW9yeSBmdW5jdGlvbnNcIl1cbnN1YmdyYXBoIGludGVycHJldGVyIFtcIlB5dGhvbiBpbnRlcnByZXRlclwiXVxuc3ViZ3JhcGggc3BhY2VyIFtcIiBcIl1cbnN1YmdyYXBoIG1nciBbXCJQeXRob24gbWVtb3J5IG1hbmFnZXJcIl1cbnB5bWFsbG9jW1wicHltYWxsb2NcIl1cbmVuZFxuZW5kXG5lbmRcbmVuZFxuJSUtXG5jb2RlIC0tPiB8aW50ZXJwcmV0ZWQgYW5kXFxuZXhlY3V0ZWQgYnl8IGludGVycHJldGVyXG5weW1hbGxvYyAtLT4gfFwiYWxsb2NhdGVzIG1lbW9yeSBmb3JcXG5zbWFsbCBhbmQgdGVtcG9yYXJ5IG5lZWRzXCJ8IG1hbGxvY1xubWdyIC0tPiB8XCJhbGxvY2F0ZXMgbWVtb3J5IGZvclxcbmxhcmdlciBvciBsb25nLWxpdmVkIG5lZWRzXCJ8IG1hbGxvY1xubWFsbG9jIC0tPiBweWhlYXBcbiUlLVxuc3R5bGUgY29tcHV0ZXIgZmlsbDojZmZmLHN0cm9rZTojMzMzXG5zdHlsZSBtZW1vcnkgZmlsbDojODZFRkFDLHN0cm9rZTojMzMzXG5zdHlsZSBjb2RlIGZpbGw6IzY3RThGOSxzdHJva2U6IzMzMztcbnN0eWxlIG1nciBmaWxsOiNGREJBNzQsc3Ryb2tlOiMzMzM7XG5zdHlsZSBweW1hbGxvYyBmaWxsOiNGQkJGMjQsc3Ryb2tlOiMzMzM7XG5zdHlsZSBtYWxsb2MgZmlsbDojRkJCRjI0LHN0cm9rZTojMzMzO1xuc3R5bGUgc3BhY2VyIHN0cm9rZTpub25lOyIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>The Python memory manager by default will use <code class="language-plaintext highlighter-rouge">pymalloc</code> internally or malloc from the system to allocate computer memory resources.</em></p>

<p>The Python memory manager allocates memory for use through memory allocators.
Python may use one or many memory allocators depending on specifications in Python code and how the Python interpreter is configured (for example, see <a href="https://docs.python.org/3/c-api/memory.html#default-memory-allocators">Python: Memory Management - Default Memory Allocators</a>).
One way to understand Python memory allocators is through the following distinctions.</p>

<ul>
  <li><strong>&#8220;Python Memory Allocator&#8221; (<code class="language-plaintext highlighter-rouge">pymalloc</code>)</strong>
The Python interpreter is packaged with a specialized memory allocator called <code class="language-plaintext highlighter-rouge">pymalloc</code>.
&#8220;Python has a pymalloc allocator optimized for small objects (smaller or equal to 512 bytes) with a short lifetime.&#8221; (<a href="https://docs.python.org/3/c-api/memory.html#the-pymalloc-allocator">Python: Memory Management - The pymalloc allocator</a>).
Ultimately, <code class="language-plaintext highlighter-rouge">pymalloc</code> uses C standard library dynamic memory allocation functions to implement memory work.</li>
  <li><strong>C dynamic memory allocation functions (<code class="language-plaintext highlighter-rouge">malloc</code>, <code class="language-plaintext highlighter-rouge">realloc</code>, etc.)</strong>
When <code class="language-plaintext highlighter-rouge">pymalloc</code> is disabled or a memory requirements exceed <code class="language-plaintext highlighter-rouge">pymalloc</code>&#8217;s constraints, the Python interpreter will directly use a function from the <a href="https://en.wikipedia.org/wiki/C_standard_library">C standard library</a> called <a href="https://en.wikipedia.org/wiki/C_dynamic_memory_allocation">C standard library dynamic memory allocation functions</a>.
When C standard library dynamic memory allocation functions are used by the Python interpreter, it uses the system&#8217;s existing implementation of the C standard library.</li>
</ul>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyIChyZXNvdXJjZXMpXCJdXG4lJS1cbnN1YmdyYXBoIG1lbW9yeVtcIk1lbW9yeVwiXVxuc3ViZ3JhcGggcHJvY2VzcyBbXCJQcm9jZXNzXCJdXG5zdWJncmFwaCBoZWFwMSBbXCJoZWFwXCJdXG5kaXJlY3Rpb24gVEJcbnN1YmdyYXBoIGFyZW5hIFtcInB5bWFsbG9jXFxuYXJlbmEocylcIl1cbnN1YmdyYXBoIHNwYWNlciBbXCIgXCJdXG5zdWJncmFwaCBwb29sc1tcInBvb2wocylcIl1cbmJsb2Nrc1tcImJsb2NrKHMpXCJdXG5lbmRcbmVuZFxuZW5kXG5lbmRcbmVuZFxuZW5kXG4lJS1cbmVuZFxuJSUtXG5zdHlsZSBjb21wdXRlciBmaWxsOiNmZmYsc3Ryb2tlOiMzMzNcbnN0eWxlIGFyZW5hIGZpbGw6I0Q4QjRGRSxzdHJva2U6IzMzM1xuc3R5bGUgcG9vbHMgZmlsbDojQzdEMkZFLHN0cm9rZTojMzMzXG5zdHlsZSBzcGFjZXIgZmlsbDp0cmFuc3BhcmVudCxzdHJva2U6dHJhbnNwYXJlbnQ7IiwibWVybWFpZCI6bnVsbH0" /></p>

<p class="center"><em><code class="language-plaintext highlighter-rouge">pymalloc</code> makes use of arenas to further organize pools within a Python process memory heap.</em></p>

<p>It&#8217;s important to note that <code class="language-plaintext highlighter-rouge">pymalloc</code> adds additional abstractions to how memory is organized through the use of &#8220;arenas&#8221;.
These arenas are specific to <code class="language-plaintext highlighter-rouge">pymalloc</code> purposes.
<code class="language-plaintext highlighter-rouge">pymalloc</code> may be disabled through the use of a special environment variable called <a href="https://docs.python.org/3/using/cmdline.html#envvar-PYTHONMALLOC"><code class="language-plaintext highlighter-rouge">PYTHONMALLOC</code></a> (for example, to use only <a href="https://en.wikipedia.org/wiki/C_dynamic_memory_allocation">C standard library dynamic memory allocation functions</a> as seen below).
This same environment variable may be used with <code class="language-plaintext highlighter-rouge">debug</code> settings in order to help troubleshoot in-depth questions.</p>

<p><strong>Additional Python Memory Allocators</strong></p>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIG1lbW9yeVtcIk1lbW9yeVwiXVxuc3ViZ3JhcGggcHJvY2Vzc1tcIlB5dGhvbiBwcm9jZXNzXCJdXG5weWhlYXBbXCJoZWFwXCJdXG5lbmRcbmVuZFxuY29kZVtcIlB5dGhvbiBjb2RlXCJdXG5tYWxsb2NbXCJDIG1lbW9yeSBmdW5jdGlvbnNcIl1cbnN1YmdyYXBoIGludGVycHJldGVyIFtcIlB5dGhvbiBpbnRlcnByZXRlclwiXVxuc3ViZ3JhcGggc3BhY2VyIFtcIiBcIl1cbnN1YmdyYXBoIG1nciBbXCJQeXRob24gbWVtb3J5IG1hbmFnZXJcIl1cbnB5bWFsbG9jW1wicHltYWxsb2NcIl1cbmVuZFxuZW5kXG5wYWNrYWdlX21hbmFnZWRbXCJOb24tZGVmYXVsdFxcbm1lbW9yeSBhbGxvY2F0b3JzXFxuKGV4LiBOdW1QeSwgUHlBcnJvdywgZXRjLilcIl1cbmVuZFxubWltYWxsb2NbXCJtaW1hbGxvYyBtZW1vcnkgZnVuY3Rpb25zXCJdXG5qZW1hbGxvY1tcImplbWFsbG9jIG1lbW9yeSBmdW5jdGlvbnNcIl1cbmVuZFxuJSUtXG5jb2RlIC0tPiB8aW50ZXJwcmV0ZWQgYW5kXFxuZXhlY3V0ZWQgYnl8IGludGVycHJldGVyXG5weW1hbGxvYyAtLT4gfFwiYWxsb2NhdGVzIG1lbW9yeSBmb3JcXG5zbWFsbCBhbmQgdGVtcG9yYXJ5IG5lZWRzXCJ8IG1hbGxvY1xubWdyIC0tPiB8XCJhbGxvY2F0ZXMgbWVtb3J5IGZvclxcbmxhcmdlciBvciBsb25nLWxpdmVkIG5lZWRzXCJ8IG1hbGxvY1xubWFsbG9jIC0tPiBweWhlYXBcbmNvZGUgLS4tPiB8bWF5IHN0aXB1bGF0ZVxcbnRoZSB1c2Ugb2Z8IHBhY2thZ2VfbWFuYWdlZFxucGFja2FnZV9tYW5hZ2VkIC0uLT4gbWFsbG9jXG5wYWNrYWdlX21hbmFnZWQgLS4tPiBtaW1hbGxvY1xucGFja2FnZV9tYW5hZ2VkIC0uLT4gamVtYWxsb2Ncbm1pbWFsbG9jIC0uLT4gcHloZWFwXG5qZW1hbGxvYyAtLi0-IHB5aGVhcFxuJSUtXG5zdHlsZSBjb21wdXRlciBmaWxsOiNmZmYsc3Ryb2tlOiMzMzNcbnN0eWxlIG1lbW9yeSBmaWxsOiM4NkVGQUMsc3Ryb2tlOiMzMzNcbnN0eWxlIGNvZGUgZmlsbDojNjdFOEY5LHN0cm9rZTojMzMzO1xuc3R5bGUgbWdyIGZpbGw6I0ZEQkE3NCxzdHJva2U6IzMzMztcbnN0eWxlIHB5bWFsbG9jIGZpbGw6I0ZCQkYyNCxzdHJva2U6IzMzMztcbnN0eWxlIG1hbGxvYyBmaWxsOiNGQkJGMjQsc3Ryb2tlOiMzMzM7XG5zdHlsZSBwYWNrYWdlX21hbmFnZWQgZmlsbDojRkJCRjI0LHN0cm9rZTojMzMzO1xuc3R5bGUgbWltYWxsb2MgZmlsbDojRkVGMDhBLHN0cm9rZTojMzMzO1xuc3R5bGUgamVtYWxsb2MgZmlsbDojRkVGMDhBLHN0cm9rZTojMzMzO1xuc3R5bGUgc3BhY2VyIHN0cm9rZTpub25lOyIsIm1lcm1haWQiOm51bGx9" /></p>

<p class="center"><em>Python code may stipulate the use of additional memory allocators, such as <code class="language-plaintext highlighter-rouge">mimalloc</code> and <code class="language-plaintext highlighter-rouge">jemalloc</code> outside of the default Python memory manager&#8217;s operation.</em></p>

<p>Python provides the capability of customizing memory allocation through the use of custom code or non-default packages.
See below for some notable examples of additional memory allocation possibilities.</p>

<ul>
  <li><strong>NumPy Memory Allocation</strong>
<a href="https://numpy.org/">NumPy</a> <a href="https://numpy.org/doc/stable/reference/c-api/data_memory.html">uses custom C-API&#8217;s</a> which are backed by C dynamic memory allocation functions (<code class="language-plaintext highlighter-rouge">alloc</code>, <code class="language-plaintext highlighter-rouge">free</code>, <code class="language-plaintext highlighter-rouge">realloc</code>) to help address memory management.
These interfaces can be controlled directly through NumPy to help manage memory effectively when using the package.</li>
  <li><strong>PyArrow Memory Allocators</strong>
<a href="https://arrow.apache.org/">PyArrow</a> provides the capability to use C standard library dynamic memory allocation functions, <a href="https://github.com/jemalloc/jemalloc"><code class="language-plaintext highlighter-rouge">jemalloc</code></a>, or <a href="https://github.com/microsoft/mimalloc"><code class="language-plaintext highlighter-rouge">mimalloc</code></a> through the <a href="https://arrow.apache.org/docs/python/api/memory.html#memory-pools">PyArrow Memory Pools group of functions</a>.
A default memory allocator is selected for use when PyArrow based on the operating system and the availability of the memory allocator on the system.
The selection of a memory allocator for use with PyArrow can be influenced by how it performs on a particular system.</li>
</ul>

<h3 id="python-reference-counting">Python Reference Counting</h3>

<table>
<tr><th>Processed line of code</th><th>Reference count</th></tr>
<tr>

<td>

```python
a_string = "cornucopia"
```

</td>
<td>
a_string: 1
</td>
<tr>
<td>

```python
reference_a_string = a_string
```

</td>
<td>
a_string: 2<br />
(Because `a_string` is now referenced twice.)
</td>
</tr>
<tr>
<td>

```python
del reference_a_string
```

</td>
<td>
a_string: 1<br />
(Because the additional reference has been deleted.)
</td>
</tr>

&lt;/table&gt;

_Python reference counting at a simple level works through the use of object reference increments and decrements._
{:.center}

As computer memory is allocated to Python processes the Python memory manager keeps track of these through the use of a [reference counter](https://en.wikipedia.org/wiki/Reference_counting).
In Python, we could label this as an "Object reference counter" because all data in Python is represented by objects ([Python: Data model](https://docs.python.org/3/reference/datamodel.html#objects-values-and-types)).
"... CPython counts how many different places there are that have a reference to an object. Such a place could be another object, or a global (or static) C variable, or a local variable in some C function." ([Python Developer's Guide: Garbage collector design](https://devguide.python.org/internals/garbage-collector/)).

### Python's Garbage Collection

<img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIGNvbXB1dGVyIFtcIkNvbXB1dGVyXCJdXG5kaXJlY3Rpb24gTFJcbnN1YmdyYXBoIG1lbW9yeVtcIk1lbW9yeVwiXVxuc3ViZ3JhcGggcHJvY2Vzc1tcIlB5dGhvbiBwcm9jZXNzXCJdXG5weWhlYXBbXCJoZWFwXCJdXG5lbmRcbmVuZFxuY29kZVtcIlB5dGhvbiBjb2RlXCJdXG5tYWxsb2NbXCJDIG1lbW9yeSBmdW5jdGlvbnNcIl1cbnN1YmdyYXBoIGludGVycHJldGVyIFtcIlB5dGhvbiBpbnRlcnByZXRlclwiXVxuc3ViZ3JhcGggc3BhY2VyIFtcIiBcIl1cbnN1YmdyYXBoIG1nciBbXCJQeXRob24gbWVtb3J5IG1hbmFnZXJcIl1cbnB5bWFsbG9jW1wicHltYWxsb2NcIl1cbmdjW1wiR2FyYmFnZVxcbkNvbGxlY3RvclwiXVxuZW5kXG5lbmRcbmVuZFxuZW5kXG4lJS1cbmNvZGUgLS0-IHxpbnRlcnByZXRlZCBhbmRcXG5leGVjdXRlZCBieXwgaW50ZXJwcmV0ZXJcbnB5bWFsbG9jIC0tPiB8XCJhbGxvY2F0ZXMgbWVtb3J5IGZvclxcbnNtYWxsIGFuZCB0ZW1wb3JhcnkgbmVlZHNcInwgbWFsbG9jXG5tZ3IgLS0-IHxcImFsbG9jYXRlcyBtZW1vcnkgZm9yXFxubGFyZ2VyIG9yIGxvbmctbGl2ZWQgbmVlZHNcInwgbWFsbG9jXG5tYWxsb2MgLS0-IHB5aGVhcFxuZ2MgLS0-IHxcImZyZWVzIG1lbW9yeSB3aXRoXFxubm8gb2JqZWN0IHJlZmVyZW5jZXNcXG4oaW5jbHVkaW5nIEMsIG1pbWFsbG9jLFxcbiBqZW1hbGxvYyBhbmQgb3RoZXIgXFxuZnVuY3Rpb24gYWxsb2NhdGVkIG1lbW9yeSlcInwgcHloZWFwXG4lJS1cbnN0eWxlIGNvbXB1dGVyIGZpbGw6I2ZmZixzdHJva2U6IzMzM1xuc3R5bGUgbWVtb3J5IGZpbGw6Izg2RUZBQyxzdHJva2U6IzMzM1xuc3R5bGUgY29kZSBmaWxsOiM2N0U4Rjksc3Ryb2tlOiMzMzM7XG5zdHlsZSBtZ3IgZmlsbDojRkRCQTc0LHN0cm9rZTojMzMzO1xuc3R5bGUgcHltYWxsb2MgZmlsbDojRkJCRjI0LHN0cm9rZTojMzMzO1xuc3R5bGUgbWFsbG9jIGZpbGw6I0ZCQkYyNCxzdHJva2U6IzMzMztcbnN0eWxlIGdjIGZpbGw6I0ZDQTVBNSxzdHJva2U6IzMzMztcbnN0eWxlIHNwYWNlciBzdHJva2U6bm9uZTsiLCJtZXJtYWlkIjpudWxsfQ" />

_The Python garbage collector works as part of the Python memory manager to free memory which is no longer needed (based on reference count)._
{:.center}

Python by default uses an optional garbage collector to automatically deallocate garbage memory through the Python interpreter in CPython.
"When an object’s reference count becomes zero, the object is deallocated." ([Python Developer's Guide: Garbage collector design](https://devguide.python.org/internals/garbage-collector/))
Python's garbage collector focuses on collecting garbage created by `pymalloc`, C memory functions, as well as other memory allocators like `mimalloc` and `jemalloc`.

## Python Tools for Observing Memory Behavior

### Python Built-in Tools

```python
import gc
import sys

# set gc in debug mode for detecting memory leaks
gc.set_debug(gc.DEBUG_LEAK)

# create an int object
an_object = 1

# show the number of uncollectable references via COLLECTED
COLLECTED = gc.collect()
print(f"Uncollectable garbage references: {COLLECTED}")

# show the reference count for an object
print(f"Reference count of `an_object`: {sys.getrefcount(an_object)}")
```

The [`gc` module](https://docs.python.org/3/library/gc.html) provides an interface to the Python garbage collector.
In addition, the [`sys` module](https://docs.python.org/3/library/sys.html) provides many functions which provide information about references and other details about Python objects as they are executed through the interpreter.
These functions and other packages can help software developers observe memory behaviors within Python procedures.

### Python Package: Scalene

<figure class="figure">
  <a class="figure-image" aria-label="Scalene provides a web interface to analyze memory, CPU, and GPU resource consumption in one spot alongside suggested areas of concern.">
    <img src="/set-website/preview/pr-46/images/scalene-web-interface.png" style="
        width: auto;
        max-height: unset;
      " alt="Scalene provides a web interface to analyze memory, CPU, and GPU resource consumption in one spot alongside suggested areas of concern." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Scalene provides a web interface to analyze memory, CPU, and GPU resource consumption in one spot alongside suggested areas of concern.

    </figcaption>
  
</figure>


[Scalene](https://github.com/plasma-umass/scalene) is a Python package for analyzing memory, CPU, and GPU resource consumption.
It provides [a web interface](https://github.com/plasma-umass/scalene?tab=readme-ov-file#web-based-gui) to help visualize and understand how resources are consumed.
Scalene provides suggestions on which portions of your code to troubleshoot through the web interface.
Scalene can also be configured to work with [OpenAI](https://en.wikipedia.org/wiki/OpenAI) [LLM's](https://en.wikipedia.org/wiki/Large_language_model) by way of a an [OpenAI API  provided by the user](https://github.com/plasma-umass/scalene?tab=readme-ov-file#ai-powered-optimization-suggestions).

### Python Package: Memray

<figure class="figure">
  <a class="figure-image" aria-label="Memray provides the ability to create and view flamegraphs which show how memory was consumed as a procedure executed.">
    <img src="/set-website/preview/pr-46/images/memray-flamegraph.png" style="
        width: auto;
        max-height: unset;
      " alt="Memray provides the ability to create and view flamegraphs which show how memory was consumed as a procedure executed." loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Memray provides the ability to create and view flamegraphs which show how memory was consumed as a procedure executed.

    </figcaption>
  
</figure>


[Memray](https://github.com/bloomberg/memray) is a Python package to track memory allocation within Python and compiled extension modules.
Memray provides a high-level way to investigate memory performance and adds visualizations such as [flamegraphs](https://www.brendangregg.com/flamegraphs.html) (which contextualization of [stack traces](https://en.wikipedia.org/wiki/Stack_trace) and memory allocations in one spot).
Memray seeks to provide a way to overcome challenges with tracking and understanding Python and other memory allocators (such as C, C++, or Rust libraries used in tandem with a Python process).

## Concluding Thoughts

It's worth mentioning that this article covers only a small fraction of how and what memory is as well as how Python might make use of it.
Hopefully it clarifies the process and provides a way to get started with investigating memory within the software you work with.
Wishing you the very best in your software journey with memory!
</tr></table>]]></content><author><name>dave-bunten</name></author><category term="tip-of-the-month" /><category term="python" /><category term="memory" /><category term="memory-management" /><category term="memory-allocators" /><summary type="html"><![CDATA[Python Memory Management and Troubleshooting]]></summary></entry><entry><title type="html">Tip of the Week: Codesgiving - Open-source Contribution Walkthrough</title><link href="/set-website/preview/pr-46/2023/11/15/Codesgiving-Open-source-Contribution-Walkthrough.html" rel="alternate" type="text/html" title="Tip of the Week: Codesgiving - Open-source Contribution Walkthrough" /><published>2023-11-15T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2023/11/15/Codesgiving-Open-source-Contribution-Walkthrough</id><content type="html" xml:base="/set-website/preview/pr-46/2023/11/15/Codesgiving-Open-source-Contribution-Walkthrough.html"><![CDATA[<h1 id="tip-of-the-week-codesgiving---open-source-contribution-walkthrough">Tip of the Week: Codesgiving - Open-source Contribution Walkthrough</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>Each week we seek to provide a software tip of the week geared towards helping you achieve your software goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any software questions or suggestions for an upcoming tip of the week, please don’t hesitate to reach out to
#software-engineering on Slack or email DBMISoftwareEngineering at olucdenver.onmicrosoft.com</p>

  </div>
</div>

<h2 id="introduction">Introduction</h2>

<figure class="figure">
  <a class="figure-image" aria-label="What good harvests from open-source have you experienced this year">
    <img src="/set-website/preview/pr-46/images/French_Orchard_at_Harvest_Time_(Le_verger)_(SM_1444)_cropped.png" style="
        width: auto;
        max-height: unset;
      " alt="What good harvests from open-source have you experienced this year" loading="lazy" onerror="this.src = '/set-website/preview/pr-46/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      What good harvests from open-source have you experienced this year?

    </figcaption>
  
</figure>

<!-- excerpt start -->
<p><a href="https://en.wikipedia.org/wiki/Thanksgiving">Thanksgiving</a> is a holiday practiced in many countries which focuses on gratitude for good harvests of the preceding year.
In the United States, we celebrate Thanksgiving on the fourth Thursday of November each year often by eating meals we create together with others.
This post channels the spirit of Thanksgiving by <em>giving</em> our thanks through <em>code</em> as a <strong><em>&#8220;Codesgiving&#8221;</em></strong>,  acknowledging and creating better software together.
<!-- excerpt end --></p>

<h2 id="giving-thanks-to-open-source-harvests">Giving Thanks to Open-source Harvests</h2>

<p class="center"><i class="fas fa-handshake-angle" style="font-size:4em;"></i></p>

<p>Part of building software involves the use of code which others have built, maintained, and distributed for a wider audience.
Using other people&#8217;s work often comes in the form of <a href="https://en.wikipedia.org/wiki/Open_source">open-source</a> &#8220;harvesting&#8221; as we find solutions to software challenges we face.
Examples might include installing and depending upon Python packages from <a href="https://en.wikipedia.org/wiki/Python_Package_Index">PyPI</a> or R packages from <a href="https://en.wikipedia.org/wiki/R_package#Comprehensive_R_Archive_Network_(CRAN)">CRAN</a> within your software projects.</p>

<blockquote>
  <p>&#8220;Real generosity toward the future lies in giving all to the present.&#8221;
- Albert Camus</p>
</blockquote>

<p>These open-source projects have internal costs which are sometimes invisible to those who consume them.
Every software project has an implied level of <a href="https://bssw.io/blog_posts/long-term-software-gardening-strategies-for-cultivating-scientific-development-ecosystems">software gardening</a> time costs involved to impede decay, practice continuous improvements, and evolve the work.
One way to actively share our thanks for the projects we depend on is through applying our time towards code contributions on them.</p>

<p>Many projects are in need of additional people&#8217;s thinking and development time.
Have you ever noticed something that needs to be fixed or desirable functionality in a project you use?
<strong><em>Consider adding your contributions to open-source!</em></strong></p>

<h2 id="all-contributions-matter">All Contributions Matter</h2>

<p class="center"><i class="fas fa-hands-holding-circle" style="font-size:4em;"></i></p>

<p>Contributing to open-source can come in many forms and contributions don&#8217;t need to be gigantic to make an impact.
Software often involves simplifying complexity.
Simplification requires many actions beyond solely writing code.
For example, a short walk outside, a conversation with someone, or a nap can sometimes help us with breakthroughs when it comes to development.
By the same token, open-source benefits greatly from communications on discussion boards, bug or feature descriptions, or other work that might not be strictly considered &#8220;engineering&#8221;.</p>

<h2 id="an-open-source-contribution-approach">An Open-source Contribution Approach</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG5yZXBvcnRlZFtcIlJlcG9ydFxcbm5lZWQocylcIl1cbnZlcmlmaWNhdGlvbltcIlZlcmlmeSBvciByZXBsaWNhdGVcXG4gdGhlIG5lZWRcIl1cbnZlcmlmeV9jaGVjazF7XCJBYmxlIHRvXFxudmVyaWZ5P1wifVxuc29sdXRpb25bXCJIeXBvdGhlc2l6ZVxcbiBhbmQgYXBwbHkgZml4XCJdXG52ZXJpZnlfY2hlY2sye1wiSXMgaXRcXG5yZXNvbHZlZD9cIn1cbnJlc29sdmVkW1wiUmVzb2x1dGlvblxcbmFuZCBwb3N0LWFjdGlvbnNcIl1cbiUlLVxucmVwb3J0ZWQgLS0-IHZlcmlmaWNhdGlvblxudmVyaWZpY2F0aW9uIC0tPiB2ZXJpZnlfY2hlY2sxXG52ZXJpZnlfY2hlY2sxIC0tPiB8Tm86IGdhdGhlclxcbm1vcmUgZGV0YWlsc3wgdmVyaWZpY2F0aW9uXG52ZXJpZnlfY2hlY2sxIC0tPiB8WWVzOiBhYmxlXFxudG8gdmVyaWZ5fCBzb2x1dGlvblxuc29sdXRpb24gLS0-IHZlcmlmeV9jaGVjazJcbnZlcmlmeV9jaGVjazIgLS0-IHxObzogdHJ5XFxuc29tZXRoaW5nIGVsc2V8IHNvbHV0aW9uXG52ZXJpZnlfY2hlY2syIC0tPiB8WWVzOiBpc3N1ZVxcbnJlc29sdmVkfHJlc29sdmVkXG4lJS1cbnN0eWxlIHJlcG9ydGVkIGZpbGw6I0ZFRjNDNyxzdHJva2U6I0Q5NzcwNjtcbnN0eWxlIHJlc29sdmVkIGZpbGw6I0JCRjdEMCxzdHJva2U6IzE2QTM0QTsiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p><em>The troubleshooting process as a workflow involving looped checks for verifying an issue and validating the solution fixes an issue.</em></p>

<p>It can feel overwhelming to find a way to contribute to open-source.
Similar to other software methodology, modularizing your approach can help you progress without being overwhelmed.
Using a troubleshooting approach like the above can help you break down big challenges into bite-sized chunks.
Consider each step as a &#8220;module&#8221; or &#8220;section&#8221; which needs to be addressed sequentially.</p>

<h3 id="embrace-a-learning-mindset">Embrace a Learning Mindset</h3>

<blockquote>
  <p>&#8220;Before you speak ask yourself if what you are going to say <strong>is true, is kind, is necessary, is helpful</strong>. If the answer is no, maybe what you are about to say should be left unsaid.&#8221;
- Bernard Meltzer</p>
</blockquote>

<p>Open-source contributions almost always entail learning of some kind.
Many contributions happen solely in the form of code and text communications which are easily misinterpreted.
<strong>Assume positive intent</strong> and accept input from others while upholding your own ideas to share successful contributions together.
Prepare yourself by intentionally opening your mind to input from others, even if you&#8217;re sure you&#8217;re absolutely &#8220;right&#8221;.</p>

<div class="alert" style="--color: #6366f1">
  
  <i class="icon fa-solid fa-circle-question"></i>
  <div class="alert-content">
    
<p>Before communicating, be sure to use Bernard Meltzer&#8217;s self-checks mentioned above.</p>

<ol>
  <li>Is what I&#8217;m about to say <strong>true</strong>?
    <ul>
      <li>Have I taken time to verify the claims in a way others can replicate or understand?</li>
    </ul>
  </li>
  <li>Is what I&#8217;m about to say <strong>kind</strong>?
    <ul>
      <li>Does my intention and communication channel kindness (and not cruelty)?</li>
    </ul>
  </li>
  <li>Is what I&#8217;m about to say <strong>necessary</strong>?
    <ul>
      <li>Do my words and actions here enable or enhance progress towards a goal (would the outcome be achieved without them)?</li>
    </ul>
  </li>
  <li>Is what I&#8217;m about to say <strong>helpful</strong>?
    <ul>
      <li>How does my communication increase the quality or sustainability of the project (or group)?</li>
    </ul>
  </li>
</ol>

  </div>
</div>

<h3 id="setting-software-scheduling-expectations">Setting Software Scheduling Expectations</h3>

<script src="https://cdn.jsdelivr.net/npm/vega@5.22.1"></script>

<script src="https://cdn.jsdelivr.net/npm/vega-lite@5.6.0"></script>

<script src="https://cdn.jsdelivr.net/npm/vega-embed@6.21.0"></script>

<div id="vis"></div>

<script>
  var spec = {
    "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
    "description": "Suggested Open-source Time Allocations",
    "width": 500,
    "height": 300,
    "title":"Suggested Open-source Time Allocations",
    "data": {
      "values": [
        {"task": "1. Planning", "percentage": 33},
        {"task": "2. Coding", "percentage": 16},
        {"task": "3. Component and System Testing", "percentage": 25},
        {"task": "4. Code Review, Revisions, and Post-Actions", "percentage": 25}
      ]
    },
    "mark": {"type": "arc", "tooltip": true},
    "encoding": {
      "color": {"field": "task", "type": "nominal", "title": "Task", "sort":"ascending"},
      "theta": {"field": "percentage", "type": "quantitative", "title": "Percentage"}
    },
    "config": {
      "legend": {
        "orient": "right",
        "labelLimit": 500
      }
    }
  };

  const embed_opt = {"mode": "vega-lite"};
  const el = document.getElementById('vis');
  const view = vegaEmbed("#vis", spec, embed_opt);
</script>

<p class="center"><em>Suggested ratio of time spent by type of work for an open-source contribution.</em></p>

<ol>
  <li>1/3 planning (~33%)</li>
  <li>1/6 coding (~16%)</li>
  <li>1/4 component and system testing (25%)</li>
  <li>1/4 code review, revisions, and post-actions (25%)</li>
</ol>

<p>This modified rule of thumb from <a href="https://www.oreilly.com/library/view/mythical-man-month-the/0201835959/"><em>The Mythical Man Month</em></a> can assist with how you structure your time for an open-source contribution.
Notice the emphasis on planning and testing and keep these in mind as you progress (the actual programming time can be small if adequate time has been spent on planning).
Notably, the original time fractions are modified here with the final quarter of the time spent suggested as code review, revisions, and post-actions.
Planning for the time expense of the added code review and related elements assists with keeping a learning mindset throughout the process (instead of feeling like the review is a &#8220;tack-on&#8221; or &#8220;optional / supplementary&#8221;).
A good motto to keep in mind throughout this process is <a href="https://en.wikipedia.org/wiki/Festina_lente"><em>Festina lente</em></a>, or <strong>&#8220;Make haste, slowly.&#8221;</strong> (take care to move thoughtfully and as slowly as necessary to do things correctly the first time).</p>

<h2 id="planning-an-open-source-contribution">Planning an Open-source Contribution</h2>

<h3 id="has-the-need-already-been-reported">Has the Need Already Been Reported?</h3>

<p class="center"><i class="fas fa-comments" style="font-size:4em;"></i></p>

<p>Be sure to check whether the bug or feature has already been reported somewhere!
In a way, this is a practice of <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">&#8220;Don&#8217;t repeat yourself&#8221; (DRY)</a> where we attempt to avoid repeating the same block of code (in this case, the &#8220;code&#8221; can be understood as natural language).
For example, you can look on GitHub Issues or GitHub Discussions with a search query matching the rough idea of what you&#8217;re thinking about.
You can also use the GitHub search bar to automatically search multiple areas (including Issues, Discussions, Pull Requests, etc.) when you enter a query from the repository homepage.
If it has been reported already, take a look to see if someone has made a code contribution related to the work already.</p>

<p>An open discussion or report of the need doesn&#8217;t guarantee someone&#8217;s already working on a solution.
If there aren&#8217;t yet any code contributions and it doesn&#8217;t look like anyone is working on one, consider volunteering to take a further look into the solution and be sure to acknowledge any existing discussions.
If you&#8217;re unsure, it&#8217;s always kind to mention your interest in the report and ask for more information.</p>

<h3 id="is-the-need-a-bug-or-feature">Is the Need a Bug or Feature?</h3>

<!-- set a max width for mermaid diagram below so it doesn't render so large -->
<style>
#feature-or-bug img { max-width: 500px; }
</style>

<div id="feature-or-bug">

<img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnN1YmdyYXBoIHNvZnR3YXJlX25lZWRzIFtcIlNvZnR3YXJlIE5lZWRzXCJdXG5zdWJncmFwaCBidWdfb3ZlciBbXCJCdWdcIl1cbmJ1Z1tcIlNvbWV0aGluZydzXFxuYnJva2VuIVwiXVxuZW5kXG4lJS1cbnN1YmdyYXBoIGZlYXR1cmVfb3ZlciBbXCJGZWF0dXJlXCJdXG5mZWF0dXJlW1wiV2UgbmVlZCBuZXdcXG5mdW5jdGlvbmFsaXR5IVwiXVxuZW5kXG5lbmRcbiUlLVxuc3R5bGUgc29mdHdhcmVfbmVlZHMgZmlsbDojZmZmLHN0cm9rZTojZmZmOyIsIm1lcm1haWQiOm51bGx9" />

</div>

<p>One way to help solidify your thinking and the approach is to consider whether what you&#8217;re proposing is a bug or a feature.
A <a href="https://en.wikipedia.org/wiki/Software_bug">software bug</a> is considered something which is broken or malfunctioning.
A <a href="https://en.wikipedia.org/wiki/Software_feature">software feature</a> is generally considered new functionality or a different way of doing things than what exists today.
There&#8217;s often overlap between these, and sometimes they can inspire branching needs, but individually they usually are more of one than the other.
If you can&#8217;t decide whether your need is a bug or a feature, consider breaking it down into smaller sub-components so they can be more of one or the other.
Following this strategy will help you communicate the potential for contribution and also clarify the development process (for example, a critical bug might be prioritized differently than a nice-to-have new feature).</p>

<h3 id="reporting-the-need-for-change">Reporting the Need for Change</h3>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh"># Using `function_x` with `library_y` causes `exception_z`</span>

<span class="gu">## Summary</span>

As a <span class="sb">`library_y`</span> research software developer I want to use <span class="sb">`function_x`</span> 
for my data so that I can share data for research outcomes.

<span class="gu">## Reproducing the error</span>

This error may be seen using Python v3.x on all major OS's using
the following code snippet:
...

</code></pre></div></div>

<p><em>An example of a user story issue report with imagined code example.</em></p>

<p>Open-source needs are often best reported through written stories captured within a bug or feature tracking system (such as <a href="https://github.com/features/issues">GitHub Issues</a>) which if possible also include example code or logs.
One template for reporting issues is through a &#8220;user story&#8221;.
A user story typically comes in the form: <code class="language-plaintext highlighter-rouge">As a &lt; type of user &gt;, I want &lt; some goal &gt; so that &lt; some reason &gt;.</code> (<a href="https://www.mountaingoatsoftware.com/agile/user-stories">Mountain Goat Software: User Stories</a>).
Alongside the story, it can help to add in a snippet of code which exemplifies a problem, new functionality, or a potential adjacent / similar solution.
As a general principle, <strong>be as specific as you can without going overboard</strong>.
Include things like programming language version, operating system, and other system dependencies that might be related.</p>

<p>Once you have a good written description of the need, be sure to submit it where it can be seen by the relevant development community.
For GitHub-based work, this is usually a GitHub Issue, but can also entail discussion board posts to gather buy-in or consensus before proceeding.
In addition to the specifics outlined above, also recall the <a href="#embrace-a-learning-mindset">learning mindset and Bernard Meltzer&#8217;s self-checks</a>, taking time to acknowledge especially the potential challenges and already attempted solutions associated with the description (conveying kindness throughout).</p>

<h3 id="what-happens-after-you-submit-a-bug-or-feature-report">What Happens After You Submit a Bug or Feature Report?</h3>

<p class="center"><i class="fas fa-check-to-slot" style="font-size:4em;"></i></p>

<p>When making open-source contributions, sometimes it can also help to mention that you&#8217;re interested in resolving the issue through a related pull request and review.
Oftentimes open-source projects welcome new contributors but may have specific requirements.
These requirements are usually spelled out within a <a href="https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/setting-guidelines-for-repository-contributors"><code class="language-plaintext highlighter-rouge">CONTRIBUTING.md</code> document</a> found somewhere in the repository or the organization level documentation.
It&#8217;s also completely okay to let other contributors build solutions for the issue (like we mentioned before, all contributions matter, including the reporting of bugs or features themselves)!</p>

<h2 id="developing-and-testing-an-open-source-contribution">Developing and Testing an Open-source Contribution</h2>

<h3 id="creating-a-development-workspace">Creating a Development Workspace</h3>

<p class="center"><i class="fas fa-code-branch" style="font-size:4em;"></i></p>

<p>Once ready to develop a solution for the reported need in the open-source project you&#8217;ll need a place to version your updates.
This work generally takes place through version control on focused branches which are named in a way that relates to the focus.
When working on GitHub, this work also commonly takes place on <a href="https://docs.github.com/en/get-started/quickstart/fork-a-repo">forked repository copies</a>.
Using these methods helps isolate your changes from other work that takes place within the project.
It also can help you track your progress alongside related changes that might take place before you&#8217;re able to seek review or code merges.</p>

<h4 id="bug-or-feature-verification-with-test-driven-development">Bug or Feature Verification with Test-driven Development</h4>

<div class="alert" style="--color: #d946ef">
  
  <i class="icon fa-solid fa-lightbulb"></i>
  <div class="alert-content">
    
<p>One can use a test-driven development approach as numbered steps (<a href="https://en.wikipedia.org/wiki/Test-driven_development">Wikipedia</a>).</p>

<blockquote>
  <ol>
    <li>Add or modify a test which checks for a bug fix or feature addition</li>
    <li>Run all tests (expecting the newly added test content to fail)</li>
    <li>Write a simple version of code which allows the tests to succeed</li>
    <li>Verify that all tests now pass</li>
    <li>Return to step 3, refactoring the code as needed</li>
  </ol>
</blockquote>


  </div>
</div>

<p>If you decide to develop a solution for what you reported, one software strategy which can help you remain focused and objective is <a href="https://en.wikipedia.org/wiki/Test-driven_development">test-driven development</a>.
Using this pattern sets a &#8220;cognitive milestone&#8221; for you as you develop a solution to what was reported.
Open-source projects can have many interesting components which could take time and be challenging to understand.
The addition of the test and related development will help keep you goal-orientated without getting lost in the &#8220;software forest&#8221; of a project.</p>

<h3 id="prefer-simple-over-complex-changes">Prefer Simple Over Complex Changes</h3>

<blockquote>
  <p>&#8230;
Simple is better than complex.
Complex is better than complicated.
&#8230;
- <a href="https://peps.python.org/pep-0020/">PEP 20: The Zen of Python</a></p>
</blockquote>

<p>Further channeling step 3. from test-driven development above, prefer simple changes over more complex ones (recognizing that the <em>absolute</em> simplest can take iteration and thought).
Some of the best solutions are often the most easily understood ones (where the code addition or changes seem obvious afterwards).
A &#8220;simplest version&#8221; of the code can often be more quickly refactored and completed than devising a &#8220;perfect&#8221; solution the first time.
Remember, you&#8217;ll very likely have the help of a code review before the code is merged (expect to learn more and add changes during review!).</p>

<p>It might be tempting to address more than one bug or feature at the same time.
<strong><em>Avoid <a href="https://en.wikipedia.org/wiki/Feature_creep">feature creep</a> as you build solutions - stay focused on the task at hand!</em></strong>
Take note of things you notice on your journey to address the reported needs.
These can be become additional reported bugs or features which could be addressed later.
Staying focused with your development will save you time, keep your tests constrained, and (theoretically) help reduce the time and complexity of code review.</p>

<h3 id="developing-a-solution">Developing a Solution</h3>

<p class="center"><i class="fas fa-screwdriver-wrench" style="font-size:4em;"></i></p>

<p>Once you have a test in place for the bug fix or feature addition it&#8217;s time to work towards developing a solution.
If you&#8217;ve taken time to accomplish the prior steps before this point you may already have a good idea about how to go about a solution.
If not, spend some time investigating the technical aspects of a solution, optionally adding this information to the report or discussion content for further review before development.
Use <a href="https://cu-dbmi.github.io/set-website/2023/01/17/Timebox-Your-Software-Work.html">timeboxing techniques</a> to  help make sure the time you spend in development is no more than necessary.</p>

<h2 id="code-review-revisions-and-post-actions">Code Review, Revisions, and Post-actions</h2>

<h3 id="pull-requests-and-code-review">Pull Requests and Code Review</h3>

<p>When your code and new test(s) are in a good spot it&#8217;s time to ask for a code review.
It might feel tempting to perfect the code.
Instead, consider whether the code is &#8220;good enough&#8221; and would benefit from someone else providing feedback.
Code review takes advantage of a strength of our species: collaborative &amp; multi-perspectival thinking.
Leverage this in your open-source experience by seeking feedback when things feel &#8220;good enough&#8221;.</p>

<div id="pareto_viz"></div>

<script>
  var spec = {
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "config": {"view": {"stroke": ""}, "fontSize": 14},
  "width": 800,
  "height": 200,
  "data": {
    "values": [
            {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "changes"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "value"},
      {"pareto_category": "2. Achieving Perfection", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "changes"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "changes"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},
      {"pareto_category": "1. Vital Few Efforts", "pareto_measure": "value"},

    ]
  },
  "transform": [
    {
      "calculate": "{ 'changes': '🟢', 'value': '🙂'}[datum.pareto_measure]",
      "as": "emoji"
    },
    {"window": [{"op": "rank", "as": "rank"}], "groupby": ["pareto_category", "pareto_measure"]}
  ],
  "mark": {"type": "text", "baseline": "middle"},
  "encoding": {
    "x": {"field": "rank", "type": "ordinal", "axis": null},
    "y": {"field": "pareto_measure", "type": "nominal", "title":"", "axis":{"labelFontSize":15}},
    "row": {"field": "pareto_category", "header": {"title": "", "labelFontSize":15}},
    "text": {"field": "emoji", "type": "nominal"},
    "size": {"value": 55}
  }
};

  vegaEmbed("#pareto_viz", spec, embed_opt);
</script>

<p class="center"><em>Demonstrating Pareto Principle &#8220;vital few&#8221; through a small number of changes to achieve 80% of the value associated with the needs.</em></p>

<p>One way to understand &#8220;good enough&#8221; is to assess whether you have reached what the <a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto Principle</a> terms as the &#8220;vital few&#8221; causes.
The Pareto Principle states that roughly 80% of consequences come from 20% of causes (the &#8220;vital few&#8221;).
What are the 20% changes (for example, as commits) which are required to achieve 80% of the desired intent for development with your open-source contribution?
When you reach those 20% of the changes, consider opening a pull request to gather more insight about whether those changes will suffice and how the remaining effort might be spent.</p>

<p>As you go through the process of opening a pull request, be sure to follow the open-source <a href="https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/setting-guidelines-for-repository-contributors"><code class="language-plaintext highlighter-rouge">CONTRIBUTING.md</code> document</a> documentation related to the project; each one can vary.
When working on GitHub-based projects, you&#8217;ll need to open a <a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests">pull request</a> on the correct branch (usually upstream <code class="language-plaintext highlighter-rouge">main</code>).
If you used a GitHub issue to help report the issue, mention the issue in the pull request description using the <code class="language-plaintext highlighter-rouge">#issue number</code> (for example <code class="language-plaintext highlighter-rouge">#123</code> where the issue link would look like: <code class="language-plaintext highlighter-rouge">https://github.com/orgname/reponame/issues/123</code>) reference to help link the work to the reported need.
This will cause the pull request to show up within the issue and automatically create a link to the issue from the pull request.</p>

<h3 id="code-revisions">Code Revisions</h3>

<blockquote>
  <p>&#8220;Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.&#8221;
- Antoine de Saint-Exupery</p>
</blockquote>

<p>You may be asked to update your code based on automated code quality checks or reviewer request.
Treat these with care; embrace learning and remember that this step can take 25% of the total time for the contribution.
When working on GitHub forks or branches, you can make additional commits directly on the development branch which was used for the pull request.
If your reviewers requested changes, re-request their review once changes have been made to help let them know the code is ready for another look.</p>

<h3 id="post-actions-and-tidying-up-afterwards">Post-actions and Tidying Up Afterwards</h3>

<p class="center"><i class="fas fa-broom" style="font-size:4em;"></i></p>

<p>Once the code has been accepted by the reviewers and through potential automated testing suite(s) the content is ready to be merged.
Oftentimes this work is completed by core maintainers of the project.
After the code is merged, it&#8217;s usually a good idea to clean up your workspace by deleting your development branch and syncing with the upstream repository.
While it&#8217;s up to core maintainers to decide on report closure, typically the reported need content can be closed and might benefit from a comment describing the fix.
Many of these steps are considered common courtesy but also, importantly, assist in setting you up for your next contributions!</p>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>

<p>Hopefully the above helps you understand the open-source contribution process better.
As stated earlier, every little part helps!
Best wishes on your open-source journey and happy Codesgiving!</p>

<h2 id="references">References</h2>

<ul>
  <li>Top Image: Französischer Obstgarten zur Erntezeit (Le verger) by Charles-François Daubigny (cropped). (Source: <a href="https://commons.wikimedia.org/wiki/File:French_Orchard_at_Harvest_Time_(Le_verger)_(SM_1444).png">Wikimedia Commons</a>)</li>
</ul>]]></content><author><name>dave-bunten</name></author><category term="tip-of-the-week" /><category term="codesgiving" /><category term="open-source" /><category term="contributions" /><category term="development-strategy" /><category term="process" /><summary type="html"><![CDATA[Tip of the Week: Codesgiving - Open-source Contribution Walkthrough]]></summary></entry><entry><title type="html">Tip of the Week: Data Quality Validation through Software Testing Techniques</title><link href="/set-website/preview/pr-46/2023/10/04/Data-Quality-Validation.html" rel="alternate" type="text/html" title="Tip of the Week: Data Quality Validation through Software Testing Techniques" /><published>2023-10-04T00:00:00+00:00</published><updated>2025-05-23T15:12:31+00:00</updated><id>/set-website/preview/pr-46/2023/10/04/Data-Quality-Validation</id><content type="html" xml:base="/set-website/preview/pr-46/2023/10/04/Data-Quality-Validation.html"><![CDATA[<h1 id="tip-of-the-week-data-quality-validation-through-software-testing-techniques">Tip of the Week: Data Quality Validation through Software Testing Techniques</h1>

<div class="alert" style="--color: #0ea5e9">
  
  <i class="icon fa-solid fa-circle-info"></i>
  <div class="alert-content">
    
<p>Each week we seek to provide a software tip of the week geared towards helping you achieve your software goals. Views
expressed in the content belong to the content creators and not the organization, its affiliates, or employees. If you
have any software questions or suggestions for an upcoming tip of the week, please don’t hesitate to reach out to
#software-engineering on Slack or email DBMISoftwareEngineering at olucdenver.onmicrosoft.com</p>

  </div>
</div>

<p><strong>TLDR (too long, didn&#8217;t read);</strong></p>

<p>Implement data quality validation through <a href="https://en.wikipedia.org/wiki/Software_testing">software testing</a> approaches which leverage ideas surrounding <a href="https://en.wikipedia.org/wiki/Hoare_logic#Hoare_triple">Hoare triples</a> and <a href="https://en.wikipedia.org/wiki/Design_by_contract">Design by contract (DbC)</a>. Balancing reusability through <a href="https://en.wikipedia.org/wiki/Component-based_software_engineering">component-based design</a> data testing with <a href="https://github.com/great-expectations/great_expectations">Great Expectations</a> or <a href="https://github.com/ropensci/assertr/">Assertr</a>. For greater specificity in your data testing, use <a href="https://en.wikipedia.org/wiki/Database_schema">database schema-like</a> verification through <a href="https://pandera.readthedocs.io/en/stable/index.html">Pandera</a> or a <a href="https://json-schema.org/learn/getting-started-step-by-step">JSON Schema</a> validator. When possible, practice <a href="https://en.wikipedia.org/wiki/Shift-left_testing">shift-left testing</a> on data sources by through the concept of <a href="https://speakerdeck.com/tastapod/arent-we-forgetting-someone">&#8220;database(s) as code&#8221;</a> via tools like <a href="https://dvc.org/doc">Data Version Control (DVC)</a> and <a href="https://github.com/flyway/flyway">Flyway</a>.</p>

<h2 id="introduction">Introduction</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG5zdWJncmFwaCBsb2NhbCBbXCJEYXRhIFF1YWxpdHkgVmFsaWRhdGlvblwiXVxuZGlyZWN0aW9uIExSXG4lJS1cbmlucHV0X2RhdGFbKFwiSW5wdXQgRGF0YVwiKV1cbm1ldF9zcGVjaWZpY2F0aW9uMXtcIk1ldFxcbnNwZWNzP1wifVxucHJvY2Vzc19kYXRhW1wiRGF0YSBwcm9jZXNzaW5nXCJdXG5tZXRfc3BlY2lmaWNhdGlvbjJ7XCJNZXQgXFxuc3BlY3M_XCJ9XG5vdXRwdXRfZGF0YVsoXCJPdXRwdXQgRGF0YVwiKV1cbmVuZFxuJSUtXG5pbnB1dF9kYXRhIC0tPiBtZXRfc3BlY2lmaWNhdGlvbjFcbm1ldF9zcGVjaWZpY2F0aW9uMSAtLT4gcHJvY2Vzc19kYXRhXG5wcm9jZXNzX2RhdGEgLS0-IG1ldF9zcGVjaWZpY2F0aW9uMlxubWV0X3NwZWNpZmljYXRpb24yIC0tPiBvdXRwdXRfZGF0YSIsIm1lcm1haWQiOm51bGx9" /></p>

<p><em>Diagram showing input, in-process data, and output data as a workflow.</em></p>

<!-- excerpt start -->
<p>Data orientated software development can benefit from a specialized focus on varying aspects of data quality validation.
We can use <a href="https://en.wikipedia.org/wiki/Software_testing">software testing</a> techniques to validate certain qualities of the data in order to meet a declarative standard (where one doesn&#8217;t need to guess or rediscover known issues).
These come in a number of forms and generally follow existing software testing concepts which we&#8217;ll expand upon below.
This article will cover a few tools which leverage these techniques for addressing data quality validation testing.
<!-- excerpt end --></p>
<h2 id="data-quality-testing-concepts">Data Quality Testing Concepts</h2>

<h3 id="hoare-triple">Hoare Triple</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG5zdWJncmFwaCBsb2NhbCBbXCJEYXRhIFdvcmtmbG93IGFzIEhvYXJlIFRyaXBsZVwiXVxuZGlyZWN0aW9uIExSXG5pbnB1dF9kYXRhWyhcIklucHV0IERhdGFcXG4oUCAtIHByZWNvbmRpdGlvbilcIildXG5wcm9jZXNzX2RhdGFbXCJEYXRhIHByb2Nlc3NpbmdcXG4oQyAtIGNvbW1hbmQpXCJdXG5vdXRwdXRfZGF0YVsoXCJPdXRwdXQgRGF0YVxcbihRIC0gcG9zdGNvbmRpdGlvbilcIildXG5lbmRcbiUlLVxuaW5wdXRfZGF0YSAtLT4gcHJvY2Vzc19kYXRhIC0tPiBvdXRwdXRfZGF0YSIsIm1lcm1haWQiOm51bGx9" /></p>

<p>One concept we&#8217;ll use to present these ideas is <a href="https://en.wikipedia.org/wiki/Hoare_logic"><em>Hoare logic</em></a>, which is a system for reasoning on <a href="https://en.wikipedia.org/wiki/Correctness_(computer_science)">software correctness</a>.
Hoare logic includes the idea of a <a href="https://en.wikipedia.org/wiki/Hoare_logic#Hoare_triple">Hoare triple</a> ($ {\displaystyle {P}C{Q}} $) where $ {\displaystyle {P}} $ is an assertion of precondition, $ {\displaystyle \ C} $ is a command, and $ {\displaystyle {Q}} $ is a postcondition assertion.
Software development using data often entails (sometimes assumed) assertions of precondition from data sources, a transformation or command which changes the data, and a (sometimes assumed) assertion of postcondition in a data output or result.</p>

<h3 id="design-by-contract">Design by Contract</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG5zdWJncmFwaCBsb2NhbCBbXCJEYXRhIFRlc3RpbmcgdGhyb3VnaCBEZXNpZ24gYnkgQ29udHJhY3Qgb3ZlciBIb2FyZSBUcmlwbGVcIl1cbmRpcmVjdGlvbiBMUlxuc3ViZ3JhcGggaG9hcmVfdHJpcGxlIFtcIkhvYXJlIFRyaXBsZVwiXVxuZGlyZWN0aW9uIExSXG5pbnB1dF9kYXRhWyhcIklucHV0IERhdGFcXG4oUCAtIHByZWNvbmRpdGlvbilcIildXG4lJS1cbnByb2Nlc3NfZGF0YVtcIkRhdGEgcHJvY2Vzc2luZ1xcbihDIC0gY29tbWFuZClcIl1cbiUlLVxub3V0cHV0X2RhdGFbKFwiT3V0cHV0IERhdGFcXG4oUSAtIHBvc3Rjb25kaXRpb24pXCIpXVxuZW5kXG5zdWJncmFwaCBkYmMgW1wiRGVzaWduIGJ5IENvbnRyYWN0XCJdXG5kaXJlY3Rpb24gTFJcbm1ldF9zcGVjaWZpY2F0aW9uMXtcIk1ldFxcbnNwZWNzP1wifVxuY29udHJhY3QxKFtcIkNvbnRyYWN0KHMpXCJdKVxubWV0X3NwZWNpZmljYXRpb24ye1wiTWV0IFxcbnNwZWNzP1wifVxuY29udHJhY3QyKFtcIkNvbnRyYWN0KHMpXCJdKVxuZW5kXG5lbmRcbiUlLVxuaW5wdXRfZGF0YSAtLT4gbWV0X3NwZWNpZmljYXRpb24xXG5tZXRfc3BlY2lmaWNhdGlvbjEgLS0-IHByb2Nlc3NfZGF0YVxucHJvY2Vzc19kYXRhIC0tPiBtZXRfc3BlY2lmaWNhdGlvbjJcbm1ldF9zcGVjaWZpY2F0aW9uMiAtLT4gb3V0cHV0X2RhdGFcbmNvbnRyYWN0MSAtLT4gbWV0X3NwZWNpZmljYXRpb24xXG5jb250cmFjdDIgLS0-IG1ldF9zcGVjaWZpY2F0aW9uMlxuJSUtIiwibWVybWFpZCI6bnVsbH0" /></p>

<p><em>Data testing through design by contract over Hoare triple.</em></p>

<p>Hoare logic and Software correctness help describe <a href="https://en.wikipedia.org/wiki/Design_by_contract">design by contract (DbC)</a>, a software approach involving the formal specification of &#8220;contracts&#8221; which help ensure we meet our intended goals.
DbC helps describe how to create assertions when proceeding through Hoare triplet states for data.
These concepts provide a framework for thinking about the tools mentioned below.</p>

<h2 id="data-component-testing">Data Component Testing</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG5pbnB1dF9kYXRhWyhcIkRhdGEgdG8gY2hlY2tcIildXG5oYXNfY29tcG9uZW50c3tcIkV4aGliaXRzXFxuY29tcG9uZW50cz9cIn1cbmNvbnRyYWN0KFtcIkNvbnRyYWN0KHMpXCJdKVxuY29tcG9uZW50c1tcIi0gSGFzIG5vIG51bGwgdmFsdWVzXFxuLSBDb2x1bW5zIGFyZSBhbGwgbnVtZXJpY1xcbi0gZXRjLi4uXCJdXG5jb250aW51ZVtcIkNvbnRpbnVlXFxub3BlcmF0aW9uc1wiXVxuZXJyb3JbXCJSYWlzZVxcbmV4Y2VwdGlvblwiXVxuJSUtXG5jb21wb25lbnRzIC0tPiBjb250cmFjdFxuaW5wdXRfZGF0YSAtLT4gaGFzX2NvbXBvbmVudHNcbmNvbnRyYWN0IC0uLT4gaGFzX2NvbXBvbmVudHNcbmhhc19jb21wb25lbnRzIC0tPiB8IFllcyB8IGNvbnRpbnVlXG5oYXNfY29tcG9uZW50cyAtLT4gfCBObyB8IGVycm9yXG4lJS1cbnN0eWxlIGVycm9yIGZpbGw6I0ZFRDdBQVxuc3R5bGUgY29udGludWUgZmlsbDojRENGQ0U3XG5zdHlsZSBjb21wb25lbnRzIGZpbGw6I2ZmZiIsIm1lcm1haWQiOm51bGx9" /></p>

<p><em>Diagram showing data contracts as <strong>generalized and reusable &#8220;component&#8221; testing</strong> being checked through contracts and raising an error if they aren&#8217;t met or continuing operations if they are met.</em></p>

<p>We often need to verify a certain component&#8217;s surrounding data in order to ensure it meets minimum standards.
The word &#8220;component&#8221; is used here from the context of <a href="https://en.wikipedia.org/wiki/Component-based_software_engineering">component-based software design</a> to group together reusable, modular qualities of the data where sometimes we don&#8217;t know (or want) to specify granular aspects (such as schema, type, column name, etc).
These components often are implied by software which will eventually use the data, which can emit warnings or errors when they find the data does not meet these standards.
Oftentimes these components are contracts checking postconditions of earlier commands or procedures, ensuring the data we receive is accurate to our intention.
<strong><em>We can avoid these challenges by creating contracts for our data to verify the components of the result before it reaches later stages.</em></strong></p>

<p>Examples of these data components might include:</p>

<ul>
  <li>The dataset has no null values.</li>
  <li>The dataset has no more than 3 columns.</li>
  <li>The dataset has a column called <code class="language-plaintext highlighter-rouge">numbers</code> which includes numbers in the range of 0-10.</li>
</ul>

<h3 id="data-component-testing---great-expectations">Data Component Testing - Great Expectations</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
Example of using Great Expectations
Referenced with modifications from: 
https://docs.greatexpectations.io/docs/tutorials/quickstart/
"""</span>
<span class="kn">import</span> <span class="nn">great_expectations</span> <span class="k">as</span> <span class="n">gx</span>

<span class="c1"># get gx DataContext
# see: https://docs.greatexpectations.io/docs/terms/data_context
</span><span class="n">context</span> <span class="o">=</span> <span class="n">gx</span><span class="p">.</span><span class="n">get_context</span><span class="p">()</span>

<span class="c1"># set a context data source 
# see: https://docs.greatexpectations.io/docs/terms/datasource
</span><span class="n">validator</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">sources</span><span class="p">.</span><span class="n">pandas_default</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s">"https://raw.githubusercontent.com/great-expectations/gx_tutorials/main/data/yellow_tripdata_sample_2019-01.csv"</span>
<span class="p">)</span>

<span class="c1"># add and save expectations 
# see: https://docs.greatexpectations.io/docs/terms/expectation
</span><span class="n">validator</span><span class="p">.</span><span class="n">expect_column_values_to_not_be_null</span><span class="p">(</span><span class="s">"pickup_datetime"</span><span class="p">)</span>
<span class="n">validator</span><span class="p">.</span><span class="n">expect_column_values_to_be_between</span><span class="p">(</span><span class="s">"passenger_count"</span><span class="p">,</span> <span class="n">auto</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">validator</span><span class="p">.</span><span class="n">save_expectation_suite</span><span class="p">()</span>

<span class="c1"># checkpoint the context with the validator
# see: https://docs.greatexpectations.io/docs/terms/checkpoint
</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">add_or_update_checkpoint</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s">"my_quickstart_checkpoint"</span><span class="p">,</span>
    <span class="n">validator</span><span class="o">=</span><span class="n">validator</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># gather checkpoint expectation results
</span><span class="n">checkpoint_result</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># show the checkpoint expectation results
</span><span class="n">context</span><span class="p">.</span><span class="n">view_validation_result</span><span class="p">(</span><span class="n">checkpoint_result</span><span class="p">)</span>
</code></pre></div></div>

<p><em>Example code leveraging Python package Great Expectations to perform various data component contract validation.</em></p>

<p><a href="https://github.com/great-expectations/great_expectations">Great Expectations</a> is a Python project which provides data  contract testing features through the use of component called <a href="https://greatexpectations.io/expectations/">&#8220;expectations&#8221;</a> about the data involved.
These expectations act as a standardized way to define and validate the component of the data in the same way across different datasets or projects.
In addition to providing a mechanism for validating data contracts, Great Expecations also provides a way to <a href="https://docs.greatexpectations.io/docs/guides/setup/configuring_metadata_stores/configure_result_stores">view validation results</a>, <a href="https://docs.greatexpectations.io/docs/guides/setup/configuring_metadata_stores/configure_expectation_stores">share expectations</a>, and also <a href="https://docs.greatexpectations.io/docs/guides/setup/configuring_data_docs/host_and_share_data_docs">build data documentation</a>.
See the above example for a quick code reference of how these work.</p>

<h3 id="data-component-testing---assertr">Data Component Testing - Assertr</h3>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example using the Assertr package</span><span class="w">
</span><span class="c1"># referenced with modifications from:</span><span class="w">
</span><span class="c1"># https://docs.ropensci.org/assertr/articles/assertr.html</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">assertr</span><span class="p">)</span><span class="w">

</span><span class="c1"># set our.data to reference the mtcars dataset</span><span class="w">
</span><span class="n">our.data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mtcars</span><span class="w">

</span><span class="c1"># simulate an issue in the data for contract specification</span><span class="w">
</span><span class="n">our.data</span><span class="o">$</span><span class="n">mpg</span><span class="p">[</span><span class="m">5</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">our.data</span><span class="o">$</span><span class="n">mpg</span><span class="p">[</span><span class="m">5</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">-1</span><span class="w">

</span><span class="c1"># use verify to validate that column mpg &gt;= 0</span><span class="w">
</span><span class="n">our.data</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">verify</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">

</span><span class="c1"># use assert to validate that column mpg is within the bounds of 0 to infinity</span><span class="w">
</span><span class="n">our.data</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">assert</span><span class="p">(</span><span class="n">within_bounds</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="kc">Inf</span><span class="p">),</span><span class="w"> </span><span class="n">mpg</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><em>Example code leveraging R package Assertr to perform various data component contract validation.</em></p>

<p><a href="https://github.com/ropensci/assertr/">Assertr</a> is an R project which provides similar data component assertions in the form of verify, assert, and insist methods (<a href="https://docs.ropensci.org/assertr/articles/assertr.html">see here for more documentation</a>).
Using Assertr enables a similar but more lightweight functionality to that of Great Expectations.
See the above for an example of how to use it in your projects.</p>

<h2 id="data-schema-testing">Data Schema Testing</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbmlucHV0X2RhdGFbKFwiRGF0YSB0byBjaGVja1wiKV1cbmhhc19zY2hlbWF7XCJIYXNcXG5zY2hlbWE_XCJ9XG5jb250cmFjdChbXCJDb250cmFjdChzKVwiXSlcbnNjaGVtYVtcIi0gSGFzIGNvbHVtbiB4IG9mIHR5cGUgZmxvYXQgXFxuLSBIYXMgbm9uLW51bGwgY29sdW1uIHkgb2YgdHlwZSBpbnRcXG4gLSBldGMuLi5cIl1cbmNvbnRpbnVlW1wiQ29udGludWVcXG5vcGVyYXRpb25zXCJdXG5lcnJvcltcIlJhaXNlXFxuZXhjZXB0aW9uXCJdXG4lJS1cbnNjaGVtYSAtLT4gY29udHJhY3RcbmlucHV0X2RhdGEgLS0-IGhhc19zY2hlbWFcbmNvbnRyYWN0IC0uLT4gaGFzX3NjaGVtYVxuaGFzX3NjaGVtYSAtLT4gfCBZZXMgfCBjb250aW51ZVxuaGFzX3NjaGVtYSAtLT4gfCBObyB8IGVycm9yXG4lJS1cbnN0eWxlIGVycm9yIGZpbGw6I0ZFRDdBQVxuc3R5bGUgY29udGludWUgZmlsbDojRENGQ0U3XG5zdHlsZSBzY2hlbWEgZmlsbDojZmZmIiwibWVybWFpZCI6bnVsbH0" /></p>

<p><em>Diagram showing data contracts as <strong>more granular specifications via &#8220;schema&#8221; testing</strong> being checked through contracts and raising an error if they aren&#8217;t met or continuing operations if they are met.</em></p>

<p>Sometimes we need greater specificity than what a data component can offer.
We can use data schema testing contracts in these cases.
The word &#8220;schema&#8221; here is used from the context of <a href="https://en.wikipedia.org/wiki/Database_schema">database schema</a>, but oftentimes these specifications are suitable well beyond solely databases (including database-like formats like dataframes).
While reuse and modularity are more limited with these cases, they can be helpful for efforts where precision is valued or necessary to accomplish your goals.
It&#8217;s worth mentioning that data schema and component testing tools often have many overlaps (meaning you can interchangeably use them to accomplish both tasks).</p>

<h3 id="data-schema-testing---pandera">Data Schema Testing - Pandera</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
Example of using the Pandera package
referenced with modifications from:
https://pandera.readthedocs.io/en/stable/try_pandera.html
"""</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pandera</span> <span class="k">as</span> <span class="n">pa</span>
<span class="kn">from</span> <span class="nn">pandera.typing</span> <span class="kn">import</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">Series</span>


<span class="c1"># define a schema
</span><span class="k">class</span> <span class="nc">Schema</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="n">DataFrameModel</span><span class="p">):</span>
    <span class="n">item</span><span class="p">:</span> <span class="n">Series</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Field</span><span class="p">(</span><span class="n">isin</span><span class="o">=</span><span class="p">[</span><span class="s">"apple"</span><span class="p">,</span> <span class="s">"orange"</span><span class="p">],</span> <span class="nb">coerce</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">price</span><span class="p">:</span> <span class="n">Series</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">pa</span><span class="p">.</span><span class="n">Field</span><span class="p">(</span><span class="n">gt</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">coerce</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>


<span class="c1"># simulate invalid dataframe
</span><span class="n">invalid_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_records</span><span class="p">(</span>
    <span class="p">[{</span><span class="s">"item"</span><span class="p">:</span> <span class="s">"applee"</span><span class="p">,</span> <span class="s">"price"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span> 
     <span class="p">{</span><span class="s">"item"</span><span class="p">:</span> <span class="s">"orange"</span><span class="p">,</span> <span class="s">"price"</span><span class="p">:</span> <span class="o">-</span><span class="mi">1000</span><span class="p">}]</span>
<span class="p">)</span>


<span class="c1"># set a decorator on a function which will
# check the schema as a precondition
</span><span class="o">@</span><span class="n">pa</span><span class="p">.</span><span class="n">check_types</span><span class="p">(</span><span class="n">lazy</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">precondition_transform_data</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">[</span><span class="n">Schema</span><span class="p">]):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"here"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="c1"># precondition schema testing
</span><span class="k">try</span><span class="p">:</span>
    <span class="n">precondition_transform_data</span><span class="p">(</span><span class="n">invalid_data</span><span class="p">)</span>
<span class="k">except</span> <span class="n">pa</span><span class="p">.</span><span class="n">errors</span><span class="p">.</span><span class="n">SchemaErrors</span> <span class="k">as</span> <span class="n">schema_excs</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">schema_excs</span><span class="p">)</span>

<span class="c1"># inline or implied postcondition schema testing
</span><span class="k">try</span><span class="p">:</span>
    <span class="n">Schema</span><span class="p">.</span><span class="n">validate</span><span class="p">(</span><span class="n">invalid_data</span><span class="p">)</span>
<span class="k">except</span> <span class="n">pa</span><span class="p">.</span><span class="n">errors</span><span class="p">.</span><span class="n">SchemaError</span> <span class="k">as</span> <span class="n">schema_exc</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">schema_exc</span><span class="p">)</span>
</code></pre></div></div>

<p><em>Example code leveraging Python package Pandera to perform various data schema contract validation.</em></p>

<p>DataFrame-like libraries like <a href="https://pandas.pydata.org/">Pandas</a> can verified using schema specification contracts through <a href="https://pandera.readthedocs.io/en/stable/index.html">Pandera</a> (see here for <a href="https://pandera.readthedocs.io/en/stable/supported_libraries.html#supported-dataframe-libraries">full DataFrame library support</a>).
Pandera helps define specific columns, column types, and also has some component-like features.
It leverages a Pythonic class specification, similar to <a href="https://docs.python.org/3/library/dataclasses.html">data classes</a> and <a href="https://docs.pydantic.dev/latest/concepts/models/">pydantic models</a>, making it potentially easier to use if you already understand Python and DataFrame-like libraries.
See the above example for a look into how Pandera may be used.</p>

<h3 id="data-schema-testing---json-schema">Data Schema Testing - JSON Schema</h3>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example of using the jsonvalidate R package.</span><span class="w">
</span><span class="c1"># Referenced with modifications from:</span><span class="w">
</span><span class="c1"># https://docs.ropensci.org/jsonvalidate/articles/jsonvalidate.html</span><span class="w">

</span><span class="n">schema</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s1">'{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "Hello World JSON Schema",
  "description": "An example",
  "type": "object",
  "properties": {
    "hello": {
      "description": "Provide a description of the property here",
      "type": "string"
    }
  },
  "required": [
    "hello"
  ]
}'</span><span class="w">

</span><span class="c1"># create a schema contract for data</span><span class="w">
</span><span class="n">validate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">jsonvalidate</span><span class="o">::</span><span class="n">json_validator</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span><span class="w"> </span><span class="n">engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"ajv"</span><span class="p">)</span><span class="w">

</span><span class="c1"># validate JSON using schema specification contract and invalid data</span><span class="w">
</span><span class="n">validate</span><span class="p">(</span><span class="s2">"{}"</span><span class="p">)</span><span class="w">

</span><span class="c1"># validate JSON using schema specification contract and valid data</span><span class="w">
</span><span class="n">validate</span><span class="p">(</span><span class="s2">"{'hello':'world'}"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><a href="https://json-schema.org/learn/getting-started-step-by-step">JSON Schema</a> provides a vocabulary way to validate schema contracts for JSON documents.
There are several implementations of the vocabulary, including <a href="https://github.com/python-jsonschema/jsonschema">Python package jsonschema</a>, and R package <a href="https://github.com/ropensci/jsonvalidate">jsonvalidate</a>.
Using these libraries allows you to define pre- or postcondition data schema contracts for your software work.
See above for an R based example of using this vocabulary to perform data schema testing.</p>

<h2 id="shift-left-data-testing">Shift-left Data Testing</h2>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG5zdWJncmFwaCBsb2NhbCBbXCJEYXRhIFdvcmtmbG93IGFzIEhvYXJlIFRyaXBsZVwiXVxuZGlyZWN0aW9uIExSXG5zdWJncmFwaCBzcGFjZXIgW1wiIFwiXVxuc3ViZ3JhcGggcXVlc3Rpb24gW1wiRGF0YSBzb3VyY2UgY29uZGl0aW9uP1wiXVxuaW5wdXRfZGF0YVsoXCJJbnB1dCBEYXRhXFxuKFAgLSBwcmVjb25kaXRpb24pXCIpXVxuZW5kXG5lbmRcbnByb2Nlc3NfZGF0YVtcIkRhdGEgcHJvY2Vzc2luZ1xcbihDIC0gY29tbWFuZClcIl1cbm91dHB1dF9kYXRhWyhcIk91dHB1dCBEYXRhXFxuKFEgLSBwb3N0Y29uZGl0aW9uKVwiKV1cbmVuZFxuJSUtXG5pbnB1dF9kYXRhIC0tPiBwcm9jZXNzX2RhdGEgLS0-IG91dHB1dF9kYXRhXG4lJS1cbnN0eWxlIHF1ZXN0aW9uIGZpbGw6I2ZmZmZmZixzdHJva2U6I2ZmZmZmZjtcbnN0eWxlIHNwYWNlciBmaWxsOiNmZmZmZmYiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p>Earlier portions of this article have covered primarily data validation of command side-effects and postconditions.
This is commonplace in development where data sources usually are provided without the ability to validate their precondition or definition.
<a href="https://en.wikipedia.org/wiki/Shift-left_testing">Shift-left testing</a> is a movement which focuses on validating earlier in the lifecycle if and when possible to avoid downstream issues which might occur.</p>

<h3 id="shift-left-data-testing---data-version-control-dvc">Shift-left Data Testing - Data Version Control (DVC)</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbmR2Y1soXCJEYXRhIFZlcnNpb25cXG5Db250cm9sIChEVkMpXCIpXVxudmVyc2lvbmVkX2RhdGFbKFwiVmVyc2lvbmVkXFxuRGF0YXNldHNcIildXG5kdmNfY2xpW1wiRFZDIENsaWVudFwiXVxuaW5wdXRfZGF0YVsoXCJJbnB1dCBEYXRhXFxuKFAgLSBwcmVjb25kaXRpb24pXCIpXVxuJSUtXG5kdmMgLS0-IHwgdmVyc2lvbiBkYXRhIHwgZHZjX2NsaVxudmVyc2lvbmVkX2RhdGEgLS0-IHwgYWN0dWFsIGRhdGEgfCBkdmNfY2xpXG5kdmNfY2xpIC0tPiB8IHRvIG1haW50YWluIHwgaW5wdXRfZGF0YSIsIm1lcm1haWQiOm51bGx9" /></p>

<p>Data sources undergoing frequent changes become difficult to use because we oftentimes don&#8217;t know <em>when</em> the data is from or what version it might be.
This information is sometimes added in the form of filename additions or an update datetime column in a table.
<a href="https://dvc.org/doc">Data Version Control (DVC)</a> is one tool which is specially purposed to address this challenge through <a href="https://en.wikipedia.org/wiki/Version_control">source control</a> techniques.
Data managed by DVC allows software to be built in such a way that version preconditions are validated before reaching data transformations (commands) or postconditions.</p>

<h3 id="shift-left-data-testing---flyway">Shift-left Data Testing - Flyway</h3>

<p><img class="mermaid" src="https://mermaid.ink/svg/eyJjb2RlIjoiZmxvd2NoYXJ0IExSXG4lJS1cbnNxbFtcIkRhdGFiYXNlIGFzIENvZGVcXG4oaW4gU1FMKVwiXVxuZmx5d2F5W1wiRmx5d2F5XCJdXG5pbnB1dF9kYXRhWyhcIklucHV0IERhdGFcXG4oUCAtIHByZWNvbmRpdGlvbilcIildXG4lJS1cbnNxbCAtLT4gfCBpbnN0cnVjdGlvbnMgZm9yIHwgZmx5d2F5XG5mbHl3YXkgLS0-IHwgdG8gYnVpbGQgfCBpbnB1dF9kYXRhXG4lJS1cbnN0eWxlIHNxbCBmaWxsOiNmZmZmZmYiLCJtZXJtYWlkIjpudWxsfQ" /></p>

<p>Database sources can leverage an idea nicknamed <a href="https://speakerdeck.com/tastapod/arent-we-forgetting-someone">&#8220;database as code&#8221;</a> (which builds on a similar idea about <a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">infrastructure as code</a>) to help declare the schema and other elements of a database in the same way one would code.
These ideas apply to both databases and also more broadly through DVC mentioned above (among other tools) via the concept <a href="https://en.wikipedia.org/wiki/Code_as_data">&#8220;data as code&#8221;</a>.
Implementing this idea has several advantages from source versioning, visibility, and replicability.
One tool which implements these ideas is <a href="https://github.com/flyway/flyway">Flyway</a> which can manage and implement SQL-based files as part of software data precondition validation.
A lightweight alternative to using Flyway is sometimes to include a SQL file which creates related database objects and becomes data documentation.</p>]]></content><author><name>dave-bunten</name></author><category term="tip-of-the-week" /><category term="software" /><category term="data-quality" /><category term="data-testing" /><category term="testing" /><category term="design-by-contract" /><category term="component-based-design" /><category term="hoare-logic" /><category term="data-as-code" /><summary type="html"><![CDATA[Tip of the Week: Data Quality Validation through Software Testing Techniques]]></summary></entry></feed>