---
title: "Parquet"
author: dave-bunten
tags:
  - 
---

# Parquet

{% include blog-post-intro.html %}

## Introduction

<!-- excerpt start -->

<!-- excerpt end -->

![](../images/parquet.png)

[Apache Parquet](https://en.wikipedia.org/wiki/Apache_Parquet) is a columnar and strongly-typed tabular data storage format built for scalable processing which is widely compatible with many data models, programming languages, and software systems.
Parquet files (typically denoted with a `.parquet` filename extension) are typically compressed within the format itself and are often used in embedded or cloud-based high-performance scenarios
It has grown in popularity since it was introduced in 2013 and is used as a core data storage technology in many organizations.
This article will introduce the Parquet format from a research data engineering perspective.

## Understanding the Parquet file format

<table>
<tr>
<th>Data Type</th>
<th>Data</th>
<th>How data is organized on file</th>
</tr>
<tr>
<td>CSV</td>
<td>
<table>
<tr>
<td>1</td>
<td>Grapes</td>
</tr>
<tr>
<td>2</td>
<td>Oranges</td>
</tr>
</table>
<td>
<table>
<tr>
<td>1</td><td>Grapes</td><td>2</td><td>Oranges</td>
</tr>
</table>
</td>
</tr>
<tr>
<td>Parquet</td>
<td>
<table>
<tr>
<td>1</td>
<td>Grapes</td>
</tr>
<tr>
<td>2</td>
<td>Oranges</td>
</tr>
</table>
<td>

<table>
<tr>
<td>1</td><td>2</td><td>Grapes</td><td>Oranges</td>
</tr>
</table>

<center>(simplification)</center>

</td>
</tr>
</table>

_Parquet organizes column values together. CSV intermixes values from multiple columns._
{:.center}

Parquet files store data in a __"columnar"__ way which is distinct from other formats.
We can understand this columnar format by using [plaintext](https://en.wikipedia.org/wiki/Plaintext) [comma-separated value (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) format as a reference point.
CSV files store data in a row-orientated way by using new lines to represent rows of values.
Reading all values of a single column in CSV often involves seeking through multiple other portions of the data by default.

Parquet files are binary in nature, optimizing storage by arranging values from individual columns in close proximity to each other.
This enables the data to be stored and retrieved more efficiently than possible with CSV files.
For example, Parquet files allow you to query individual columns without needing to traverse non-necessary column value data.

### <i class="fas fa-box-archive"></i> Compression

Parquet files may leverage compression to help reduce file size and increase data read performance.
Data stored through Parquet is usually compressed when it is written, denoting the compression type through the filename (for example: `filename.snappy.parquet`).
[Snappy](https://en.wikipedia.org/wiki/Snappy_(compression)) is often used as a common compression algorithm for Parquet data.
[Brotli](https://en.wikipedia.org/wiki/Brotli), [Gzip](https://en.wikipedia.org/wiki/Gzip), [ZSTD](https://en.wikipedia.org/wiki/Zstd), [LZ4](https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)) ar also sometimes used.

### <i class="fas fa-table-columns"></i> "Strongly-typed" Data

Data within Parquet is considered ["strongly-typed"](https://en.wikipedia.org/wiki/Strong_and_weak_typing), entailing specific data types (such as integer, string, etc.) associated with each column and value.
Attempting to store a data value type which does not match the column data type will usually result in an error (or implied conversion).
This can lead to performance and compression benefits due to how quickly Parquet readers can determine the data type.

### <i class="fas fa-diagram-successor"></i> Complex data handling


Parquet files may store many data types that are complicated or impossible to store in other formats.
For example, images may be stored using the [byte array](https://parquet.apache.org/docs/file-format/types/) storage type.
Nested data may be stored using [`LIST` or `MAP` logical types](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#nested-types).
Dates or times may be stored using [various temporal data types.](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#temporal-types)
Oftentimes, complex data conversion within Parquet files is already implemented (for example, in [PyArrow](https://arrow.apache.org/docs/developers/python.html)).

### <i class="fas fa-tags"></i> Metadata

The Parquet format treats data about the data (metadata) separately from that of column value data.
[Parquet metadata](https://parquet.apache.org/docs/file-format/metadata/) includes column names, data types, compression, various statistics about the file, and custom fields (in key-value form).
This metadata may be read without reading column value data which can assist with data exploration tasks (especially if the data are large).

### <i class="fas fa-folder-tree"></i> Multi-file "datasets"

Parquet files may be used individually or treated as a "dataset" through file groups which include the same schema (column names and types).
This means you can store "chunks" of Parquet-based data in one or many files.
When reading Parquet data this way libraries usually use the directory as a way to parse all files as a single dataset.

### <i class="fas fa-forward"></i> Apache Arrow memory format integration

The Parquet format has robust support and integration with the [Apache Arrow](https://arrow.apache.org/docs/index.html) memory format.
This enables consistency across Parquet integration and how the data are read using various programming languages (the Arrow memory format is relatively uniform across these).




## Detail

<!-- set a max width for mermaid diagram below so it doesn't render so large -->
<style>
.mermaid {
  display: block;
  margin: 0 auto;
  max-height: 400px;
}
</style>

```mermaid!

```

_caption._
{:.center}


## Concluding Thoughts


